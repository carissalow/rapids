{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to RAPIDS documentation","text":"<p>Reproducible Analysis Pipeline for Data Streams (RAPIDS) allows you to process smartphone and wearable data to extract and create behavioral features (a.k.a. digital biomarkers), visualize mobile sensor data, and structure your analysis into reproducible workflows.</p> <p>RAPIDS is open source, documented, multi-platform, modular, tested, and reproducible. At the moment, we support data streams logged by smartphones, Fitbit wearables, and Empatica wearables in collaboration with the DBDP. </p> <p>Where do I start?</p> <p> New to RAPIDS? Check our Overview + FAQ and minimal example</p> <p> Install, configure, and execute RAPIDS to extract and plot behavioral features</p> <p> Bugs should be reported on Github issues</p> <p>:fontawesome-solid-tasks: Questions, discussions, feature requests, and feedback can be posted on our Github discussions</p> <p> Keep up to date with our Twitter feed or Slack channel</p> <p> Do you want to modify or add new functionality to RAPIDS? Check our contributing guide</p> <p>:fontawesome-solid-sync-alt: Are you upgrading from RAPIDS <code>0.4.x</code> or older? Follow this guide</p>"},{"location":"#what-are-the-benefits-of-using-rapids","title":"What are the benefits of using RAPIDS?","text":"<ol> <li>Consistent analysis. Every participant sensor dataset is analyzed in the same way and isolated from each other.</li> <li>Efficient analysis. Every analysis step is executed only once. Whenever your data or configuration changes, only the affected files are updated.</li> <li>Parallel execution. Thanks to Snakemake, your analysis can be executed over multiple cores without changing your code.</li> <li>Code-free features. Extract any of the behavioral features offered by RAPIDS without writing any code.</li> <li>Extensible code. You can easily add your own data streams or behavioral features in R or Python, share them with the community, and keep authorship and citations.</li> <li>Time zone aware. Your data is adjusted to one or more time zones per participant.</li> <li>Flexible time segments. You can extract behavioral features on time windows of any length (e.g., 5 minutes, 3 hours, 2 days), on every day or particular days (e.g., weekends, Mondays, the 1<sup>st</sup> of each month, etc.), or around events of interest (e.g., surveys or clinical relapses).</li> <li>Tested code. We are continually adding tests to make sure our behavioral features are correct.</li> <li>Reproducible code. If you structure your analysis within RAPIDS, you can be sure your code will run in other computers as intended, thanks to R and Python virtual environments. You can share your analysis code along with your publications without any overhead.</li> <li>Private. All your data is processed locally.</li> </ol>"},{"location":"#users-and-contributors","title":"Users and Contributors","text":"Community Contributors <p>Many thanks to our community contributions and the whole team:</p> <ul> <li>Agam Kumar (CMU)</li> <li>Yasaman S. Sefidgar (University of Washington)</li> <li>Joe Kim (Duke University)</li> <li>Brinnae Bent (Duke University)</li> <li>Stephen Price (CMU)</li> <li>Neil Singh (University of Virginia)</li> </ul> <p>Many thanks to the researchers that made their work open source:</p> <ul> <li>Panda et al. paper</li> <li>Stachl et al. paper</li> <li>Doryab et al. paper</li> <li>Barnett et al. paper</li> <li>Canzian et al. paper</li> </ul> Publications using RAPIDS <ul> <li>Predicting Symptoms of Depression and Anxiety Using Smartphone and Wearable Data link</li> <li>Predicting Depression from Smartphone Behavioral Markers Using Machine Learning Methods, Hyper-parameter Optimization, and Feature Importance Analysis: An Exploratory Study link</li> <li>Digital Biomarkers of Symptom Burden Self-Reported by Perioperative Patients Undergoing Pancreatic Surgery: Prospective Longitudinal Study link</li> <li>An Automated Machine Learning Pipeline for Monitoring and Forecasting Mobile Health Data link</li> </ul>"},{"location":"change-log/","title":"Change Log","text":""},{"location":"change-log/#v120","title":"v1.2.0","text":"<ul> <li>Sleep summary and intraday features are more consistent.</li> <li>Add wake and bedtime features for sleep summary data.</li> <li>Fix bugs with sleep PRICE features.</li> <li>Update home page</li> <li>Add contributing guide</li> </ul>"},{"location":"change-log/#v111","title":"v1.1.1","text":"<ul> <li>Fix length of periodic segments on days with DLS</li> <li>Fix crash when scraping data for an app that does not exist</li> <li>Add tests for phone screen data</li> </ul>"},{"location":"change-log/#v110","title":"v1.1.0","text":"<ul> <li>Add Fitbit calories intraday features</li> </ul>"},{"location":"change-log/#v101","title":"v1.0.1","text":"<ul> <li>Fix crash in <code>chunk_episodes</code> of <code>utils.py</code> for multi time zone data</li> <li>Fix crash in BT Doryab provider when the number of clusters is 2</li> <li>Fix Fitbit multi time zone inference from phone data (simplify)</li> <li>Fix missing columns when the input for phone data yield is empty</li> <li>Fix wrong date time labels for event segments for multi time zone data (all labels are computed based on a single tz)</li> <li>Fix periodic segment crash when there are no segments to assign (only affects wday, mday, qday, or yday) </li> <li>Fix crash in Analysis Workflow with new suffix in segments\u2019 labels</li> </ul>"},{"location":"change-log/#v100","title":"v1.0.0","text":"<ul> <li>Add a new Overview page.</li> <li>You can extend RAPIDS with your own data streams. Data streams are data collected with other sensing apps besides AWARE (like Beiwe, mindLAMP), and stored in other data containers (databases, files) besides MySQL.</li> <li>Support to analyze Empatica wearable data (thanks to Joe Kim and  Brinnae Bent from the DBDP)</li> <li>Support to analyze AWARE data stored in CSV files and InfluxDB databases</li> <li>Support to analyze data collected over multiple time zones</li> <li>Support for sleep intraday features from the core team and also from the community (thanks to Stephen Price)</li> <li>Users can comment on the documentation (powered by utterances).</li> <li><code>SCR_SCRIPT</code> and <code>SRC_LANGUAGE</code> are replaced by <code>SRC_SCRIPT</code>.</li> <li>Add RAPIDS new logo</li> <li>Move Citation and Minimal Example page to the Setup section</li> <li>Add <code>config.yaml</code> validation schema and documentation. Now it\u2019s more difficult to modify the <code>config.yaml</code> file with invalid values.</li> <li>Add new <code>time at home</code> Doryab location feature</li> <li>Add and home coordinates to the location data file so location providers can build features based on it.</li> <li>If you are migrating from RAPIDS 0.4.3 or older, check this guide</li> </ul>"},{"location":"change-log/#v043","title":"v0.4.3","text":"<ul> <li>Fix bug when any of the rows from any sensor do not belong a time segment</li> </ul>"},{"location":"change-log/#v042","title":"v0.4.2","text":"<ul> <li>Update battery testing</li> <li>Fix location processing bug when certain columns don\u2019t exist</li> <li>Fix HR intraday bug when minutesonZONE features were 0 </li> <li>Update FAQs</li> <li>Fix HR summary bug when restinghr=0 (ignore those rows)</li> <li>Fix ROG, location entropy and normalized entropy in Doryab location provider</li> <li>Remove sampling frequency dependance in Doryab location provider</li> <li>Update documentation of Doryab location provider</li> <li>Add new <code>FITBIT_DATA_YIELD</code> <code>RAPIDS</code> provider</li> <li>Deprecate Doryab circadian movement feature until it is fixed</li> </ul>"},{"location":"change-log/#v041","title":"v0.4.1","text":"<ul> <li>Fix bug when no error message was displayed for an empty <code>[PHONE_DATA_YIELD][SENSORS]</code> when resampling location data</li> </ul>"},{"location":"change-log/#v040","title":"v0.4.0","text":"<ul> <li>Add four new phone sensors that can be used for PHONE_DATA_YIELD</li> <li>Add code so new feature providers can be added for the new four sensors</li> <li>Add new clustering algorithm (OPTICS) for Doryab features</li> <li>Update default EPS parameter for Doryab location clustering</li> <li>Add clearer error message for invalid phone data yield sensors</li> <li>Add ALL_RESAMPLED flag and accuracy limit for location features</li> <li>Add FAQ about null characters in phone tables</li> <li>Reactivate light and wifi tests and update testing docs</li> <li>Fix bug when parsing Fitbit steps data</li> <li>Fix bugs when merging features from empty time segments</li> <li>Fix minor issues in the documentation</li> </ul>"},{"location":"change-log/#v032","title":"v0.3.2","text":"<ul> <li>Update docker and linux instructions to use RSPM binary repo for for faster installation</li> <li>Update CI to create a release on a tagged push that passes the tests</li> <li>Clarify in DB credential configuration that we only support MySQL</li> <li>Add Windows installation instructions</li> <li>Fix bugs in the create_participants_file script</li> <li>Fix bugs in Fitbit data parsing.</li> <li>Fixed Doryab location features context of clustering.</li> <li>Fixed the wrong shifting while calculating distance in Doryab location features.</li> <li>Refactored the haversine function</li> </ul>"},{"location":"change-log/#v031","title":"v0.3.1","text":"<ul> <li>Update installation docs for RAPIDS\u2019 docker container</li> <li>Fix example analysis use of accelerometer data in a plot</li> <li>Update FAQ</li> <li>Update minimal example documentation</li> <li>Minor doc updates</li> </ul>"},{"location":"change-log/#v030","title":"v0.3.0","text":"<ul> <li>Update R and Python virtual environments</li> <li>Add GH actions CI support for tests and docker</li> <li>Add release and test badges to README</li> </ul>"},{"location":"change-log/#v026","title":"v0.2.6","text":"<ul> <li>Fix old versions banner on nested pages</li> </ul>"},{"location":"change-log/#v025","title":"v0.2.5","text":"<ul> <li>Fix docs deploy typo</li> </ul>"},{"location":"change-log/#v024","title":"v0.2.4","text":"<ul> <li>Fix broken links in landing page and docs deploy</li> </ul>"},{"location":"change-log/#v023","title":"v0.2.3","text":"<ul> <li>Fix participant IDS in the example analysis workflow</li> </ul>"},{"location":"change-log/#v022","title":"v0.2.2","text":"<ul> <li>Fix readme link to docs</li> </ul>"},{"location":"change-log/#v021","title":"v0.2.1","text":"<ul> <li>FIx link to the most recent version in the old version banner</li> </ul>"},{"location":"change-log/#v020","title":"v0.2.0","text":"<ul> <li>Add new <code>PHONE_BLUETOOTH</code> <code>DORYAB</code> provider</li> <li>Deprecate <code>PHONE_BLUETOOTH</code> <code>RAPIDS</code> provider</li> <li>Fix bug in <code>filter_data_by_segment</code> for Python when dataset was empty</li> <li>Minor doc updates</li> <li>New FAQ item</li> </ul>"},{"location":"change-log/#v010","title":"v0.1.0","text":"<ul> <li>New and more consistent docs (this website). The previous docs are marked as beta </li> <li>Consolidate configuration instructions</li> <li>Flexible time segments</li> <li>Simplify Fitbit behavioral feature extraction and documentation</li> <li>Sensor\u2019s configuration and output is more consistent</li> <li>Update visualizations to handle flexible day segments</li> <li>Create a RAPIDS execution script that allows re-computation of the pipeline after configuration changes</li> <li>Add citation guide</li> <li>Update virtual environment guide</li> <li>Update analysis workflow example</li> <li>Add a Code of Conduct</li> <li>Update Team page</li> </ul>"},{"location":"citation/","title":"Cite RAPIDS and providers","text":"<p>RAPIDS and the community</p> <p>RAPIDS is a community effort and as such we want to continue recognizing the contributions from other researchers. Besides citing RAPIDS, we ask you to cite any of the authors listed below if you used those sensor providers in your analysis, thank you!</p>"},{"location":"citation/#rapids","title":"RAPIDS","text":"<p>If you used RAPIDS, please cite this paper.</p> <p>RAPIDS et al. citation</p> <p>Vega J, Li M, Aguillera K, Goel N, Joshi E, Durica KC, Kunta AR, Low CA RAPIDS: Reproducible Analysis Pipeline for Data Streams Collected with Mobile Devices JMIR Preprints. 18/08/2020:23246 DOI: 10.2196/preprints.23246 URL: https://preprints.jmir.org/preprint/23246</p>"},{"location":"citation/#dbdp-all-empatica-sensors","title":"DBDP (all Empatica sensors)","text":"<p>If you computed features using the provider  <code>[DBDP]</code> of any of the Empatica sensors (accelerometer, heart rate, temperature, EDA, BVP, IBI, tags) cite this paper in addition to RAPIDS.</p> <p>Bent et al. citation</p> <p>Bent, B., Wang, K., Grzesiak, E., Jiang, C., Qi, Y., Jiang, Y., Cho, P., Zingler, K., Ogbeide, F.I., Zhao, A., Runge, R., Sim, I., Dunn, J. (2020). The Digital Biomarker Discovery Pipeline: An open source software platform for the development of digital biomarkers using mHealth and wearables data. Journal of Clinical and Translational Science, 1-28. doi:10.1017/cts.2020.511</p>"},{"location":"citation/#panda-accelerometer","title":"Panda (accelerometer)","text":"<p>If you computed accelerometer features using the provider  <code>[PHONE_ACCLEROMETER][PANDA]</code> cite this paper in addition to RAPIDS.</p> <p>Panda et al. citation</p> <p>Panda N, Solsky I, Huang EJ, Lipsitz S, Pradarelli JC, Delisle M, Cusack JC, Gadd MA, Lubitz CC, Mullen JT, Qadan M, Smith BL, Specht M, Stephen AE, Tanabe KK, Gawande AA, Onnela JP, Haynes AB. Using Smartphones to Capture Novel Recovery Metrics After Cancer Surgery. JAMA Surg. 2020 Feb 1;155(2):123-129. doi: 10.1001/jamasurg.2019.4702. PMID: 31657854; PMCID: PMC6820047.</p>"},{"location":"citation/#stachl-applications-foreground","title":"Stachl (applications foreground)","text":"<p>If you computed applications foreground features using the app category (genre) catalogue in  <code>[PHONE_APPLICATIONS_FOREGROUND][RAPIDS]</code> cite this paper in addition to RAPIDS.</p> <p>Stachl et al. citation</p> <p>Clemens Stachl, Quay Au, Ramona Schoedel, Samuel D. Gosling, Gabriella M. Harari, Daniel Buschek, Sarah Theres V\u00f6lkel, Tobias Schuwerk, Michelle Oldemeier, Theresa Ullmann, Heinrich Hussmann, Bernd Bischl, Markus B\u00fchner. Proceedings of the National Academy of Sciences Jul 2020, 117 (30) 17680-17687; DOI: 10.1073/pnas.1920484117 </p>"},{"location":"citation/#doryab-bluetooth","title":"Doryab (bluetooth)","text":"<p>If you computed bluetooth features using the provider <code>[PHONE_BLUETOOTH][DORYAB]</code> cite this paper in addition to RAPIDS.</p> <p>Doryab et al. citation</p> <p>Doryab, A., Chikarsel, P., Liu, X., &amp; Dey, A. K. (2019). Extraction of Behavioral Features from Smartphone and Wearable Data. ArXiv:1812.10394 [Cs, Stat]. http://arxiv.org/abs/1812.10394</p>"},{"location":"citation/#barnett-locations","title":"Barnett (locations)","text":"<p>If you computed locations features using the provider <code>[PHONE_LOCATIONS][BARNETT]</code> cite this paper and this paper in addition to RAPIDS.</p> <p>Barnett et al. citation</p> <p>Ian Barnett, Jukka-Pekka Onnela, Inferring mobility measures from GPS traces with missing data, Biostatistics, Volume 21, Issue 2, April 2020, Pages e98\u2013e112, https://doi.org/10.1093/biostatistics/kxy059</p> <p>Canzian et al. citation</p> <p>Luca Canzian and Mirco Musolesi. 2015. Trajectories of depression: unobtrusive monitoring of depressive states by means of smartphone mobility traces analysis. In Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp \u201815). Association for Computing Machinery, New York, NY, USA, 1293\u20131304. DOI:https://doi.org/10.1145/2750858.2805845</p>"},{"location":"citation/#doryab-locations","title":"Doryab (locations)","text":"<p>If you computed locations features using the provider <code>[PHONE_LOCATIONS][DORYAB]</code> cite this paper and this paper in addition to RAPIDS.</p> <p>Doryab et al. citation</p> <p>Doryab, A., Chikarsel, P., Liu, X., &amp; Dey, A. K. (2019). Extraction of Behavioral Features from Smartphone and Wearable Data. ArXiv:1812.10394 [Cs, Stat]. http://arxiv.org/abs/1812.10394</p> <p>Canzian et al. citation</p> <p>Luca Canzian and Mirco Musolesi. 2015. Trajectories of depression: unobtrusive monitoring of depressive states by means of smartphone mobility traces analysis. In Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp \u201815). Association for Computing Machinery, New York, NY, USA, 1293\u20131304. DOI:https://doi.org/10.1145/2750858.2805845</p>"},{"location":"code_of_conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"code_of_conduct/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"code_of_conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others\u2019 private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"code_of_conduct/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"code_of_conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at moshi@pitt.edu. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"code_of_conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"code_of_conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"code_of_conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"code_of_conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"code_of_conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior,  harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"code_of_conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by  Mozilla\u2019s code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available  at https://www.contributor-covenant.org/translations.</p>"},{"location":"common-errors/","title":"Common Errors","text":""},{"location":"common-errors/#cannot-connect-to-your-mysql-server","title":"Cannot connect to your MySQL server","text":"Problem <pre><code>**Error in .local(drv, \\...) :** **Failed to connect to database: Error:\nCan\\'t initialize character set unknown (path: compiled\\_in)** :\n\nCalls: dbConnect -&gt; dbConnect -&gt; .local -&gt; .Call\nExecution halted\n[Tue Mar 10 19:40:15 2020]\nError in rule download_dataset:\n    jobid: 531\n    output: data/raw/p60/locations_raw.csv\n\nRuleException:\nCalledProcessError in line 20 of /home/ubuntu/rapids/rules/preprocessing.snakefile:\nCommand 'set -euo pipefail;  Rscript --vanilla /home/ubuntu/rapids/.snakemake/scripts/tmp_2jnvqs7.download_dataset.R' returned non-zero exit status 1.\nFile \"/home/ubuntu/rapids/rules/preprocessing.snakefile\", line 20, in __rule_download_dataset\nFile \"/home/ubuntu/anaconda3/envs/moshi-env/lib/python3.7/concurrent/futures/thread.py\", line 57, in run\nShutting down, this might take some time.\nExiting because a job execution failed. Look above for error message\n</code></pre> Solution <p>Please make sure the <code>DATABASE_GROUP</code> in <code>config.yaml</code> matches your DB credentials group in <code>.env</code>.</p>"},{"location":"common-errors/#cannot-start-mysql-in-linux-via-brew-services-start-mysql","title":"Cannot start mysql in linux via <code>brew services start mysql</code>","text":"Problem <p>Cannot start mysql in linux via <code>brew services start mysql</code></p> Solution <p>Use <code>mysql.server start</code></p>"},{"location":"common-errors/#every-time-i-run-force-the-download_dataset-rule-all-rules-are-executed","title":"Every time I run force the download_dataset rule all rules are executed","text":"Problem <p>When running <code>snakemake -j1 -R pull_phone_data</code> or <code>./rapids -j1 -R pull_phone_data</code> all the rules and files are re-computed</p> Solution <p>This is expected behavior. The advantage of using <code>snakemake</code> under the hood is that every time a file containing data is modified every rule that depends on that file will be re-executed to update their results. In this case, since <code>download_dataset</code> updates all the raw data, and you are forcing the rule with the flag <code>-R</code> every single rule that depends on those raw files will be executed.</p>"},{"location":"common-errors/#error-table-xxx-doesnt-exist-while-running-the-download_phone_data-or-download_fitbit_data-rule","title":"Error <code>Table XXX doesn't exist</code> while running the <code>download_phone_data</code> or <code>download_fitbit_data</code> rule.","text":"Problem <pre><code>Error in .local(conn, statement, ...) : \n  could not run statement: Table 'db_name.table_name' doesn't exist\nCalls: colnames ... .local -&gt; dbSendQuery -&gt; dbSendQuery -&gt; .local -&gt; .Call\nExecution halted\n</code></pre> Solution <p>Please make sure the sensors listed in <code>[PHONE_VALID_SENSED_BINS][PHONE_SENSORS]</code> and the <code>[CONTAINER]</code> of each sensor you activated in <code>config.yaml</code>  match your database tables or files.</p>"},{"location":"common-errors/#how-do-i-install-rapids-on-ubuntu-1604","title":"How do I install RAPIDS on Ubuntu 16.04","text":"Solution <ol> <li> <p>Install dependencies (Homebrew - if not installed):</p> <ul> <li><code>sudo apt-get install libmariadb-client-lgpl-dev libxml2-dev libssl-dev</code></li> <li>Install brew for linux and add the following line to <code>~/.bashrc</code>: <code>export PATH=$HOME/.linuxbrew/bin:$PATH</code></li> <li><code>source ~/.bashrc</code></li> </ul> </li> <li> <p>Install MySQL</p> <ul> <li><code>brew install mysql</code></li> <li><code>brew services start mysql</code></li> </ul> </li> <li> <p>Install R, pandoc and rmarkdown:</p> <ul> <li><code>brew install r</code></li> <li><code>brew install gcc@6</code> (needed due to this bug)</li> <li><code>HOMEBREW_CC=gcc-6 brew install pandoc</code></li> </ul> </li> <li> <p>Install miniconda using these instructions</p> </li> <li> <p>Clone our repo:</p> <ul> <li><code>git clone https://github.com/carissalow/rapids</code></li> </ul> </li> <li> <p>Create a python virtual environment:</p> <ul> <li><code>cd rapids</code></li> <li><code>conda env create -f environment.yml -n MY_ENV_NAME</code></li> <li><code>conda activate MY_ENV_NAME</code></li> </ul> </li> <li> <p>Install R packages and virtual environment:</p> <ul> <li><code>snakemake renv_install</code></li> <li><code>snakemake renv_init</code></li> <li><code>snakemake renv_restore</code></li> </ul> <p>This step could take several minutes to complete. Please be patient and let it run until completion.</p> </li> </ol>"},{"location":"common-errors/#mysqlh-cannot-be-found","title":"<code>mysql.h</code> cannot be found","text":"Problem <pre><code>--------------------------[ ERROR MESSAGE ]----------------------------\n&lt;stdin&gt;:1:10: fatal error: mysql.h: No such file or directory\ncompilation terminated.\n-----------------------------------------------------------------------\nERROR: configuration failed for package 'RMySQL'\n</code></pre> Solution <pre><code>sudo apt install libmariadbclient-dev\n</code></pre>"},{"location":"common-errors/#no-package-libcurl-found","title":"No package <code>libcurl</code> found","text":"Problem <p><code>libcurl</code> cannot be found</p> Solution <p>Install <code>libcurl</code> <pre><code>sudo apt install libcurl4-openssl-dev\n</code></pre></p>"},{"location":"common-errors/#configuration-failed-because-openssl-was-not-found","title":"Configuration failed because <code>openssl</code> was not found.","text":"Problem <p><code>openssl</code> cannot be found</p> Solution <p>Install <code>openssl</code> <pre><code>sudo apt install libssl-dev\n</code></pre></p>"},{"location":"common-errors/#configuration-failed-because-libxml-20-was-not-found","title":"Configuration failed because <code>libxml-2.0</code> was not found","text":"Problem <p><code>libxml-2.0</code> cannot be found</p> Solution <p>Install <code>libxml-2.0</code> <pre><code>sudo apt install libxml2-dev\n</code></pre></p>"},{"location":"common-errors/#ssl-connection-error-when-running-rapids","title":"SSL connection error when running RAPIDS","text":"Problem <p>You are getting the following error message when running RAPIDS: <pre><code>Error: Failed to connect: SSL connection error: error:1425F102:SSL routines:ssl_choose_client_version:unsupported protocol.\n</code></pre></p> Solution <p>This is a bug in Ubuntu 20.04 when trying to connect to an old MySQL server with MySQL client 8.0. You should get the same error message if you try to connect from the command line. There you can add the option <code>--ssl-mode=DISABLED</code> but we can't do this from the R connector.</p> <p>If you can't update your server, the quickest solution would be to import your database to another server or to a local environment. Alternatively, you could replace <code>mysql-client</code> and <code>libmysqlclient-dev</code> with <code>mariadb-client</code> and <code>libmariadbclient-dev</code> and reinstall renv. More info about this issue here</p>"},{"location":"common-errors/#db_tables-key-not-found","title":"<code>DB_TABLES</code> key not found","text":"Problem <p>If you get the following error <code>KeyError in line 43 of preprocessing.smk: 'PHONE_SENSORS'</code>, it means that the indentation of the key <code>[PHONE_SENSORS]</code> is not matching the other child elements of <code>PHONE_VALID_SENSED_BINS</code></p> Solution <p>You need to add or remove any leading whitespaces as needed on that line.</p> <pre><code>PHONE_VALID_SENSED_BINS:\n    COMPUTE: False # This flag is automatically ignored (set to True) if you are extracting PHONE_VALID_SENSED_DAYS or screen or Barnett's location features\n    BIN_SIZE: &amp;bin_size 5 # (in minutes)\n    PHONE_SENSORS: []\n</code></pre>"},{"location":"common-errors/#error-while-updating-your-conda-environment-in-ubuntu","title":"Error while updating your conda environment in Ubuntu","text":"Problem <p>You get the following error: <pre><code>CondaMultiError: CondaVerificationError: The package for tk located at /home/ubuntu/miniconda2/pkgs/tk-8.6.9-hed695b0_1003\n    appears to be corrupted. The path 'include/mysqlStubs.h'\n    specified in the package manifest cannot be found.\nClobberError: This transaction has incompatible packages due to a shared path.\n    packages: conda-forge/linux-64::llvm-openmp-10.0.0-hc9558a2_0, anaconda/linux-64::intel-openmp-2019.4-243\n    path: 'lib/libiomp5.so'\n</code></pre></p> Solution <p>Reinstall conda</p>"},{"location":"common-errors/#embedded-nul-in-string","title":"Embedded nul in string","text":"Problem <p>You get the following error when downloading sensor data: <pre><code>Error in result_fetch(res@ptr, n = n) : \n  embedded nul in string:\n</code></pre></p> Solution <p>This problem is due to the way <code>RMariaDB</code> handles a mismatch between data types in R and MySQL (see this issue). Since it seems this problem won\u2019t be handled by <code>RMariaDB</code>, you have two options:</p> <ol> <li>Remove the the null character from the conflictive table cell(s). You can adapt the following query on a MySQL server 8.0 or older     <pre><code>update YOUR_TABLE set YOUR_COLUMN = regexp_replace(YOUR_COLUMN, '\\0', '');\n</code></pre></li> <li>If it\u2019s not feasible to modify your data you can try swapping <code>RMariaDB</code> with <code>RMySQL</code>. Just have in mind you might have problems connecting to modern MySQL servers running in Linux:<ul> <li>Add <code>RMySQL</code> to the renv environment by running the following command in a terminal open on RAPIDS root folder <pre><code>R -e 'renv::install(\"RMySQL\")'\n</code></pre></li> <li>Go to <code>src/data/streams/pull_phone_data.R</code> or <code>src/data/streams/pull_fitbit_data.R</code> and replace <code>library(RMariaDB)</code> with <code>library(RMySQL)</code></li> <li>In the same file(s) replace <code>dbEngine &lt;- dbConnect(MariaDB(), default.file = \"./.env\", group = group)</code> with <code>dbEngine &lt;- dbConnect(MySQL(), default.file = \"./.env\", group = group)</code></li> </ul> </li> </ol>"},{"location":"common-errors/#there-is-no-package-called-rmariadb","title":"There is no package called <code>RMariaDB</code>","text":"Problem <p>You get the following error when executing RAPIDS: <pre><code>Error in library(RMariaDB) : there is no package called 'RMariaDB'\nExecution halted\n</code></pre></p> Solution <p>In RAPIDS v0.1.0 we replaced <code>RMySQL</code> R package with <code>RMariaDB</code>, this error means your R virtual environment is out of date, to update it run <code>snakemake -j1 renv_restore</code></p>"},{"location":"common-errors/#unrecognized-output-timezone-americanew_york","title":"Unrecognized output timezone \u201cAmerica/New_York\u201d","text":"Problem <p>When running RAPIDS with R 4.0.3 on MacOS on M1, lubridate may throw an error associated with the timezone. <pre><code>Error in C_force_tz(time, tz = tzone, roll):\n   CCTZ: Unrecognized output timezone: \"America/New_York\"\nCalls: get_timestamp_filter ... .parse_date_time -&gt; .strptime -&gt; force_tz -&gt; C_force_tz\n</code></pre></p> Solution <p>This is because R timezone library is not set. Please add <code>Sys.setenv(\u201cTZDIR\u201d = file.path(R.home(), \u201cshare\u201d, \u201czoneinfo\u201d))</code> to the file active.R in renv folder to set the timezone library. For further details on how to test if <code>TZDIR</code> is properly set, please refer to <code>https://github.com/tidyverse/lubridate/issues/928#issuecomment-720059233</code>. </p>"},{"location":"common-errors/#unimplemented-max_no_field_types","title":"Unimplemented MAX_NO_FIELD_TYPES","text":"Problem <p>You get the following error when downloading Fitbit data: <pre><code>Error: Unimplemented MAX_NO_FIELD_TYPES\nExecution halted\n</code></pre></p> Solution <p>At the moment RMariaDB cannot handle MySQL columns of JSON type. Change the type of your Fitbit data column to <code>longtext</code> (note that the content will not change and will still be a JSON object just interpreted as a string).</p>"},{"location":"common-errors/#running-rapids-on-apple-silicon-m1-mac","title":"Running RAPIDS on Apple Silicon M1 Mac","text":"Problem <p>You get the following error when installing pandoc or running rapids:  <pre><code>MoSHI/rapids/renv/staging/1/00LOCK-KernSmooth/00new/KernSmooth/libs/KernSmooth.so: mach-0, but wrong architecture\n</code></pre></p> Solution <p>As of Feb 2020 in M1 macs, R needs to be installed via brew under Rosetta (x86 arch) due to some incompatibility with selected R libraries. To do this, run your terminal via Rosetta, then proceed with the usual brew installation command. x86 homebrew should be installed in <code>/usr/local/bin/brew</code>, you can check which brew you are using by typing <code>which brew</code>. Then use x86 homebrew to install R and restore RAPIDS packages (<code>renv_restore</code>). </p>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for taking the time to contribute! </p> <p>All changes, small or big, are welcome, and regardless of who you are, we are always happy to work together to make your contribution as strong as possible. We follow the Covenant Code of Conduct, so we ask you to uphold it. Be kind to everyone in the community, and please report unacceptable behavior to moshiresearch@gmail.com.</p>"},{"location":"contributing/#questions-feature-requests-and-discussions","title":"Questions, Feature Requests, and Discussions","text":"<p>Post any questions, feature requests, or discussions in our GitHub Discussions tab.</p>"},{"location":"contributing/#bug-reports","title":"Bug Reports","text":"<p>Report any bugs in our GithHub issue tracker keeping in mind to:</p> <ul> <li>Debug and simplify the problem to create a minimal example. For example, reduce the problem to a single participant, sensor, and a few rows of data.</li> <li>Provide a clear and succinct description of the problem (expected behavior vs. actual behavior).</li> <li>Attach your <code>config.yaml</code>, time segments file, and time zones file if appropriate.</li> <li>Attach test data if possible and any screenshots or extra resources that will help us debug the problem.</li> <li>Share the commit you are running: <code>git rev-parse --short HEAD</code></li> <li>Share your OS version (e.g., Windows 10)</li> <li>Share the device/sensor you are processing (e.g., phone accelerometer)</li> </ul>"},{"location":"contributing/#documentation-contributions","title":"Documentation Contributions","text":"<p>If you want to fix a typo or any other minor changes, you can edit the file online by clicking on the pencil icon at the top right of any page and opening a pull request using Github\u2019s website</p> <p>If your changes are more complex, clone RAPIDS\u2019 repository, setup the dev environment for our documentation with this tutorial, and submit any changes on a new feature branch following our git flow.</p>"},{"location":"contributing/#code-contributions","title":"Code Contributions","text":"<p>Hints for any code changes</p> <ul> <li>To submit any new code, use a new feature branch following our git flow.</li> <li>If you neeed a new Python or R package in RAPIDS\u2019 virtual environments, follow this tutorial</li> <li>If you need to change the <code>config.yaml</code> you will need to update its validation schema with this tutorial</li> </ul>"},{"location":"contributing/#new-data-streams","title":"New Data Streams","text":"<p>New data containers. If you want to process data from a device RAPIDS supports (see this table) but it\u2019s stored in a database engine or file type we don\u2019t support yet, implement a new data stream container and format. You can copy and paste the <code>format.yaml</code> of one of the other streams of the device you are targeting.</p> <p>New sensing apps. If you want to add support for new smartphone sensing apps like Beiwe, implement a new data stream container and format.</p> <p>New wearable devices. If you want to add support for a new wearable, open a Github discussion, so we can add the necessary initial configuration files and code.</p>"},{"location":"contributing/#new-behavioral-features","title":"New Behavioral Features","text":"<p>If you want to add new behavioral features for mobile sensors RAPIDS already supports, follow this tutorial. A sensor is supported if it has a configuration section in <code>config.yaml</code>.</p> <p>If you want to add new behavioral features for mobile sensors RAPIDS does not support yet, open a Github discussion, so we can add the necessary initial configuration files and code.</p>"},{"location":"contributing/#new-tests","title":"New Tests","text":"<p>If you want to add new tests for existent behavioral features, follow this tutorial.</p>"},{"location":"contributing/#new-visualizations","title":"New Visualizations","text":"<p>Open a Github discussion, so we can add the necessary initial configuration files and code.</p>"},{"location":"migrating-from-old-versions/","title":"Migration guides","text":""},{"location":"migrating-from-old-versions/#migrating-from-rapids-04x-or-older","title":"Migrating from RAPIDS 0.4.x or older","text":"<p>There are four actions that you need to take if you were using RAPIDS <code>0.4.3</code> or older (before Feb 9<sup>th</sup>, 2021):</p> Check the new Overview page <p>Check the new Overview page. Hopefully, it is a better overview of RAPIDS and provides answers to Frequently Asked Questions.</p> Deploy RAPIDS in a new folder <ul> <li>Clone RAPIDS 1.x in a new folder (do not pull the updates in your current folder)</li> <li>Activate your conda environment</li> <li>Install renv again <code>snakemake -j1 renv_install</code> (for Ubuntu take advantage of the platform specific R <code>renv</code> instructions)</li> <li>Restore renv packages <code>snakemake -j1 renv_restore</code> (for Ubuntu take advantage of the platform specific R <code>renv</code> instructions)</li> <li>Move your participant files <code>pxx.yaml</code> to the new folder</li> <li>Move your time segment files to the new folder</li> <li>Move your <code>.env</code> file to the new folder</li> </ul> Migrate your <code>.env</code> file to the new <code>credentials.yaml</code> format <p>The <code>.env</code> file is not used anymore, the same credential groups are stored in <code>credentials.yaml</code>, migrate your <code>.env</code> file by running:   <pre><code>python tools/update_format_env.py\n</code></pre></p> Reconfigure your <code>config.yaml</code> <p>Reconfigure your <code>config.yaml</code> file by hand (don\u2019t copy and paste the old one). Some keys and values changed but the defaults should be compatible with the things you know from RAPIDS 0.x (see below).</p> <p>The most relevant changes to RAPIDS that you need to know about are:</p> We introduced the concept of data streams <p>RAPIDS abstracts sensor data logged by different devices, platforms and stored in different data containers as data streams.</p> <p>The default data stream for <code>PHONE</code> is <code>aware_mysql</code>, and the default for <code>FITBIT</code> is <code>fitbitjson_mysql</code>. This is compatible with the old functionality (AWARE and JSON Fitbit data stored in MySQL). These values are set in <code>[PHONE_DATA_STREAMS][USE]</code> and <code>[FITBIT_DATA_STREAMS][USE]</code>.</p> <p>You can add new data stream formats (sensing apps) and containers (database engines, file types, etc.).</p> <p>If you were processing your Fitbit data either in JSON or plain text (parsed) format, and it was stored in MySQL or CSV files, the changes that you made to your raw data will be compatible. Just choose <code>fitbitjson_mysql</code>, <code>fitbitparsed_mysql</code>, <code>fitbitjson_csv</code>, <code>fitbitparsed_csv</code> accordingly and set it in <code>[FITBIT_DATA_STREAMS][USE]</code>. </p> <p>In the future, you will not have to change your raw data; you will be able to just change column mappings/values in the data stream\u2019s <code>format.yaml</code> file.</p> We introduced multiple time zones <p>You can now process data from participants that visited multiple time zones. The default is still a single time zone (America/New_York). See how to handle multiple time zones</p> The keyword <code>multiple</code> is now <code>infer</code> <p>When processing data from smartphones, RAPIDS allows you to infer the OS of a smartphone by using the keyword <code>multiple</code> in the <code>[PLATFORM]</code> key of participant files. Now RAPIDS uses <code>infer</code> instead of <code>multiple</code> Nonetheless, <code>multiple</code> still works for backward compatibility.</p> A global <code>DATABASE_GROUP</code> does not exist anymore <p>There is no global <code>DATABASE_GROUP</code> anymore. Each data stream that needs credentials to connect to a database has its own <code>DATABASE_GROUP</code> config key. The groups are defined in <code>credentials.yaml</code> instead of the <code>.env</code>.</p> <code>[DEVICE_SENSOR][TABLE]</code> is now <code>[DEVICE_SENSOR][CONTAINER]</code> <p>We renamed the keys <code>[DEVICE_SENSOR][TABLE]</code> to <code>[DEVICE_SENSOR][CONTAINER]</code> to reflect that, with the introduction of data streams, they can point to a database table, file, or any other data container.</p> Creating participant files from the AWARE_DEVICE_TABLE is deprecated <p>In previous versions of RAPIDS, you could create participant files automatically using the <code>aware_device</code> table. We deprecated this option but you can still achieve the same results if you export the output of the following SQL query as a CSV file and follow the instructions to create participant files from CSV files:</p> <pre><code>SELECT device_id, device_id as fitbit_id, CONCAT(\"p\", _id) as empatica_id, CONCAT(\"p\", _id) as pid, if(brand = \"iPhone\", \"ios\", \"android\") as platform, CONCAT(\"p\", _id)  as label, DATE_FORMAT(FROM_UNIXTIME((timestamp/1000)- 86400), \"%Y-%m-%d\") as start_date, CURRENT_DATE as end_date from aware_device order by _id;\n</code></pre> <code>SCR_SCRIPT</code> and <code>SRC_LANGUAGE</code> are replaced by <code>SRC_SCRIPT</code> <p>The attributes <code>SCR_SCRIPT</code> and <code>SRC_LANGUAGE</code> of every sensor <code>PROVIDER</code> are replaced by <code>SRC_SCRIPT</code>. <code>SRC_SCRIPT</code> is a relative path from the RAPIDS root folder to that provider\u2019s feature script. We did this to simplify and clarify where the features scripts are stored. </p> <p>There are no actions to take unless you created your own feature provider; update it with your feature script path.</p>"},{"location":"migrating-from-old-versions/#migrating-from-rapids-beta","title":"Migrating from RAPIDS beta","text":"<p>If you were relying on the old docs and the most recent version of RAPIDS you are working with is from or before Oct 13, 2020 you are using the beta version of RAPIDS.</p> <p>You can start using the RAPIDS <code>0.1.0</code> right away, just take into account the following:</p> Deploy RAPIDS in a new folder <ul> <li>Install a new copy of RAPIDS (the R and Python virtual environments didn\u2019t change so the cached versions will be reused)</li> <li>Make sure you don\u2019t skip a new Installation step to give execution permissions to the RAPIDS script: <code>chmod +x rapids</code></li> <li>Move your old <code>.env</code> file</li> <li>Move your participant files</li> </ul> Migrate your participant files <p>You can migrate your old participant files to the new YAML format:   <pre><code>python tools/update_format_participant_files.py\n</code></pre></p> Follow the new Configuration guide <p>Follow the new Configuration guide</p> Learn more about the new way to run RAPIDS <p>Get familiar with the new way of Executing RAPIDS</p>"},{"location":"team/","title":"RAPIDS Team","text":"<p>If you are interested in contributing feel free to submit a pull request or contact us.</p>"},{"location":"team/#core-team","title":"Core Team","text":""},{"location":"team/#julio-vega-designer-and-lead-developer","title":"Julio Vega (Designer and Lead Developer)","text":"About <p>Julio Vega is a postdoctoral associate at the Mobile Sensing + Health Institute. He is interested in personalized methodologies to monitor chronic conditions that affect daily human behavior using mobile and wearable data.</p> <ul> <li>vegaju at upmc . edu</li> <li>Personal Website</li> </ul>"},{"location":"team/#meng-li","title":"Meng Li","text":"About <p>Meng Li received her Master of Science degree in Information Science from the University of Pittsburgh. She is interested in applying machine learning algorithms to the medical field.</p> <ul> <li>lim11 at upmc . edu</li> <li>Linkedin Profile</li> <li>Github Profile</li> </ul>"},{"location":"team/#abhineeth-reddy-kunta","title":"Abhineeth Reddy Kunta","text":"About <p>Abhineeth Reddy Kunta is a Senior Software Engineer with the Mobile Sensing + Health Institute. He is experienced in software development and specializes in building solutions using machine learning. Abhineeth likes exploring ways to leverage technology in advancing medicine and education. Previously he worked as a Computer Programmer at Georgia Department of Public Health. He has a master\u2019s degree in Computer Science from George Mason University.</p>"},{"location":"team/#kwesi-aguillera","title":"Kwesi Aguillera","text":"About <p>Kwesi Aguillera is currently in his first year at the University of Pittsburgh pursuing a Master of Sciences in Information Science specializing in Big Data Analytics. He received his Bachelor of Science degree in Computer Science and Management from the University of the West Indies. Kwesi considers himself a full stack developer and looks forward to applying this knowledge to big data analysis.</p> <ul> <li>Linkedin Profile</li> </ul>"},{"location":"team/#echhit-joshi","title":"Echhit Joshi","text":"About <p>Echhit Joshi is a Masters student at the School of Computing and Information at University of Pittsburgh. His areas of interest are Machine/Deep Learning, Data Mining, and Analytics.</p> <ul> <li>Linkedin Profile</li> </ul>"},{"location":"team/#nicolas-leo","title":"Nicolas Leo","text":"About <p>Nicolas is a rising senior studying computer science at the University of Pittsburgh. His academic interests include databases, machine learning, and application development. After completing his undergraduate degree, he plans to attend graduate school for a MS in Computer Science with a focus on Intelligent Systems.</p>"},{"location":"team/#nikunj-goel","title":"Nikunj Goel","text":"About <p>Nik is a graduate student at the University of Pittsburgh pursuing Master of Science in Information Science. He earned his Bachelor of Technology degree in Information Technology from India. He is a Data Enthusiasts and passionate about finding the meaning out of raw data. In a long term, his goal is to create a breakthrough in Data Science and Deep Learning.</p> <ul> <li>Linkedin Profile</li> </ul>"},{"location":"team/#community-contributors","title":"Community Contributors","text":""},{"location":"team/#agam-kumar","title":"Agam Kumar","text":"About <p>Agam is a junior at Carnegie Mellon University studying Statistics and Machine Learning and pursuing an additional major in Computer Science. He is a member of the Data Science team in the Health and Human Performance Lab at CMU and has keen interests in software development and data science. His research interests include ML applications in medicine.</p> <ul> <li>Linkedin Profile</li> <li>Github Profile</li> </ul>"},{"location":"team/#yasaman-s-sefidgar","title":"Yasaman S. Sefidgar","text":"About <ul> <li>Linkedin Profile</li> </ul>"},{"location":"team/#joe-kim","title":"Joe Kim","text":"About <ul> <li>Personal Website</li> </ul>"},{"location":"team/#brinnae-bent","title":"Brinnae Bent","text":"About <ul> <li>Personal Website</li> </ul>"},{"location":"team/#stephen-price","title":"Stephen Price","text":"About <p>Carnegie Mellon University</p>"},{"location":"team/#neil-singh","title":"Neil Singh","text":"About <p>University of Virginia</p>"},{"location":"team/#advisors","title":"Advisors","text":""},{"location":"team/#afsaneh-doryab","title":"Afsaneh Doryab","text":"About <ul> <li>Personal Website</li> </ul>"},{"location":"team/#carissa-low","title":"Carissa Low","text":"About <ul> <li>Profile</li> </ul>"},{"location":"datastreams/add-new-data-streams/","title":"Add New Data Streams","text":"<p>A data stream is a set of sensor data collected using a specific type of device with a specific format and stored in a specific container. RAPIDS is agnostic to data streams\u2019 formats and container; see the Data Streams Introduction for a list of supported streams.</p> <p>A container is queried with an R or Python script that connects to the database, API or file where your stream\u2019s raw data is stored. </p> <p>A format is described using a <code>format.yaml</code> file that specifies how to map and mutate your stream\u2019s raw data to match the data and format RAPIDS needs.</p> <p>The most common cases when you would want to implement a new data stream are:</p> <ul> <li>You collected data with a mobile sensing app RAPIDS does not support yet. For example, Beiwe data stored in MySQL. You will need to define a new format file and a new container script.</li> <li>You collected data with a mobile sensing app RAPIDS supports, but this data is stored in a container that RAPIDS can\u2019t connect to yet. For example, AWARE data stored in PostgreSQL. In this case, you can reuse the format file of the <code>aware_mysql</code> stream, but you will need to implement a new container script.</li> </ul> <p>Hint</p> <p>Both the <code>container.[R|py]</code> and the <code>format.yaml</code> are stored in <code>./src/data/streams/[stream_name]</code> where <code>[stream_name]</code> can be <code>aware_mysql</code> for example.</p>"},{"location":"datastreams/add-new-data-streams/#implement-a-container","title":"Implement a Container","text":"<p>The <code>container</code> script of a data stream can be implemented in R (strongly recommended) or python. This script must have two functions if you are implementing a stream for phone data or one function otherwise. The script can contain other auxiliary functions.</p> <p>First of all, add any parameters your script might need in <code>config.yaml</code> under <code>(device)_DATA_STREAMS</code>. These parameters will be available in the <code>stream_parameters</code> argument of the one or two functions you implement.  For example, if you are adding support for <code>Beiwe</code> data stored in <code>PostgreSQL</code> and your container needs a set of credentials to connect to a database, your new data stream configuration would be:</p> <pre><code>PHONE_DATA_STREAMS:\n  USE: aware_python\n\n  # AVAILABLE:\n  aware_mysql: \n    DATABASE_GROUP: MY_GROUP\n  beiwe_postgresql: \n    DATABASE_GROUP: MY_GROUP # users define this group (user, password, host, etc.) in credentials.yaml\n</code></pre> <p>Then implement one or both of the following functions:</p> pull_data <p>This function returns the data columns for a specific sensor and participant. It has the following parameters:</p> Param Description stream_parameters Any parameters (keys/values) set by the user in any <code>[DEVICE_DATA_STREAMS][stream_name]</code> key of <code>config.yaml</code>. For example, <code>[DATABASE_GROUP]</code> inside <code>[FITBIT_DATA_STREAMS][fitbitjson_mysql]</code> sensor_container The value set by the user in any <code>[DEVICE_SENSOR][CONTAINER]</code> key of <code>config.yaml</code>. It can be a table, file path, or whatever data source you want to support that contains the data from a single sensor for all participants. For example, <code>[PHONE_ACCELEROMETER][CONTAINER]</code> device The device id that you need to get the data for (this is set by the user in the participant files). For example, in AWARE this device id is a uuid columns A list of the columns that you need to get from <code>sensor_container</code>. You specify these columns in your stream\u2019s <code>format.yaml</code> <p>Example</p> <p>This is the <code>pull_data</code> function we implemented for <code>aware_mysql</code>. Note that we can <code>message</code>, <code>warn</code> or <code>stop</code> the user during execution.</p> <pre><code>pull_data &lt;- function(stream_parameters, device, sensor_container, columns){\n    # get_db_engine is an auxiliary function not shown here for brevity bu can be found in src/data/streams/aware_mysql/container.R\n    dbEngine &lt;- get_db_engine(stream_parameters$DATABASE_GROUP)\n    query &lt;- paste0(\"SELECT \", paste(columns, collapse = \",\"),\" FROM \", sensor_container, \" WHERE device_id = '\", device,\"'\")\n    # Letting the user know what we are doing\n    message(paste0(\"Executing the following query to download data: \", query)) \n    sensor_data &lt;- dbGetQuery(dbEngine, query)\n\n    dbDisconnect(dbEngine)\n\n    if(nrow(sensor_data) == 0)\n        warning(paste(\"The device '\", device,\"' did not have data in \", sensor_container))\n\n    return(sensor_data)\n}\n</code></pre> infer_device_os <p>Warning</p> <p>This function is only necessary for phone data streams. </p> <p>RAPIDS allows users to use the keyword <code>infer</code> (previously <code>multiple</code>) to automatically infer the mobile Operative System a phone was running. </p> <p>If you have a way to infer the OS of a device id, implement this function. For example, for AWARE data we use the <code>aware_device</code> table.</p> <p>If you don\u2019t have a way to infer the OS, call <code>stop(\"Error Message\")</code> so other users know they can\u2019t use <code>infer</code> or the inference failed, and they have to assign the OS manually in the participant file.</p> <p>This function returns the operative system (<code>android</code> or <code>ios</code>) for a specific phone device id. It has the following parameters:</p> Param Description stream_parameters Any parameters (keys/values) set by the user in any <code>[DEVICE_DATA_STREAMS][stream_name]</code> key of <code>config.yaml</code>. For example, <code>[DATABASE_GROUP]</code> inside <code>[FITBIT_DATA_STREAMS][fitbitjson_mysql]</code> device The device id that you need to infer the OS for (this is set by the user in the participant files). For example, in AWARE this device id is a uuid <p>Example</p> <p>This is the <code>infer_device_os</code> function we implemented for <code>aware_mysql</code>. Note that we can <code>message</code>, <code>warn</code> or <code>stop</code> the user during execution.</p> <pre><code>infer_device_os &lt;- function(stream_parameters, device){\n    # get_db_engine is an auxiliary function not shown here for brevity bu can be found in src/data/streams/aware_mysql/container.R\n    group &lt;- stream_parameters$DATABASE_GROUP\n\n    dbEngine &lt;- dbConnect(MariaDB(), default.file = \"./.env\", group = group)\n    query &lt;- paste0(\"SELECT device_id,brand FROM aware_device WHERE device_id = '\", device, \"'\")\n    message(paste0(\"Executing the following query to infer phone OS: \", query)) \n    os &lt;- dbGetQuery(dbEngine, query)\n    dbDisconnect(dbEngine)\n\n    if(nrow(os) &gt; 0)\n        return(os %&gt;% mutate(os = ifelse(brand == \"iPhone\", \"ios\", \"android\")) %&gt;% pull(os))\n    else\n        stop(paste(\"We cannot infer the OS of the following device id because it does not exist in the aware_device table:\", device))\n\n    return(os)\n}\n</code></pre>"},{"location":"datastreams/add-new-data-streams/#implement-a-format","title":"Implement a Format","text":"<p>A format file <code>format.yaml</code> describes the mapping between your stream\u2019s raw data and the data that RAPIDS needs. This file has a section per sensor (e.g. <code>PHONE_ACCELEROMETER</code>), and each section has two attributes (keys):</p> <ol> <li> <p><code>RAPIDS_COLUMN_MAPPINGS</code> are mappings between the columns RAPIDS needs and the columns your raw data already has. </p> <ol> <li>The reserved keyword <code>FLAG_TO_MUTATE</code> flags columns that RAPIDS requires but that are not initially present in your container (database, CSV file). These columns have to be created by your mutation scripts.</li> </ol> </li> <li> <p><code>MUTATION</code>. Sometimes your raw data needs to be transformed to match the format RAPIDS can handle (including creating columns marked as <code>FLAG_TO_MUTATE</code>)</p> <ol> <li> <p><code>COLUMN_MAPPINGS</code> are mappings between the columns a mutation <code>SCRIPT</code> needs and the columns your raw data has.</p> </li> <li> <p><code>SCRIPTS</code> are a collection of R or Python scripts that transform one or more raw data columns into the format RAPIDS needs.</p> </li> </ol> </li> </ol> <p>Hint</p> <p><code>[RAPIDS_COLUMN_MAPPINGS]</code> and <code>[MUTATE][COLUMN_MAPPINGS]</code> have a <code>key</code> (left-hand side string) and a <code>value</code> (right-hand side string). The <code>values</code> are the names used to pulled columns from a container (e.g., columns in a database table). All <code>values</code> are renamed to their <code>keys</code> in lower case. The renamed columns are sent to every mutation script within the <code>data</code> argument, and the final output is the input RAPIDS process further.</p> <p>For example, let\u2019s assume we are implementing <code>beiwe_mysql</code> and defining the following format for <code>PHONE_FAKESENSOR</code>:</p> <pre><code>PHONE_FAKESENSOR:\n    ANDROID:\n        RAPIDS_COLUMN_MAPPINGS:\n            TIMESTAMP: beiwe_timestamp\n            DEVICE_ID: beiwe_deviceID\n            MAGNITUDE_SQUARED: FLAG_TO_MUTATE\n        MUTATE:\n            COLUMN_MAPPINGS:\n                MAGNITUDE: beiwe_value\n            SCRIPTS:\n              - src/data/streams/mutations/phone/square_magnitude.py\n</code></pre> <p>RAPIDS will:</p> <ol> <li>Download <code>beiwe_timestamp</code>, <code>beiwe_deviceID</code>, and <code>beiwe_value</code> from the container of <code>beiwe_mysql</code> (MySQL DB)</li> <li>Rename these columns to <code>timestamp</code>, <code>device_id</code>, and <code>magnitude</code>, respectively.</li> <li>Execute <code>square_magnitude.py</code> with a data frame as an argument containing the renamed columns. This script will square <code>magnitude</code> and rename it to <code>magnitude_squared</code></li> <li>Verify the data frame returned by <code>square_magnitude.py</code> has the columns RAPIDS needs <code>timestamp</code>, <code>device_id</code>, and <code>magnitude_squared</code>.</li> <li>Use this data frame as the input to be processed in the pipeline.</li> </ol> <p>Note that although <code>RAPIDS_COLUMN_MAPPINGS</code> and <code>[MUTATE][COLUMN_MAPPINGS]</code> keys are in capital letters for readability (e.g. <code>MAGNITUDE_SQUARED</code>), the names of the final columns you mutate in your scripts should be lower case.</p> <p>Let\u2019s explain in more depth this column mapping with examples.</p>"},{"location":"datastreams/add-new-data-streams/#name-mapping","title":"Name mapping","text":"<p>The mapping for some sensors is straightforward. For example, accelerometer data most of the time has a timestamp, three axes (x,y,z), and a device id that produced it. AWARE and a different sensing app like Beiwe likely logged accelerometer data in the same way but with different column names. In this case, we only need to match Beiwe data columns to RAPIDS columns one-to-one:</p> <pre><code>PHONE_ACCELEROMETER:\n  ANDROID:\n    RAPIDS_COLUMN_MAPPINGS:\n      TIMESTAMP: beiwe_timestamp\n      DEVICE_ID: beiwe_deviceID\n      DOUBLE_VALUES_0: beiwe_x\n      DOUBLE_VALUES_1: beiwe_y\n      DOUBLE_VALUES_2: beiwe_z\n    MUTATE:\n      COLUMN_MAPPINGS:\n      SCRIPTS: # it's ok if this is empty\n</code></pre>"},{"location":"datastreams/add-new-data-streams/#value-mapping","title":"Value mapping","text":"<p>For some sensors, we need to map column names and values. For example, screen data has ON and OFF events; let\u2019s suppose Beiwe represents an ON event with the number <code>1,</code> but RAPIDS identifies ON events with the number <code>2</code>. In this case, we need to mutate the raw data coming from Beiwe and replace all <code>1</code>s with <code>2</code>s.</p> <p>We do this by listing one or more R or Python scripts in <code>MUTATION_SCRIPTS</code> that will be executed in order. We usually store all mutation scripts under <code>src/data/streams/mutations/[device]/[platform]/</code> and they can be reused across data streams.</p> <pre><code>PHONE_SCREEN:\n  ANDROID:\n    RAPIDS_COLUMN_MAPPINGS:\n      TIMESTAMP: beiwe_timestamp\n      DEVICE_ID: beiwe_deviceID\n      EVENT: beiwe_event\n     MUTATE:\n      COLUMN_MAPPINGS:\n      SCRIPTS:\n        - src/data/streams/mutations/phone/beiwe/beiwe_screen_map.py\n</code></pre> <p>Hint</p> <ul> <li>A <code>MUTATION_SCRIPT</code> can also be used to clean/preprocess your data before extracting behavioral features.</li> <li>A mutation script has to have a <code>main</code> function that receives two arguments, <code>data</code> and <code>stream_parameters</code>.</li> <li>The <code>stream_parameters</code> argument contains the <code>config.yaml</code> key/values of your data stream (this is the same argument that your <code>container.[py|R]</code> script receives, see Implement a Container). </li> </ul> python <p>Example of a python mutation script <pre><code>import pandas as pd\n\ndef main(data, stream_parameters):\n    # mutate data\n    return(data)\n</code></pre></p> R <p>Example of a R mutation script <pre><code>source(\"renv/activate.R\") # needed to use RAPIDS renv environment\nlibrary(dplyr)\n\nmain &lt;- function(data, stream_parameters){\n    # mutate data\n    return(data)\n}\n</code></pre></p>"},{"location":"datastreams/add-new-data-streams/#complex-mapping","title":"Complex mapping","text":"<p>Sometimes, your raw data doesn\u2019t even have the same columns RAPIDS expects for a sensor. For example, let\u2019s pretend Beiwe stores <code>PHONE_ACCELEROMETER</code> axis data in a single column called <code>acc_col</code> instead of three. You have to create a <code>MUTATION_SCRIPT</code> to split <code>acc_col</code> into three columns <code>x</code>, <code>y</code>, and <code>z</code>. </p> <p>For this, you mark the three axes columns RAPIDS needs in <code>[RAPIDS_COLUMN_MAPPINGS]</code> with the word <code>FLAG_TO_MUTATE</code>, map <code>acc_col</code> in <code>[MUTATION][COLUMN_MAPPINGS]</code>, and list a Python script under <code>[MUTATION][SCRIPTS]</code> with the code to split <code>acc_col</code>. See an example below.</p> <p>RAPIDS expects that every column mapped as <code>FLAG_TO_MUTATE</code> will be generated by your mutation script, so it won\u2019t try to retrieve them from your container (database, CSV file, etc.). </p> <p>In our example, <code>acc_col</code> will be fetched from the stream\u2019s container and renamed to <code>JOINED_AXES</code> because <code>beiwe_split_acc.py</code> will split it into <code>double_values_0</code>, <code>double_values_1</code>, and <code>double_values_2</code>.</p> <pre><code>PHONE_ACCELEROMETER:\n  ANDROID:\n    RAPIDS_COLUMN_MAPPINGS:\n      TIMESTAMP: beiwe_timestamp\n      DEVICE_ID: beiwe_deviceID\n      DOUBLE_VALUES_0: FLAG_TO_MUTATE\n      DOUBLE_VALUES_1: FLAG_TO_MUTATE\n      DOUBLE_VALUES_2: FLAG_TO_MUTATE\n    MUTATE:\n      COLUMN_MAPPINGS:\n        JOINED_AXES: acc_col\n      SCRIPTS:\n        - src/data/streams/mutations/phone/beiwe/beiwe_split_acc.py\n</code></pre> <p>This is a draft of <code>beiwe_split_acc.py</code> <code>MUTATION_SCRIPT</code>: <pre><code>import pandas as pd\n\ndef main(data, stream_parameters):\n    # data has the acc_col\n    # split acc_col into three columns: double_values_0, double_values_1, double_values_2 to match RAPIDS format\n    # remove acc_col since we don't need it anymore\n    return(data)\n</code></pre></p>"},{"location":"datastreams/add-new-data-streams/#os-complex-mapping","title":"OS complex mapping","text":"<p>There is a special case for a complex mapping scenario for smartphone data streams. The Android and iOS sensor APIs return data in different formats for certain sensors (like screen, activity recognition, battery, among others). </p> <p>In case you didn\u2019t notice, the examples we have used so far are grouped under an <code>ANDROID</code> key, which means they will be applied to data collected by Android phones. Additionally, each sensor has an <code>IOS</code> key for a similar purpose. We use the complex mapping described above to transform iOS data into an Android format (it\u2019s always iOS to Android and any new phone data stream must do the same).</p> <p>For example, this is the <code>format.yaml</code> key for <code>PHONE_ACTVITY_RECOGNITION</code>. Note that the <code>ANDROID</code> mapping is simple (one-to-one) but the <code>IOS</code> mapping is complex with three <code>FLAG_TO_MUTATE</code> columns, two <code>[MUTATE][COLUMN_MAPPINGS]</code> mappings, and one <code>[MUTATION][SCRIPT]</code>.</p> <pre><code>PHONE_ACTIVITY_RECOGNITION:\n  ANDROID:\n    RAPIDS_COLUMN_MAPPINGS:\n      TIMESTAMP: timestamp\n      DEVICE_ID: device_id\n      ACTIVITY_TYPE: activity_type\n      ACTIVITY_NAME: activity_name\n      CONFIDENCE: confidence\n    MUTATION:\n      COLUMN_MAPPINGS:\n      SCRIPTS:\n  IOS:\n    RAPIDS_COLUMN_MAPPINGS:\n      TIMESTAMP: timestamp\n      DEVICE_ID: device_id\n      ACTIVITY_TYPE: FLAG_TO_MUTATE\n      ACTIVITY_NAME: FLAG_TO_MUTATE\n      CONFIDENCE: FLAG_TO_MUTATE\n    MUTATION:\n      COLUMN_MAPPINGS:\n        ACTIVITIES: activities\n        CONFIDENCE: confidence\n      SCRIPTS:\n        - \"src/data/streams/mutations/phone/aware/activity_recogniton_ios_unification.R\"\n</code></pre> Example activity_recogniton_ios_unification.R <p>In this <code>MUTATION_SCRIPT</code> we create <code>ACTIVITY_NAME</code> and <code>ACTIVITY_TYPE</code> based on <code>activities</code>, and map <code>confidence</code> iOS values to Android values. <pre><code>source(\"renv/activate.R\")\nlibrary(\"dplyr\", warn.conflicts = F)\nlibrary(stringr)\n\nclean_ios_activity_column &lt;- function(ios_gar){\n    ios_gar &lt;- ios_gar %&gt;%\n        mutate(activities = str_replace_all(activities, pattern = '(\"|\\\\[|\\\\])', replacement = \"\"))\n\n    existent_multiple_activities &lt;- ios_gar %&gt;%\n        filter(str_detect(activities, \",\")) %&gt;% \n        group_by(activities) %&gt;%\n        summarise(mutiple_activities = unique(activities), .groups = \"drop_last\") %&gt;% \n        pull(mutiple_activities)\n\n    known_multiple_activities &lt;- c(\"stationary,automotive\")\n    unkown_multiple_actvities &lt;- setdiff(existent_multiple_activities, known_multiple_activities)\n    if(length(unkown_multiple_actvities) &gt; 0){\n        stop(paste0(\"There are unkwown combinations of ios activities, you need to implement the decision of the ones to keep: \", unkown_multiple_actvities))\n    }\n\n    ios_gar &lt;- ios_gar %&gt;%\n        mutate(activities = str_replace_all(activities, pattern = \"stationary,automotive\", replacement = \"automotive\"))\n\n    return(ios_gar)\n}\n\nunify_ios_activity_recognition &lt;- function(ios_gar){\n    # We only need to unify Google Activity Recognition data for iOS\n    # discard rows where activities column is blank\n    ios_gar &lt;- ios_gar[-which(ios_gar$activities == \"\"), ]\n    # clean \"activities\" column of ios_gar\n    ios_gar &lt;- clean_ios_activity_column(ios_gar)\n\n    # make it compatible with android version: generate \"activity_name\" and \"activity_type\" columns\n    ios_gar  &lt;-  ios_gar %&gt;% \n        mutate(activity_name = case_when(activities == \"automotive\" ~ \"in_vehicle\",\n                                        activities == \"cycling\" ~ \"on_bicycle\",\n                                        activities == \"walking\" ~ \"walking\",\n                                        activities == \"running\" ~ \"running\",\n                                        activities == \"stationary\" ~ \"still\"),\n                activity_type = case_when(activities == \"automotive\" ~ 0,\n                                        activities == \"cycling\" ~ 1,\n                                        activities == \"walking\" ~ 7,\n                                        activities == \"running\" ~ 8,\n                                        activities == \"stationary\" ~ 3,\n                                        activities == \"unknown\" ~ 4),\n                confidence = case_when(confidence == 0 ~ 0,\n                                      confidence == 1 ~ 50,\n                                      confidence == 2 ~ 100)\n                                    ) %&gt;% \n        select(-activities)\n\n    return(ios_gar)\n}\n\nmain &lt;- function(data, stream_parameters){\n    return(unify_ios_activity_recognition(data, stream_parameters))\n}\n</code></pre></p>"},{"location":"datastreams/aware-csv/","title":"<code>aware_csv</code>","text":"<p>This data stream handles iOS and Android sensor data collected with the AWARE Framework and stored in CSV files.</p> <p>Warning</p> <p>The CSV files have to use <code>,</code> as separator, <code>\\</code> as escape character (do not escape <code>\"</code> with <code>\"\"</code>), and wrap any string columns with <code>\"</code>.</p> <p>See examples in the CSV files inside rapids_example_csv.zip</p> Example of a valid CSV file <pre><code>\"_id\",\"timestamp\",\"device_id\",\"activities\",\"confidence\",\"stationary\",\"walking\",\"running\",\"automotive\",\"cycling\",\"unknown\",\"label\"\n1,1587528000000,\"13dbc8a3-dae3-4834-823a-4bc96a7d459d\",\"[\\\"stationary\\\"]\",2,1,0,0,0,0,0,\"\"\n2,1587528060000,\"13dbc8a3-dae3-4834-823a-4bc96a7d459d\",\"[\\\"stationary\\\"]\",2,1,0,0,0,0,0,\"supplement\"\n3,1587528120000,\"13dbc8a3-dae3-4834-823a-4bc96a7d459d\",\"[\\\"stationary\\\"]\",2,1,0,0,0,0,0,\"supplement\"\n4,1587528180000,\"13dbc8a3-dae3-4834-823a-4bc96a7d459d\",\"[\\\"stationary\\\"]\",2,1,0,0,0,0,0,\"supplement\"\n5,1587528240000,\"13dbc8a3-dae3-4834-823a-4bc96a7d459d\",\"[\\\"stationary\\\"]\",2,1,0,0,0,0,0,\"supplement\"\n6,1587528300000,\"13dbc8a3-dae3-4834-823a-4bc96a7d459d\",\"[\\\"stationary\\\"]\",2,1,0,0,0,0,0,\"supplement\"\n7,1587528360000,\"13dbc8a3-dae3-4834-823a-4bc96a7d459d\",\"[\\\"stationary\\\"]\",2,1,0,0,0,0,0,\"supplement\"\n</code></pre>"},{"location":"datastreams/aware-csv/#container","title":"Container","text":"<p>A CSV file per sensor, each containing the data for all participants. </p> <p>The script to connect and download data from this container is at: <pre><code>src/data/streams/aware_csv/container.R\n</code></pre></p>"},{"location":"datastreams/aware-csv/#format","title":"Format","text":"<p>If you collected sensor data with the vanilla (original) AWARE mobile clients, you shouldn\u2019t need to modify this format (described below). </p> <p>Remember that a format maps and transforms columns in your raw data stream to the mandatory columns RAPIDS needs.</p> <p>The yaml file that describes the format of this data stream is at: <pre><code>src/data/streams/aware_csv/format.yaml\n</code></pre></p> <p>For some sensors, we need to transform iOS data into Android format; you can refer to OS complex mapping for learn how this works.</p> <p>Hint</p> <p>The mappings in this stream (RAPIDS/Stream) are the same names because AWARE data was the first stream RAPIDS supported, meaning that it considers AWARE column names the default.</p> PHONE_ACCELEROMETER ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_VALUES_0 double_values_0 DOUBLE_VALUES_1 double_values_1 DOUBLE_VALUES_2 double_values_2 <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_ACTIVITY_RECOGNITION ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id ACTIVITY_NAME activity_name ACTIVITY_TYPE activity_type CONFIDENCE confidence <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id ACTIVITY_NAME FLAG_TO_MUTATE ACTIVITY_TYPE FLAG_TO_MUTATE CONFIDENCE FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column ACTIVITIES activities CONFIDENCE confidence <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/activity_recogniton_ios_unification.R\n</code></pre> <p>Note</p> <p>For RAPIDS columns of <code>ACTIVITY_NAME</code> and <code>ACTIVITY_TYPE</code>:</p> <ul> <li>if stream\u2019s <code>activities</code> field is automotive, set <code>ACTIVITY_NAME</code> = in_vehicle and <code>ACTIVITY_TYPE</code> = 0</li> <li>if stream\u2019s <code>activities</code> field is cycling, set <code>ACTIVITY_NAME</code> = on_bicycle and <code>ACTIVITY_TYPE</code> = 1</li> <li>if stream\u2019s <code>activities</code> field is walking, set <code>ACTIVITY_NAME</code> = walking and <code>ACTIVITY_TYPE</code> = 7</li> <li>if stream\u2019s <code>activities</code> field is running, set <code>ACTIVITY_NAME</code> = running and <code>ACTIVITY_TYPE</code> = 8</li> <li>if stream\u2019s <code>activities</code> field is stationary, set <code>ACTIVITY_NAME</code> = still and <code>ACTIVITY_TYPE</code> = 3</li> <li>if stream\u2019s <code>activities</code> field is unknown, set <code>ACTIVITY_NAME</code> = unknown and  <code>ACTIVITY_TYPE</code> = 4</li> </ul> <p>For RAPIDS <code>CONFIDENCE</code> column:</p> <ul> <li>if stream\u2019s <code>confidence</code> field is 0, set <code>CONFIDENCE</code> = 0</li> <li>if stream\u2019s <code>confidence</code> field is 1, set <code>CONFIDENCE</code> = 50</li> <li>if stream\u2019s <code>confidence</code> field is 2, set <code>CONFIDENCE</code> = 100</li> </ul> PHONE_APPLICATIONS_CRASHES ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name APPLICATION_NAME application_name APPLICATION_VERSION application_version ERROR_SHORT error_short ERROR_LONG error_long ERROR_CONDITION error_condition IS_SYSTEM_APP is_system_app <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_APPLICATIONS_FOREGROUND ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name APPLICATION_NAME application_name IS_SYSTEM_APP is_system_app <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_APPLICATIONS_NOTIFICATIONS ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name APPLICATION_NAME application_name TEXT text SOUND sound VIBRATE vibrate DEFAULTS defaults FLAGS flags <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_BATTERY ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BATTERY_STATUS battery_status BATTERY_LEVEL battery_level BATTERY_SCALE battery_scale <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS Client V1 <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BATTERY_STATUS FLAG_TO_MUTATE BATTERY_LEVEL battery_level BATTERY_SCALE battery_scale <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column BATTERY_STATUS battery_status <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/battery_ios_unification.R\n</code></pre> <p>Note</p> <p>For RAPIDS <code>BATTERY_STATUS</code> column:</p> <ul> <li>if stream\u2019s <code>battery_status</code> field is 3, set <code>BATTERY_STATUS</code> = 5 (full status)</li> <li>if stream\u2019s <code>battery_status</code> field is 1, set <code>BATTERY_STATUS</code> = 3 (discharge)</li> </ul> IOS Client V2 <p>Same as ANDROID</p> PHONE_BLUETOOTH ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BT_ADDRESS bt_address BT_NAME bt_name BT_RSSI bt_rssi <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Only old iOS versions supported this sensor (same mapping as Android).</p> PHONE_CALLS ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id CALL_TYPE call_type CALL_DURATION call_duration TRACE trace <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id CALL_TYPE FLAG_TO_MUTATE CALL_DURATION call_duration TRACE trace <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column CALL_TYPE call_type <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/calls_ios_unification.R\n</code></pre> <p>Note</p> <p>We transform iOS call logs into Android\u2019s format. iOS stores call status: 1=incoming, 2=connected, 3=dialing, 4=disconnected, as opposed to Android\u2019s events: 1=incoming, 2=outgoing, 3=missed. </p> <p>We follow this algorithm to convert iOS call data (there are some inaccuracies in the way we handle sequences, see new rules below):</p> <ul> <li>Search for the disconnected (4) status as it is common to all calls</li> <li>Group all events that preceded every status 4</li> <li>We convert every 1,2,4 (or 2,1,4) sequence to an incoming call</li> <li>We convert every 3,2,4 (or 2,3,4) sequence to an outgoing call</li> <li>We convert every 1,4 or 3,4 sequence to a missed call (either incoming or outgoing)</li> <li>We set the duration of the call to be the sum of every status (dialing/ringing to hangup) as opposed to the duration of the last status (pick up to hang up)</li> </ul> <p>Tested with an Android (OnePlus 7T) and an iPhone XR</p> Call type Android (duration) iOS (duration) New Rule Outgoing missed ended by me 2 (0) 3,4 (0,X) 3,4 is converted to 2 with duration 0 Outgoing missed ended by them 2(0) 3,2,4 (0,X,X2) 3,2,4 is converted to 2 with duration X2* Incoming missed ended by me NA** 1,4 (0,X) 1,4 is converted to 3 with duration 0 Incoming missed ended by them 3(0) 1,4 (0,X) 1,4 is converted to 3 with duration 0 Outgoing answered 2(X excluding dialing time) 3,2,4 (0,X,X2) 3,2,4 is converted to 2 with duration X2 Incoming answered 1(X excluding dialing time) 1,2,4 (0,X,X2) 1,2,4 is converted to 1 with duration X2 <p>.* There is no way to differentiate an outgoing missed call ended by them from an outgoing answered call because the phone goes directly to voice mail and it counts as call time (essentially the voice mail answered).</p> <p>.** Android does not record incoming missed calls ended by the participant, just those ended by the person calling or ignored by the participant.</p> PHONE_CONVERSATION ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_ENERGY double_energy INFERENCE inference DOUBLE_CONVO_START double_convo_start DOUBLE_CONVO_END double_convo_end <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_ENERGY double_energy INFERENCE inference DOUBLE_CONVO_START FLAG_TO_MUTATE DOUBLE_CONVO_END FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column DOUBLE_CONVO_START double_convo_start DOUBLE_CONVO_END double_convo_end <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/conversation_ios_timestamp.R\n</code></pre> <p>Note</p> <p>For RAPIDS columns of <code>DOUBLE_CONVO_START</code> and <code>DOUBLE_CONVO_END</code>:</p> <ul> <li>if stream\u2019s <code>double_convo_start</code> field is smaller than 9999999999, it is in seconds instead of milliseconds. Set <code>DOUBLE_CONVO_START</code> = 1000 * <code>double_convo_start</code>.</li> <li>if stream\u2019s <code>double_convo_end</code> field is smaller than 9999999999, it is in seconds instead of milliseconds. Set <code>DOUBLE_CONVO_END</code> = 1000 * <code>double_convo_end</code>.</li> </ul> PHONE_KEYBOARD ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name BEFORE_TEXT before_text CURRENT_TEXT current_text IS_PASSWORD is_password <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_LIGHT ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_LIGHT_LUX double_light_lux ACCURACY accuracy <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_LOCATIONS ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_LATITUDE double_latitude DOUBLE_LONGITUDE double_longitude DOUBLE_BEARING double_bearing DOUBLE_SPEED double_speed DOUBLE_ALTITUDE double_altitude PROVIDER provider ACCURACY accuracy <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_LOG ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id LOG_MESSAGE log_message <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_MESSAGES ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id MESSAGE_TYPE message_type TRACE trace <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_SCREEN ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id SCREEN_STATUS screen_status <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id SCREEN_STATUS FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column SCREEN_STATUS screen_status <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/screen_ios_unification.R\n</code></pre> <p>Note</p> <p>For <code>SCREEN_STATUS</code> RAPIDS column:</p> <ul> <li>if stream\u2019s <code>screen_status</code> field is 2 (lock episode), set <code>SCREEN_STATUS</code> = 0 (off episode).</li> </ul> PHONE_WIFI_CONNECTED ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id MAC_ADDRESS mac_address SSID ssid BSSID bssid <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_WIFI_VISIBLE ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id SSID ssid BSSID bssid SECURITY security FREQUENCY frequency RSSI rssi <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Only old iOS versions supported this sensor (same mapping as Android).</p>"},{"location":"datastreams/aware-influxdb/","title":"<code>aware_influxdb (beta)</code>","text":"<p>Warning</p> <p>This data stream is being released in beta while we test it thoroughly. </p> <p>This data stream handles iOS and Android sensor data collected with the AWARE Framework and stored in an InfluxDB database.</p>"},{"location":"datastreams/aware-influxdb/#container","title":"Container","text":"<p>An InfluxDB database with a table per sensor, each containing the data for all participants.</p> <p>The script to connect and download data from this container is at: <pre><code>src/data/streams/aware_influxdb/container.R\n</code></pre></p>"},{"location":"datastreams/aware-influxdb/#format","title":"Format","text":"<p>If you collected sensor data with the vanilla (original) AWARE mobile clients, you shouldn\u2019t need to modify this format (described below). </p> <p>Remember that a format maps and transforms columns in your raw data stream to the mandatory columns RAPIDS needs.</p> <p>The yaml file that describes the format of this data stream is at: <pre><code>src/data/streams/aware_csv/format.yaml\n</code></pre></p> <p>For some sensors, we need to transform iOS data into Android format; you can refer to OS complex mapping for learn how this works.</p> <p>Hint</p> <p>The mappings in this stream (RAPIDS/Stream) are the same names because AWARE data was the first stream RAPIDS supported, meaning that it considers AWARE column names the default.</p> PHONE_ACCELEROMETER ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_VALUES_0 double_values_0 DOUBLE_VALUES_1 double_values_1 DOUBLE_VALUES_2 double_values_2 <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_ACTIVITY_RECOGNITION ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id ACTIVITY_NAME activity_name ACTIVITY_TYPE activity_type CONFIDENCE confidence <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id ACTIVITY_NAME FLAG_TO_MUTATE ACTIVITY_TYPE FLAG_TO_MUTATE CONFIDENCE FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column ACTIVITIES activities CONFIDENCE confidence <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/activity_recogniton_ios_unification.R\n</code></pre> <p>Note</p> <p>For RAPIDS columns of <code>ACTIVITY_NAME</code> and <code>ACTIVITY_TYPE</code>:</p> <ul> <li>if stream\u2019s <code>activities</code> field is automotive, set <code>ACTIVITY_NAME</code> = in_vehicle and <code>ACTIVITY_TYPE</code> = 0</li> <li>if stream\u2019s <code>activities</code> field is cycling, set <code>ACTIVITY_NAME</code> = on_bicycle and <code>ACTIVITY_TYPE</code> = 1</li> <li>if stream\u2019s <code>activities</code> field is walking, set <code>ACTIVITY_NAME</code> = walking and <code>ACTIVITY_TYPE</code> = 7</li> <li>if stream\u2019s <code>activities</code> field is running, set <code>ACTIVITY_NAME</code> = running and <code>ACTIVITY_TYPE</code> = 8</li> <li>if stream\u2019s <code>activities</code> field is stationary, set <code>ACTIVITY_NAME</code> = still and <code>ACTIVITY_TYPE</code> = 3</li> <li>if stream\u2019s <code>activities</code> field is unknown, set <code>ACTIVITY_NAME</code> = unknown and  <code>ACTIVITY_TYPE</code> = 4</li> </ul> <p>For RAPIDS <code>CONFIDENCE</code> column:</p> <ul> <li>if stream\u2019s <code>confidence</code> field is 0, set <code>CONFIDENCE</code> = 0</li> <li>if stream\u2019s <code>confidence</code> field is 1, set <code>CONFIDENCE</code> = 50</li> <li>if stream\u2019s <code>confidence</code> field is 2, set <code>CONFIDENCE</code> = 100</li> </ul> PHONE_APPLICATIONS_CRASHES ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name APPLICATION_NAME application_name APPLICATION_VERSION application_version ERROR_SHORT error_short ERROR_LONG error_long ERROR_CONDITION error_condition IS_SYSTEM_APP is_system_app <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_APPLICATIONS_FOREGROUND ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name APPLICATION_NAME application_name IS_SYSTEM_APP is_system_app <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_APPLICATIONS_NOTIFICATIONS ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name APPLICATION_NAME application_name TEXT text SOUND sound VIBRATE vibrate DEFAULTS defaults FLAGS flags <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_BATTERY ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BATTERY_STATUS battery_status BATTERY_LEVEL battery_level BATTERY_SCALE battery_scale <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS Client V1 <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BATTERY_STATUS FLAG_TO_MUTATE BATTERY_LEVEL battery_level BATTERY_SCALE battery_scale <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column BATTERY_STATUS battery_status <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/battery_ios_unification.R\n</code></pre> <p>Note</p> <p>For RAPIDS <code>BATTERY_STATUS</code> column:</p> <ul> <li>if stream\u2019s <code>battery_status</code> field is 3, set <code>BATTERY_STATUS</code> = 5 (full status)</li> <li>if stream\u2019s <code>battery_status</code> field is 1, set <code>BATTERY_STATUS</code> = 3 (discharge)</li> </ul> IOS Client V2 <p>Same as ANDROID</p> PHONE_BLUETOOTH ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BT_ADDRESS bt_address BT_NAME bt_name BT_RSSI bt_rssi <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Only old iOS versions supported this sensor (same mapping as Android).</p> PHONE_CALLS ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id CALL_TYPE call_type CALL_DURATION call_duration TRACE trace <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id CALL_TYPE FLAG_TO_MUTATE CALL_DURATION call_duration TRACE trace <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column CALL_TYPE call_type <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/calls_ios_unification.R\n</code></pre> <p>Note</p> <p>We transform iOS call logs into Android\u2019s format. iOS stores call status: 1=incoming, 2=connected, 3=dialing, 4=disconnected, as opposed to Android\u2019s events: 1=incoming, 2=outgoing, 3=missed. </p> <p>We follow this algorithm to convert iOS call data (there are some inaccuracies in the way we handle sequences, see new rules below):</p> <ul> <li>Search for the disconnected (4) status as it is common to all calls</li> <li>Group all events that preceded every status 4</li> <li>We convert every 1,2,4 (or 2,1,4) sequence to an incoming call</li> <li>We convert every 3,2,4 (or 2,3,4) sequence to an outgoing call</li> <li>We convert every 1,4 or 3,4 sequence to a missed call (either incoming or outgoing)</li> <li>We set the duration of the call to be the sum of every status (dialing/ringing to hangup) as opposed to the duration of the last status (pick up to hang up)</li> </ul> <p>Tested with an Android (OnePlus 7T) and an iPhone XR</p> Call type Android (duration) iOS (duration) New Rule Outgoing missed ended by me 2 (0) 3,4 (0,X) 3,4 is converted to 2 with duration 0 Outgoing missed ended by them 2(0) 3,2,4 (0,X,X2) 3,2,4 is converted to 2 with duration X2* Incoming missed ended by me NA** 1,4 (0,X) 1,4 is converted to 3 with duration 0 Incoming missed ended by them 3(0) 1,4 (0,X) 1,4 is converted to 3 with duration 0 Outgoing answered 2(X excluding dialing time) 3,2,4 (0,X,X2) 3,2,4 is converted to 2 with duration X2 Incoming answered 1(X excluding dialing time) 1,2,4 (0,X,X2) 1,2,4 is converted to 1 with duration X2 <p>.* There is no way to differentiate an outgoing missed call ended by them from an outgoing answered call because the phone goes directly to voice mail and it counts as call time (essentially the voice mail answered).</p> <p>.** Android does not record incoming missed calls ended by the participant, just those ended by the person calling or ignored by the participant.</p> PHONE_CONVERSATION ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_ENERGY double_energy INFERENCE inference DOUBLE_CONVO_START double_convo_start DOUBLE_CONVO_END double_convo_end <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_ENERGY double_energy INFERENCE inference DOUBLE_CONVO_START FLAG_TO_MUTATE DOUBLE_CONVO_END FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column DOUBLE_CONVO_START double_convo_start DOUBLE_CONVO_END double_convo_end <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/conversation_ios_timestamp.R\n</code></pre> <p>Note</p> <p>For RAPIDS columns of <code>DOUBLE_CONVO_START</code> and <code>DOUBLE_CONVO_END</code>:</p> <ul> <li>if stream\u2019s <code>double_convo_start</code> field is smaller than 9999999999, it is in seconds instead of milliseconds. Set <code>DOUBLE_CONVO_START</code> = 1000 * <code>double_convo_start</code>.</li> <li>if stream\u2019s <code>double_convo_end</code> field is smaller than 9999999999, it is in seconds instead of milliseconds. Set <code>DOUBLE_CONVO_END</code> = 1000 * <code>double_convo_end</code>.</li> </ul> PHONE_KEYBOARD ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name BEFORE_TEXT before_text CURRENT_TEXT current_text IS_PASSWORD is_password <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_LIGHT ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_LIGHT_LUX double_light_lux ACCURACY accuracy <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_LOCATIONS ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_LATITUDE double_latitude DOUBLE_LONGITUDE double_longitude DOUBLE_BEARING double_bearing DOUBLE_SPEED double_speed DOUBLE_ALTITUDE double_altitude PROVIDER provider ACCURACY accuracy <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_LOG ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id LOG_MESSAGE log_message <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_MESSAGES ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id MESSAGE_TYPE message_type TRACE trace <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_SCREEN ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id SCREEN_STATUS screen_status <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id SCREEN_STATUS FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column SCREEN_STATUS screen_status <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/screen_ios_unification.R\n</code></pre> <p>Note</p> <p>For <code>SCREEN_STATUS</code> RAPIDS column:</p> <ul> <li>if stream\u2019s <code>screen_status</code> field is 2 (lock episode), set <code>SCREEN_STATUS</code> = 0 (off episode).</li> </ul> PHONE_WIFI_CONNECTED ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id MAC_ADDRESS mac_address SSID ssid BSSID bssid <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_WIFI_VISIBLE ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id SSID ssid BSSID bssid SECURITY security FREQUENCY frequency RSSI rssi <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Only old iOS versions supported this sensor (same mapping as Android).</p>"},{"location":"datastreams/aware-mysql/","title":"<code>aware_mysql</code>","text":"<p>This data stream handles iOS and Android sensor data collected with the AWARE Framework and stored in a MySQL database.</p>"},{"location":"datastreams/aware-mysql/#container","title":"Container","text":"<p>A MySQL database with a table per sensor, each containing the data for all participants. This is the default database created by the old PHP AWARE server (as opposed to the new JavaScript Micro server).</p> <p>The script to connect and download data from this container is at: <pre><code>src/data/streams/aware_mysql/container.R\n</code></pre></p>"},{"location":"datastreams/aware-mysql/#format","title":"Format","text":"<p>If you collected sensor data with the vanilla (original) AWARE mobile clients, you shouldn\u2019t need to modify this format (described below). </p> <p>Remember that a format maps and transforms columns in your raw data stream to the mandatory columns RAPIDS needs.</p> <p>The yaml file that describes the format of this data stream is at: <pre><code>src/data/streams/aware_csv/format.yaml\n</code></pre></p> <p>For some sensors, we need to transform iOS data into Android format; you can refer to OS complex mapping for learn how this works.</p> <p>Hint</p> <p>The mappings in this stream (RAPIDS/Stream) are the same names because AWARE data was the first stream RAPIDS supported, meaning that it considers AWARE column names the default.</p> PHONE_ACCELEROMETER ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_VALUES_0 double_values_0 DOUBLE_VALUES_1 double_values_1 DOUBLE_VALUES_2 double_values_2 <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_ACTIVITY_RECOGNITION ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id ACTIVITY_NAME activity_name ACTIVITY_TYPE activity_type CONFIDENCE confidence <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id ACTIVITY_NAME FLAG_TO_MUTATE ACTIVITY_TYPE FLAG_TO_MUTATE CONFIDENCE FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column ACTIVITIES activities CONFIDENCE confidence <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/activity_recogniton_ios_unification.R\n</code></pre> <p>Note</p> <p>For RAPIDS columns of <code>ACTIVITY_NAME</code> and <code>ACTIVITY_TYPE</code>:</p> <ul> <li>if stream\u2019s <code>activities</code> field is automotive, set <code>ACTIVITY_NAME</code> = in_vehicle and <code>ACTIVITY_TYPE</code> = 0</li> <li>if stream\u2019s <code>activities</code> field is cycling, set <code>ACTIVITY_NAME</code> = on_bicycle and <code>ACTIVITY_TYPE</code> = 1</li> <li>if stream\u2019s <code>activities</code> field is walking, set <code>ACTIVITY_NAME</code> = walking and <code>ACTIVITY_TYPE</code> = 7</li> <li>if stream\u2019s <code>activities</code> field is running, set <code>ACTIVITY_NAME</code> = running and <code>ACTIVITY_TYPE</code> = 8</li> <li>if stream\u2019s <code>activities</code> field is stationary, set <code>ACTIVITY_NAME</code> = still and <code>ACTIVITY_TYPE</code> = 3</li> <li>if stream\u2019s <code>activities</code> field is unknown, set <code>ACTIVITY_NAME</code> = unknown and  <code>ACTIVITY_TYPE</code> = 4</li> </ul> <p>For RAPIDS <code>CONFIDENCE</code> column:</p> <ul> <li>if stream\u2019s <code>confidence</code> field is 0, set <code>CONFIDENCE</code> = 0</li> <li>if stream\u2019s <code>confidence</code> field is 1, set <code>CONFIDENCE</code> = 50</li> <li>if stream\u2019s <code>confidence</code> field is 2, set <code>CONFIDENCE</code> = 100</li> </ul> PHONE_APPLICATIONS_CRASHES ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name APPLICATION_NAME application_name APPLICATION_VERSION application_version ERROR_SHORT error_short ERROR_LONG error_long ERROR_CONDITION error_condition IS_SYSTEM_APP is_system_app <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_APPLICATIONS_FOREGROUND ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name APPLICATION_NAME application_name IS_SYSTEM_APP is_system_app <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_APPLICATIONS_NOTIFICATIONS ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name APPLICATION_NAME application_name TEXT text SOUND sound VIBRATE vibrate DEFAULTS defaults FLAGS flags <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_BATTERY ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BATTERY_STATUS battery_status BATTERY_LEVEL battery_level BATTERY_SCALE battery_scale <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS Client V1 <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BATTERY_STATUS FLAG_TO_MUTATE BATTERY_LEVEL battery_level BATTERY_SCALE battery_scale <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column BATTERY_STATUS battery_status <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/battery_ios_unification.R\n</code></pre> <p>Note</p> <p>For RAPIDS <code>BATTERY_STATUS</code> column:</p> <ul> <li>if stream\u2019s <code>battery_status</code> field is 3, set <code>BATTERY_STATUS</code> = 5 (full status)</li> <li>if stream\u2019s <code>battery_status</code> field is 1, set <code>BATTERY_STATUS</code> = 3 (discharge)</li> </ul> IOS Client V2 <p>Same as ANDROID</p> PHONE_BLUETOOTH ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BT_ADDRESS bt_address BT_NAME bt_name BT_RSSI bt_rssi <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Only old iOS versions supported this sensor (same mapping as Android).</p> PHONE_CALLS ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id CALL_TYPE call_type CALL_DURATION call_duration TRACE trace <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id CALL_TYPE FLAG_TO_MUTATE CALL_DURATION call_duration TRACE trace <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column CALL_TYPE call_type <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/calls_ios_unification.R\n</code></pre> <p>Note</p> <p>We transform iOS call logs into Android\u2019s format. iOS stores call status: 1=incoming, 2=connected, 3=dialing, 4=disconnected, as opposed to Android\u2019s events: 1=incoming, 2=outgoing, 3=missed. </p> <p>We follow this algorithm to convert iOS call data (there are some inaccuracies in the way we handle sequences, see new rules below):</p> <ul> <li>Search for the disconnected (4) status as it is common to all calls</li> <li>Group all events that preceded every status 4</li> <li>We convert every 1,2,4 (or 2,1,4) sequence to an incoming call</li> <li>We convert every 3,2,4 (or 2,3,4) sequence to an outgoing call</li> <li>We convert every 1,4 or 3,4 sequence to a missed call (either incoming or outgoing)</li> <li>We set the duration of the call to be the sum of every status (dialing/ringing to hangup) as opposed to the duration of the last status (pick up to hang up)</li> </ul> <p>Tested with an Android (OnePlus 7T) and an iPhone XR</p> Call type Android (duration) iOS (duration) New Rule Outgoing missed ended by me 2 (0) 3,4 (0,X) 3,4 is converted to 2 with duration 0 Outgoing missed ended by them 2(0) 3,2,4 (0,X,X2) 3,2,4 is converted to 2 with duration X2* Incoming missed ended by me NA** 1,4 (0,X) 1,4 is converted to 3 with duration 0 Incoming missed ended by them 3(0) 1,4 (0,X) 1,4 is converted to 3 with duration 0 Outgoing answered 2(X excluding dialing time) 3,2,4 (0,X,X2) 3,2,4 is converted to 2 with duration X2 Incoming answered 1(X excluding dialing time) 1,2,4 (0,X,X2) 1,2,4 is converted to 1 with duration X2 <p>.* There is no way to differentiate an outgoing missed call ended by them from an outgoing answered call because the phone goes directly to voice mail and it counts as call time (essentially the voice mail answered).</p> <p>.** Android does not record incoming missed calls ended by the participant, just those ended by the person calling or ignored by the participant.</p> PHONE_CONVERSATION ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_ENERGY double_energy INFERENCE inference DOUBLE_CONVO_START double_convo_start DOUBLE_CONVO_END double_convo_end <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_ENERGY double_energy INFERENCE inference DOUBLE_CONVO_START FLAG_TO_MUTATE DOUBLE_CONVO_END FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column DOUBLE_CONVO_START double_convo_start DOUBLE_CONVO_END double_convo_end <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/conversation_ios_timestamp.R\n</code></pre> <p>Note</p> <p>For RAPIDS columns of <code>DOUBLE_CONVO_START</code> and <code>DOUBLE_CONVO_END</code>:</p> <ul> <li>if stream\u2019s <code>double_convo_start</code> field is smaller than 9999999999, it is in seconds instead of milliseconds. Set <code>DOUBLE_CONVO_START</code> = 1000 * <code>double_convo_start</code>.</li> <li>if stream\u2019s <code>double_convo_end</code> field is smaller than 9999999999, it is in seconds instead of milliseconds. Set <code>DOUBLE_CONVO_END</code> = 1000 * <code>double_convo_end</code>.</li> </ul> PHONE_KEYBOARD ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name BEFORE_TEXT before_text CURRENT_TEXT current_text IS_PASSWORD is_password <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_LIGHT ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_LIGHT_LUX double_light_lux ACCURACY accuracy <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_LOCATIONS ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_LATITUDE double_latitude DOUBLE_LONGITUDE double_longitude DOUBLE_BEARING double_bearing DOUBLE_SPEED double_speed DOUBLE_ALTITUDE double_altitude PROVIDER provider ACCURACY accuracy <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_LOG ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id LOG_MESSAGE log_message <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_MESSAGES ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id MESSAGE_TYPE message_type TRACE trace <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_SCREEN ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id SCREEN_STATUS screen_status <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id SCREEN_STATUS FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column SCREEN_STATUS screen_status <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/screen_ios_unification.R\n</code></pre> <p>Note</p> <p>For <code>SCREEN_STATUS</code> RAPIDS column:</p> <ul> <li>if stream\u2019s <code>screen_status</code> field is 2 (lock episode), set <code>SCREEN_STATUS</code> = 0 (off episode).</li> </ul> PHONE_WIFI_CONNECTED ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id MAC_ADDRESS mac_address SSID ssid BSSID bssid <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_WIFI_VISIBLE ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id SSID ssid BSSID bssid SECURITY security FREQUENCY frequency RSSI rssi <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Only old iOS versions supported this sensor (same mapping as Android).</p>"},{"location":"datastreams/data-streams-introduction/","title":"Data Streams Introduction","text":"<p>A data stream is a set of sensor data collected using a specific type of device with a specific format and stored in a specific container.</p> <p>For example, the <code>aware_mysql</code> data stream handles smartphone data (device) collected with the AWARE Framework (format) stored in a MySQL database (container). Similarly, smartphone data collected with Beiwe will have a different format and could be stored in a container like a PostgreSQL database or a CSV file.</p> <p>If you want to process a data stream using RAPIDS, make sure that your data is stored in a supported format and container (see table below). </p> <p>If RAPIDS doesn\u2019t support your data stream yet (e.g. Beiwe data stored in PostgreSQL, or AWARE data stored in SQLite), you can always implement a new data stream. If it\u2019s something you think other people might be interested on, we will be happy to include your new data stream in RAPIDS, so get in touch!.</p> <p>Hint</p> <p>Currently, you can add new data streams for smartphones, Fitbit, and Empatica devices. If you need RAPIDS to process data from other devices, like Oura Rings or Actigraph wearables, get in touch. It is a more complicated process that could take a couple of days to implement for someone familiar with R or Python, but we would be happy to work on it together.</p> <p>For reference, these are the data streams we currently support: </p> Data Stream Device Format Container Docs <code>aware_mysql</code> Phone AWARE app MySQL link <code>aware_csv</code> Phone AWARE app CSV files link <code>aware_influxdb</code> (beta) Phone AWARE app InfluxDB link <code>fitbitjson_mysql</code> Fitbit JSON (per Fitbit\u2019s API) MySQL link <code>fitbitjson_csv</code> Fitbit JSON (per Fitbit\u2019s API) CSV files link <code>fitbitparsed_mysql</code> Fitbit Parsed (parsed API data) MySQL link <code>fitbitparsed_csv</code> Fitbit Parsed (parsed API data) CSV files link <code>empatica_zip</code> Empatica E4 Connect ZIP files link"},{"location":"datastreams/empatica-zip/","title":"<code>empatica_zip</code>","text":"<p>This data stream handles Empatica sensor data downloaded as zip files using the E4 Connect. </p>"},{"location":"datastreams/empatica-zip/#container","title":"Container","text":"<p>You need to create a subfolder for every participant named after their <code>device id</code> inside the folder specified by <code>[EMPATICA_DATA_STREAMS][empatica_zipfiles][FOLDER]</code>. You can add one or more Empatica zip files to any subfolder. </p> <p>The script to connect and download data from this container is at: <pre><code>src/data/streams/empatica_zip/container.R\n</code></pre></p>"},{"location":"datastreams/empatica-zip/#format","title":"Format","text":"<p>The <code>format.yaml</code> maps and transforms columns in your raw data stream to the mandatory columns RAPIDS needs for Empatica sensors. This file is at:</p> <pre><code>src/data/streams/empatica_zip/format.yaml\n</code></pre> <p>All columns are mutated from the raw data in the zip files so you don\u2019t need to modify any column mappings.</p> EMPATICA_ACCELEROMETER <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_VALUES_0 double_values_0 DOUBLE_VALUES_1 double_values_1 DOUBLE_VALUES_2 double_values_2 <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> EMPATICA_HEARTRATE <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id HEARTRATE heartrate <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> EMPATICA_TEMPERATURE <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id TEMPERATURE temperature <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> EMPATICA_ELECTRODERMAL_ACTIVITY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id ELECTRODERMAL_ACTIVITY electrodermal_activity <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> EMPATICA_BLOOD_VOLUME_PULSE <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BLOOD_VOLUME_PULSE blood_volume_pulse <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> EMPATICA_INTER_BEAT_INTERVAL <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id INTER_BEAT_INTERVAL inter_beat_interval <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> EMPATICA_EMPATICA_TAGS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id TAGS tags <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul>"},{"location":"datastreams/fitbitjson-csv/","title":"<code>fitbitjson_csv</code>","text":"<p>This data stream handles Fitbit sensor data downloaded using the Fitbit Web API and stored in a CSV file. Please note that RAPIDS cannot query the API directly; you need to use other available tools or implement your own. Once you have your sensor data in a CSV file, RAPIDS can process it.</p> <p>Warning</p> <p>The CSV files have to use <code>,</code> as separator, <code>\\</code> as escape character (do not escape <code>\"</code> with <code>\"\"</code>), and wrap any string columns with <code>\"</code>.</p> Example of a valid CSV file <pre><code>\"timestamp\",\"device_id\",\"label\",\"fitbit_id\",\"fitbit_data_type\",\"fitbit_data\"\n1587614400000,\"a748ee1a-1d0b-4ae9-9074-279a2b6ba524\",\"5S\",\"5ZKN9B\",\"steps\",\"{\\\"activities-steps\\\":[{\\\"dateTime\\\":\\\"2020-04-23\\\",\\\"value\\\":\\\"7881\\\"}]\"\n</code></pre>"},{"location":"datastreams/fitbitjson-csv/#container","title":"Container","text":"<p>The container should be a CSV file per Fitbit sensor, each containing all participants\u2019 data.</p> <p>The script to connect and download data from this container is at: <pre><code>src/data/streams/fitbitjson_csv/container.R\n</code></pre></p>"},{"location":"datastreams/fitbitjson-csv/#format","title":"Format","text":"<p>The <code>format.yaml</code> maps and transforms columns in your raw data stream to the mandatory columns RAPIDS needs for Fitbit sensors. This file is at:</p> <pre><code>src/data/streams/fitbitjson_csv/format.yaml\n</code></pre> <p>If you want RAPIDS to process Fitbit sensor data using this stream, you will need to map <code>DEVICE_ID</code> and <code>JSON_FITBIT_COLUMN</code> to your own raw data columns inside each sensor section in <code>format.yaml</code>.</p> FITBIT_HEARTRATE_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column LOCAL_DATE_TIME FLAG_TO_MUTATE DEVICE_ID device_id HEARTRATE_DAILY_RESTINGHR FLAG_TO_MUTATE HEARTRATE_DAILY_CALORIESOUTOFRANGE FLAG_TO_MUTATE HEARTRATE_DAILY_CALORIESFATBURN FLAG_TO_MUTATE HEARTRATE_DAILY_CALORIESCARDIO FLAG_TO_MUTATE HEARTRATE_DAILY_CALORIESPEAK FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_heartrate_summary_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p>All columns except <code>DEVICE_ID</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the raw data RAPIDS expects for this data stream device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-07\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:1200.6102,\u201dmax\u201d:88,\u201dmin\u201d:31,\u201dminutes\u201d:1058,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:760.3020,\u201dmax\u201d:120,\u201dmin\u201d:86,\u201dminutes\u201d:366,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:15.2048,\u201dmax\u201d:146,\u201dmin\u201d:120,\u201dminutes\u201d:2,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:221,\u201dmin\u201d:148,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:72}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:68},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:67},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:67},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-08\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:1100.1120,\u201dmax\u201d:89,\u201dmin\u201d:30,\u201dminutes\u201d:921,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:660.0012,\u201dmax\u201d:118,\u201dmin\u201d:82,\u201dminutes\u201d:361,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:23.7088,\u201dmax\u201d:142,\u201dmin\u201d:108,\u201dminutes\u201d:3,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:221,\u201dmin\u201d:148,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:70}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:77},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:75},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:73},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-09\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:750.3615,\u201dmax\u201d:77,\u201dmin\u201d:30,\u201dminutes\u201d:851,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:734.1516,\u201dmax\u201d:107,\u201dmin\u201d:77,\u201dminutes\u201d:550,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:131.8579,\u201dmax\u201d:130,\u201dmin\u201d:107,\u201dminutes\u201d:29,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:220,\u201dmin\u201d:130,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:69}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:90},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:89},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:88},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} </li> </ul> FITBIT_HEARTRATE_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column LOCAL_DATE_TIME FLAG_TO_MUTATE DEVICE_ID device_id HEARTRATE FLAG_TO_MUTATE HEARTRATE_ZONE FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_heartrate_intraday_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p>All columns except <code>DEVICE_ID</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the raw data RAPIDS expects for this data stream device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-07\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:1200.6102,\u201dmax\u201d:88,\u201dmin\u201d:31,\u201dminutes\u201d:1058,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:760.3020,\u201dmax\u201d:120,\u201dmin\u201d:86,\u201dminutes\u201d:366,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:15.2048,\u201dmax\u201d:146,\u201dmin\u201d:120,\u201dminutes\u201d:2,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:221,\u201dmin\u201d:148,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:72}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:68},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:67},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:67},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-08\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:1100.1120,\u201dmax\u201d:89,\u201dmin\u201d:30,\u201dminutes\u201d:921,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:660.0012,\u201dmax\u201d:118,\u201dmin\u201d:82,\u201dminutes\u201d:361,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:23.7088,\u201dmax\u201d:142,\u201dmin\u201d:108,\u201dminutes\u201d:3,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:221,\u201dmin\u201d:148,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:70}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:77},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:75},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:73},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-09\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:750.3615,\u201dmax\u201d:77,\u201dmin\u201d:30,\u201dminutes\u201d:851,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:734.1516,\u201dmax\u201d:107,\u201dmin\u201d:77,\u201dminutes\u201d:550,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:131.8579,\u201dmax\u201d:130,\u201dmin\u201d:107,\u201dminutes\u201d:29,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:220,\u201dmin\u201d:130,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:69}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:90},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:89},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:88},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} </li> </ul> FITBIT_SLEEP_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME FLAG_TO_MUTATE LOCAL_START_DATE_TIME FLAG_TO_MUTATE LOCAL_END_DATE_TIME FLAG_TO_MUTATE DEVICE_ID device_id EFFICIENCY FLAG_TO_MUTATE MINUTES_AFTER_WAKEUP FLAG_TO_MUTATE MINUTES_ASLEEP FLAG_TO_MUTATE MINUTES_AWAKE FLAG_TO_MUTATE MINUTES_TO_FALL_ASLEEP FLAG_TO_MUTATE MINUTES_IN_BED FLAG_TO_MUTATE IS_MAIN_SLEEP FLAG_TO_MUTATE TYPE FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_sleep_summary_json.py\n- src/data/streams/mutations/fitbit/add_local_date_time.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p>Fitbit API has two versions for sleep data, v1 and v1.2. We support both but ignore v1\u2019s <code>count_awake</code>, <code>duration_awake</code>, and <code>count_awakenings</code>, <code>count_restless</code>, <code>duration_restless</code> columns.</p> <p>All columns except <code>DEVICE_ID</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the expected raw data device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-10\u201d,\u201dduration\u201d:3600000,\u201defficiency\u201d:92,\u201dendTime\u201d:\u201d2020-10-10T16:37:00.000\u201d,\u201dinfoCode\u201d:2,\u201disMainSleep\u201d:false,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-10T15:36:30.000\u201d,\u201dlevel\u201d:\u201drestless\u201d,\u201dseconds\u201d:60},{\u201cdateTime\u201d:\u201d2020-10-10T15:37:30.000\u201d,\u201dlevel\u201d:\u201dasleep\u201d,\u201dseconds\u201d:660},{\u201cdateTime\u201d:\u201d2020-10-10T15:48:30.000\u201d,\u201dlevel\u201d:\u201drestless\u201d,\u201dseconds\u201d:60},\u2026], \u201csummary\u201d:{\u201casleep\u201d:{\u201ccount\u201d:0,\u201dminutes\u201d:56},\u201dawake\u201d:{\u201ccount\u201d:0,\u201dminutes\u201d:0},\u201drestless\u201d:{\u201ccount\u201d:3,\u201dminutes\u201d:4}}},\u201dlogId\u201d:26315914306,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:55,\u201dminutesAwake\u201d:5,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-10T15:36:30.000\u201d,\u201dtimeInBed\u201d:60,\u201dtype\u201d:\u201dclassic\u201d},{\u201cdateOfSleep\u201d:\u201d2020-10-10\u201d,\u201dduration\u201d:22980000,\u201defficiency\u201d:88,\u201dendTime\u201d:\u201d2020-10-10T08:10:00.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-10T01:46:30.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:420},{\u201cdateTime\u201d:\u201d2020-10-10T01:53:30.000\u201d,\u201dlevel\u201d:\u201ddeep\u201d,\u201dseconds\u201d:1230},{\u201cdateTime\u201d:\u201d2020-10-10T02:14:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:360},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:3,\u201dminutes\u201d:92,\u201dthirtyDayAvgMinutes\u201d:0},\u201dlight\u201d:{\u201ccount\u201d:29,\u201dminutes\u201d:193,\u201dthirtyDayAvgMinutes\u201d:0},\u201drem\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:33,\u201dthirtyDayAvgMinutes\u201d:0},\u201dwake\u201d:{\u201ccount\u201d:28,\u201dminutes\u201d:65,\u201dthirtyDayAvgMinutes\u201d:0}}},\u201dlogId\u201d:26311786557,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:318,\u201dminutesAwake\u201d:65,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-10T01:46:30.000\u201d,\u201dtimeInBed\u201d:383,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:92,\u201dlight\u201d:193,\u201drem\u201d:33,\u201dwake\u201d:65},\u201dtotalMinutesAsleep\u201d:373,\u201dtotalSleepRecords\u201d:2,\u201dtotalTimeInBed\u201d:443}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-11\u201d,\u201dduration\u201d:41640000,\u201defficiency\u201d:89,\u201dendTime\u201d:\u201d2020-10-11T11:47:00.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-11T00:12:30.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:450},{\u201cdateTime\u201d:\u201d2020-10-11T00:20:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:870},{\u201cdateTime\u201d:\u201d2020-10-11T00:34:30.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:780},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:52,\u201dthirtyDayAvgMinutes\u201d:62},\u201dlight\u201d:{\u201ccount\u201d:32,\u201dminutes\u201d:442,\u201dthirtyDayAvgMinutes\u201d:364},\u201drem\u201d:{\u201ccount\u201d:6,\u201dminutes\u201d:68,\u201dthirtyDayAvgMinutes\u201d:58},\u201dwake\u201d:{\u201ccount\u201d:29,\u201dminutes\u201d:132,\u201dthirtyDayAvgMinutes\u201d:94}}},\u201dlogId\u201d:26589710670,\u201dminutesAfterWakeup\u201d:1,\u201dminutesAsleep\u201d:562,\u201dminutesAwake\u201d:132,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-11T00:12:30.000\u201d,\u201dtimeInBed\u201d:694,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:52,\u201dlight\u201d:442,\u201drem\u201d:68,\u201dwake\u201d:132},\u201dtotalMinutesAsleep\u201d:562,\u201dtotalSleepRecords\u201d:1,\u201dtotalTimeInBed\u201d:694}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-12\u201d,\u201dduration\u201d:28980000,\u201defficiency\u201d:93,\u201dendTime\u201d:\u201d2020-10-12T09:34:30.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-12T01:31:00.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:600},{\u201cdateTime\u201d:\u201d2020-10-12T01:41:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:60},{\u201cdateTime\u201d:\u201d2020-10-12T01:42:00.000\u201d,\u201dlevel\u201d:\u201ddeep\u201d,\u201dseconds\u201d:2340},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:63,\u201dthirtyDayAvgMinutes\u201d:59},\u201dlight\u201d:{\u201ccount\u201d:27,\u201dminutes\u201d:257,\u201dthirtyDayAvgMinutes\u201d:364},\u201drem\u201d:{\u201ccount\u201d:5,\u201dminutes\u201d:94,\u201dthirtyDayAvgMinutes\u201d:58},\u201dwake\u201d:{\u201ccount\u201d:24,\u201dminutes\u201d:69,\u201dthirtyDayAvgMinutes\u201d:95}}},\u201dlogId\u201d:26589710673,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:415,\u201dminutesAwake\u201d:68,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-12T01:31:00.000\u201d,\u201dtimeInBed\u201d:483,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:63,\u201dlight\u201d:257,\u201drem\u201d:94,\u201dwake\u201d:69},\u201dtotalMinutesAsleep\u201d:415,\u201dtotalSleepRecords\u201d:1,\u201dtotalTimeInBed\u201d:483}} </li> </ul> FITBIT_SLEEP_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME FLAG_TO_MUTATE DEVICE_ID device_id TYPE_EPISODE_ID FLAG_TO_MUTATE DURATION FLAG_TO_MUTATE IS_MAIN_SLEEP FLAG_TO_MUTATE TYPE FLAG_TO_MUTATE LEVEL FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_sleep_intraday_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p>Fitbit API has two versions for sleep data, v1 and v1.2, we support both.</p> <p>All columns except <code>DEVICE_ID</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the expected raw data device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-10\u201d,\u201dduration\u201d:3600000,\u201defficiency\u201d:92,\u201dendTime\u201d:\u201d2020-10-10T16:37:00.000\u201d,\u201dinfoCode\u201d:2,\u201disMainSleep\u201d:false,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-10T15:36:30.000\u201d,\u201dlevel\u201d:\u201drestless\u201d,\u201dseconds\u201d:60},{\u201cdateTime\u201d:\u201d2020-10-10T15:37:30.000\u201d,\u201dlevel\u201d:\u201dasleep\u201d,\u201dseconds\u201d:660},{\u201cdateTime\u201d:\u201d2020-10-10T15:48:30.000\u201d,\u201dlevel\u201d:\u201drestless\u201d,\u201dseconds\u201d:60},\u2026], \u201csummary\u201d:{\u201casleep\u201d:{\u201ccount\u201d:0,\u201dminutes\u201d:56},\u201dawake\u201d:{\u201ccount\u201d:0,\u201dminutes\u201d:0},\u201drestless\u201d:{\u201ccount\u201d:3,\u201dminutes\u201d:4}}},\u201dlogId\u201d:26315914306,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:55,\u201dminutesAwake\u201d:5,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-10T15:36:30.000\u201d,\u201dtimeInBed\u201d:60,\u201dtype\u201d:\u201dclassic\u201d},{\u201cdateOfSleep\u201d:\u201d2020-10-10\u201d,\u201dduration\u201d:22980000,\u201defficiency\u201d:88,\u201dendTime\u201d:\u201d2020-10-10T08:10:00.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-10T01:46:30.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:420},{\u201cdateTime\u201d:\u201d2020-10-10T01:53:30.000\u201d,\u201dlevel\u201d:\u201ddeep\u201d,\u201dseconds\u201d:1230},{\u201cdateTime\u201d:\u201d2020-10-10T02:14:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:360},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:3,\u201dminutes\u201d:92,\u201dthirtyDayAvgMinutes\u201d:0},\u201dlight\u201d:{\u201ccount\u201d:29,\u201dminutes\u201d:193,\u201dthirtyDayAvgMinutes\u201d:0},\u201drem\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:33,\u201dthirtyDayAvgMinutes\u201d:0},\u201dwake\u201d:{\u201ccount\u201d:28,\u201dminutes\u201d:65,\u201dthirtyDayAvgMinutes\u201d:0}}},\u201dlogId\u201d:26311786557,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:318,\u201dminutesAwake\u201d:65,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-10T01:46:30.000\u201d,\u201dtimeInBed\u201d:383,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:92,\u201dlight\u201d:193,\u201drem\u201d:33,\u201dwake\u201d:65},\u201dtotalMinutesAsleep\u201d:373,\u201dtotalSleepRecords\u201d:2,\u201dtotalTimeInBed\u201d:443}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-11\u201d,\u201dduration\u201d:41640000,\u201defficiency\u201d:89,\u201dendTime\u201d:\u201d2020-10-11T11:47:00.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-11T00:12:30.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:450},{\u201cdateTime\u201d:\u201d2020-10-11T00:20:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:870},{\u201cdateTime\u201d:\u201d2020-10-11T00:34:30.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:780},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:52,\u201dthirtyDayAvgMinutes\u201d:62},\u201dlight\u201d:{\u201ccount\u201d:32,\u201dminutes\u201d:442,\u201dthirtyDayAvgMinutes\u201d:364},\u201drem\u201d:{\u201ccount\u201d:6,\u201dminutes\u201d:68,\u201dthirtyDayAvgMinutes\u201d:58},\u201dwake\u201d:{\u201ccount\u201d:29,\u201dminutes\u201d:132,\u201dthirtyDayAvgMinutes\u201d:94}}},\u201dlogId\u201d:26589710670,\u201dminutesAfterWakeup\u201d:1,\u201dminutesAsleep\u201d:562,\u201dminutesAwake\u201d:132,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-11T00:12:30.000\u201d,\u201dtimeInBed\u201d:694,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:52,\u201dlight\u201d:442,\u201drem\u201d:68,\u201dwake\u201d:132},\u201dtotalMinutesAsleep\u201d:562,\u201dtotalSleepRecords\u201d:1,\u201dtotalTimeInBed\u201d:694}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-12\u201d,\u201dduration\u201d:28980000,\u201defficiency\u201d:93,\u201dendTime\u201d:\u201d2020-10-12T09:34:30.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-12T01:31:00.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:600},{\u201cdateTime\u201d:\u201d2020-10-12T01:41:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:60},{\u201cdateTime\u201d:\u201d2020-10-12T01:42:00.000\u201d,\u201dlevel\u201d:\u201ddeep\u201d,\u201dseconds\u201d:2340},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:63,\u201dthirtyDayAvgMinutes\u201d:59},\u201dlight\u201d:{\u201ccount\u201d:27,\u201dminutes\u201d:257,\u201dthirtyDayAvgMinutes\u201d:364},\u201drem\u201d:{\u201ccount\u201d:5,\u201dminutes\u201d:94,\u201dthirtyDayAvgMinutes\u201d:58},\u201dwake\u201d:{\u201ccount\u201d:24,\u201dminutes\u201d:69,\u201dthirtyDayAvgMinutes\u201d:95}}},\u201dlogId\u201d:26589710673,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:415,\u201dminutesAwake\u201d:68,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-12T01:31:00.000\u201d,\u201dtimeInBed\u201d:483,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:63,\u201dlight\u201d:257,\u201drem\u201d:94,\u201dwake\u201d:69},\u201dtotalMinutesAsleep\u201d:415,\u201dtotalSleepRecords\u201d:1,\u201dtotalTimeInBed\u201d:483}} </li> </ul> FITBIT_STEPS_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE DEVICE_ID device_id LOCAL_DATE_TIME FLAG_TO_MUTATE STEPS FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_steps_summary_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p><code>TIMESTAMP</code>, <code>LOCAL_DATE_TIME</code>, and <code>STEPS</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the expected raw data device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-07\u201d,\u201dvalue\u201d:\u201d1775\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:5},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:3},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:0},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-08\u201d,\u201dvalue\u201d:\u201d3201\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:14},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:11},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:10},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-09\u201d,\u201dvalue\u201d:\u201d998\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:0},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:0},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:0},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} </li> </ul> FITBIT_STEPS_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE DEVICE_ID device_id LOCAL_DATE_TIME FLAG_TO_MUTATE STEPS FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_steps_intraday_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p><code>TIMESTAMP</code>, <code>LOCAL_DATE_TIME</code>, and <code>STEPS</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the expected raw data device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-07\u201d,\u201dvalue\u201d:\u201d1775\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:5},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:3},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:0},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-08\u201d,\u201dvalue\u201d:\u201d3201\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:14},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:11},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:10},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-09\u201d,\u201dvalue\u201d:\u201d998\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:0},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:0},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:0},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} </li> </ul>"},{"location":"datastreams/fitbitjson-mysql/","title":"<code>fitbitjson_mysql</code>","text":"<p>This data stream handles Fitbit sensor data downloaded using the Fitbit Web API and stored in a MySQL database. Please note that RAPIDS cannot query the API directly; you need to use other available tools or implement your own. Once you have your sensor data in a MySQL database, RAPIDS can process it.</p>"},{"location":"datastreams/fitbitjson-mysql/#container","title":"Container","text":"<p>The container should be a MySQL database with a table per sensor, each containing all participants\u2019 data.</p> <p>The script to connect and download data from this container is at: <pre><code>src/data/streams/fitbitjson_mysql/container.R\n</code></pre></p>"},{"location":"datastreams/fitbitjson-mysql/#format","title":"Format","text":"<p>The <code>format.yaml</code> maps and transforms columns in your raw data stream to the mandatory columns RAPIDS needs for Fitbit sensors. This file is at:</p> <pre><code>src/data/streams/fitbitjson_csv/format.yaml\n</code></pre> <p>If you want RAPIDS to process Fitbit sensor data using this stream, you will need to map <code>DEVICE_ID</code> and <code>JSON_FITBIT_COLUMN</code> to your own raw data columns inside each sensor section in <code>format.yaml</code>.</p> FITBIT_HEARTRATE_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column LOCAL_DATE_TIME FLAG_TO_MUTATE DEVICE_ID device_id HEARTRATE_DAILY_RESTINGHR FLAG_TO_MUTATE HEARTRATE_DAILY_CALORIESOUTOFRANGE FLAG_TO_MUTATE HEARTRATE_DAILY_CALORIESFATBURN FLAG_TO_MUTATE HEARTRATE_DAILY_CALORIESCARDIO FLAG_TO_MUTATE HEARTRATE_DAILY_CALORIESPEAK FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_heartrate_summary_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p>All columns except <code>DEVICE_ID</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the raw data RAPIDS expects for this data stream device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-07\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:1200.6102,\u201dmax\u201d:88,\u201dmin\u201d:31,\u201dminutes\u201d:1058,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:760.3020,\u201dmax\u201d:120,\u201dmin\u201d:86,\u201dminutes\u201d:366,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:15.2048,\u201dmax\u201d:146,\u201dmin\u201d:120,\u201dminutes\u201d:2,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:221,\u201dmin\u201d:148,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:72}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:68},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:67},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:67},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-08\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:1100.1120,\u201dmax\u201d:89,\u201dmin\u201d:30,\u201dminutes\u201d:921,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:660.0012,\u201dmax\u201d:118,\u201dmin\u201d:82,\u201dminutes\u201d:361,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:23.7088,\u201dmax\u201d:142,\u201dmin\u201d:108,\u201dminutes\u201d:3,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:221,\u201dmin\u201d:148,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:70}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:77},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:75},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:73},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-09\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:750.3615,\u201dmax\u201d:77,\u201dmin\u201d:30,\u201dminutes\u201d:851,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:734.1516,\u201dmax\u201d:107,\u201dmin\u201d:77,\u201dminutes\u201d:550,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:131.8579,\u201dmax\u201d:130,\u201dmin\u201d:107,\u201dminutes\u201d:29,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:220,\u201dmin\u201d:130,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:69}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:90},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:89},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:88},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} </li> </ul> FITBIT_HEARTRATE_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column LOCAL_DATE_TIME FLAG_TO_MUTATE DEVICE_ID device_id HEARTRATE FLAG_TO_MUTATE HEARTRATE_ZONE FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_heartrate_intraday_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p>All columns except <code>DEVICE_ID</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the raw data RAPIDS expects for this data stream device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-07\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:1200.6102,\u201dmax\u201d:88,\u201dmin\u201d:31,\u201dminutes\u201d:1058,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:760.3020,\u201dmax\u201d:120,\u201dmin\u201d:86,\u201dminutes\u201d:366,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:15.2048,\u201dmax\u201d:146,\u201dmin\u201d:120,\u201dminutes\u201d:2,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:221,\u201dmin\u201d:148,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:72}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:68},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:67},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:67},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-08\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:1100.1120,\u201dmax\u201d:89,\u201dmin\u201d:30,\u201dminutes\u201d:921,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:660.0012,\u201dmax\u201d:118,\u201dmin\u201d:82,\u201dminutes\u201d:361,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:23.7088,\u201dmax\u201d:142,\u201dmin\u201d:108,\u201dminutes\u201d:3,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:221,\u201dmin\u201d:148,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:70}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:77},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:75},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:73},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-09\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:750.3615,\u201dmax\u201d:77,\u201dmin\u201d:30,\u201dminutes\u201d:851,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:734.1516,\u201dmax\u201d:107,\u201dmin\u201d:77,\u201dminutes\u201d:550,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:131.8579,\u201dmax\u201d:130,\u201dmin\u201d:107,\u201dminutes\u201d:29,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:220,\u201dmin\u201d:130,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:69}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:90},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:89},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:88},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} </li> </ul> FITBIT_SLEEP_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME FLAG_TO_MUTATE LOCAL_START_DATE_TIME FLAG_TO_MUTATE LOCAL_END_DATE_TIME FLAG_TO_MUTATE DEVICE_ID device_id EFFICIENCY FLAG_TO_MUTATE MINUTES_AFTER_WAKEUP FLAG_TO_MUTATE MINUTES_ASLEEP FLAG_TO_MUTATE MINUTES_AWAKE FLAG_TO_MUTATE MINUTES_TO_FALL_ASLEEP FLAG_TO_MUTATE MINUTES_IN_BED FLAG_TO_MUTATE IS_MAIN_SLEEP FLAG_TO_MUTATE TYPE FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_sleep_summary_json.py\n- src/data/streams/mutations/fitbit/add_local_date_time.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p>Fitbit API has two versions for sleep data, v1 and v1.2. We support both but ignore v1\u2019s <code>count_awake</code>, <code>duration_awake</code>, and <code>count_awakenings</code>, <code>count_restless</code>, <code>duration_restless</code> columns.</p> <p>All columns except <code>DEVICE_ID</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the expected raw data device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-10\u201d,\u201dduration\u201d:3600000,\u201defficiency\u201d:92,\u201dendTime\u201d:\u201d2020-10-10T16:37:00.000\u201d,\u201dinfoCode\u201d:2,\u201disMainSleep\u201d:false,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-10T15:36:30.000\u201d,\u201dlevel\u201d:\u201drestless\u201d,\u201dseconds\u201d:60},{\u201cdateTime\u201d:\u201d2020-10-10T15:37:30.000\u201d,\u201dlevel\u201d:\u201dasleep\u201d,\u201dseconds\u201d:660},{\u201cdateTime\u201d:\u201d2020-10-10T15:48:30.000\u201d,\u201dlevel\u201d:\u201drestless\u201d,\u201dseconds\u201d:60},\u2026], \u201csummary\u201d:{\u201casleep\u201d:{\u201ccount\u201d:0,\u201dminutes\u201d:56},\u201dawake\u201d:{\u201ccount\u201d:0,\u201dminutes\u201d:0},\u201drestless\u201d:{\u201ccount\u201d:3,\u201dminutes\u201d:4}}},\u201dlogId\u201d:26315914306,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:55,\u201dminutesAwake\u201d:5,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-10T15:36:30.000\u201d,\u201dtimeInBed\u201d:60,\u201dtype\u201d:\u201dclassic\u201d},{\u201cdateOfSleep\u201d:\u201d2020-10-10\u201d,\u201dduration\u201d:22980000,\u201defficiency\u201d:88,\u201dendTime\u201d:\u201d2020-10-10T08:10:00.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-10T01:46:30.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:420},{\u201cdateTime\u201d:\u201d2020-10-10T01:53:30.000\u201d,\u201dlevel\u201d:\u201ddeep\u201d,\u201dseconds\u201d:1230},{\u201cdateTime\u201d:\u201d2020-10-10T02:14:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:360},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:3,\u201dminutes\u201d:92,\u201dthirtyDayAvgMinutes\u201d:0},\u201dlight\u201d:{\u201ccount\u201d:29,\u201dminutes\u201d:193,\u201dthirtyDayAvgMinutes\u201d:0},\u201drem\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:33,\u201dthirtyDayAvgMinutes\u201d:0},\u201dwake\u201d:{\u201ccount\u201d:28,\u201dminutes\u201d:65,\u201dthirtyDayAvgMinutes\u201d:0}}},\u201dlogId\u201d:26311786557,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:318,\u201dminutesAwake\u201d:65,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-10T01:46:30.000\u201d,\u201dtimeInBed\u201d:383,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:92,\u201dlight\u201d:193,\u201drem\u201d:33,\u201dwake\u201d:65},\u201dtotalMinutesAsleep\u201d:373,\u201dtotalSleepRecords\u201d:2,\u201dtotalTimeInBed\u201d:443}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-11\u201d,\u201dduration\u201d:41640000,\u201defficiency\u201d:89,\u201dendTime\u201d:\u201d2020-10-11T11:47:00.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-11T00:12:30.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:450},{\u201cdateTime\u201d:\u201d2020-10-11T00:20:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:870},{\u201cdateTime\u201d:\u201d2020-10-11T00:34:30.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:780},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:52,\u201dthirtyDayAvgMinutes\u201d:62},\u201dlight\u201d:{\u201ccount\u201d:32,\u201dminutes\u201d:442,\u201dthirtyDayAvgMinutes\u201d:364},\u201drem\u201d:{\u201ccount\u201d:6,\u201dminutes\u201d:68,\u201dthirtyDayAvgMinutes\u201d:58},\u201dwake\u201d:{\u201ccount\u201d:29,\u201dminutes\u201d:132,\u201dthirtyDayAvgMinutes\u201d:94}}},\u201dlogId\u201d:26589710670,\u201dminutesAfterWakeup\u201d:1,\u201dminutesAsleep\u201d:562,\u201dminutesAwake\u201d:132,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-11T00:12:30.000\u201d,\u201dtimeInBed\u201d:694,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:52,\u201dlight\u201d:442,\u201drem\u201d:68,\u201dwake\u201d:132},\u201dtotalMinutesAsleep\u201d:562,\u201dtotalSleepRecords\u201d:1,\u201dtotalTimeInBed\u201d:694}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-12\u201d,\u201dduration\u201d:28980000,\u201defficiency\u201d:93,\u201dendTime\u201d:\u201d2020-10-12T09:34:30.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-12T01:31:00.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:600},{\u201cdateTime\u201d:\u201d2020-10-12T01:41:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:60},{\u201cdateTime\u201d:\u201d2020-10-12T01:42:00.000\u201d,\u201dlevel\u201d:\u201ddeep\u201d,\u201dseconds\u201d:2340},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:63,\u201dthirtyDayAvgMinutes\u201d:59},\u201dlight\u201d:{\u201ccount\u201d:27,\u201dminutes\u201d:257,\u201dthirtyDayAvgMinutes\u201d:364},\u201drem\u201d:{\u201ccount\u201d:5,\u201dminutes\u201d:94,\u201dthirtyDayAvgMinutes\u201d:58},\u201dwake\u201d:{\u201ccount\u201d:24,\u201dminutes\u201d:69,\u201dthirtyDayAvgMinutes\u201d:95}}},\u201dlogId\u201d:26589710673,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:415,\u201dminutesAwake\u201d:68,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-12T01:31:00.000\u201d,\u201dtimeInBed\u201d:483,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:63,\u201dlight\u201d:257,\u201drem\u201d:94,\u201dwake\u201d:69},\u201dtotalMinutesAsleep\u201d:415,\u201dtotalSleepRecords\u201d:1,\u201dtotalTimeInBed\u201d:483}} </li> </ul> FITBIT_SLEEP_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME FLAG_TO_MUTATE DEVICE_ID device_id TYPE_EPISODE_ID FLAG_TO_MUTATE DURATION FLAG_TO_MUTATE IS_MAIN_SLEEP FLAG_TO_MUTATE TYPE FLAG_TO_MUTATE LEVEL FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_sleep_intraday_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p>Fitbit API has two versions for sleep data, v1 and v1.2, we support both.</p> <p>All columns except <code>DEVICE_ID</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the expected raw data device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-10\u201d,\u201dduration\u201d:3600000,\u201defficiency\u201d:92,\u201dendTime\u201d:\u201d2020-10-10T16:37:00.000\u201d,\u201dinfoCode\u201d:2,\u201disMainSleep\u201d:false,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-10T15:36:30.000\u201d,\u201dlevel\u201d:\u201drestless\u201d,\u201dseconds\u201d:60},{\u201cdateTime\u201d:\u201d2020-10-10T15:37:30.000\u201d,\u201dlevel\u201d:\u201dasleep\u201d,\u201dseconds\u201d:660},{\u201cdateTime\u201d:\u201d2020-10-10T15:48:30.000\u201d,\u201dlevel\u201d:\u201drestless\u201d,\u201dseconds\u201d:60},\u2026], \u201csummary\u201d:{\u201casleep\u201d:{\u201ccount\u201d:0,\u201dminutes\u201d:56},\u201dawake\u201d:{\u201ccount\u201d:0,\u201dminutes\u201d:0},\u201drestless\u201d:{\u201ccount\u201d:3,\u201dminutes\u201d:4}}},\u201dlogId\u201d:26315914306,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:55,\u201dminutesAwake\u201d:5,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-10T15:36:30.000\u201d,\u201dtimeInBed\u201d:60,\u201dtype\u201d:\u201dclassic\u201d},{\u201cdateOfSleep\u201d:\u201d2020-10-10\u201d,\u201dduration\u201d:22980000,\u201defficiency\u201d:88,\u201dendTime\u201d:\u201d2020-10-10T08:10:00.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-10T01:46:30.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:420},{\u201cdateTime\u201d:\u201d2020-10-10T01:53:30.000\u201d,\u201dlevel\u201d:\u201ddeep\u201d,\u201dseconds\u201d:1230},{\u201cdateTime\u201d:\u201d2020-10-10T02:14:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:360},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:3,\u201dminutes\u201d:92,\u201dthirtyDayAvgMinutes\u201d:0},\u201dlight\u201d:{\u201ccount\u201d:29,\u201dminutes\u201d:193,\u201dthirtyDayAvgMinutes\u201d:0},\u201drem\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:33,\u201dthirtyDayAvgMinutes\u201d:0},\u201dwake\u201d:{\u201ccount\u201d:28,\u201dminutes\u201d:65,\u201dthirtyDayAvgMinutes\u201d:0}}},\u201dlogId\u201d:26311786557,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:318,\u201dminutesAwake\u201d:65,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-10T01:46:30.000\u201d,\u201dtimeInBed\u201d:383,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:92,\u201dlight\u201d:193,\u201drem\u201d:33,\u201dwake\u201d:65},\u201dtotalMinutesAsleep\u201d:373,\u201dtotalSleepRecords\u201d:2,\u201dtotalTimeInBed\u201d:443}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-11\u201d,\u201dduration\u201d:41640000,\u201defficiency\u201d:89,\u201dendTime\u201d:\u201d2020-10-11T11:47:00.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-11T00:12:30.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:450},{\u201cdateTime\u201d:\u201d2020-10-11T00:20:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:870},{\u201cdateTime\u201d:\u201d2020-10-11T00:34:30.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:780},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:52,\u201dthirtyDayAvgMinutes\u201d:62},\u201dlight\u201d:{\u201ccount\u201d:32,\u201dminutes\u201d:442,\u201dthirtyDayAvgMinutes\u201d:364},\u201drem\u201d:{\u201ccount\u201d:6,\u201dminutes\u201d:68,\u201dthirtyDayAvgMinutes\u201d:58},\u201dwake\u201d:{\u201ccount\u201d:29,\u201dminutes\u201d:132,\u201dthirtyDayAvgMinutes\u201d:94}}},\u201dlogId\u201d:26589710670,\u201dminutesAfterWakeup\u201d:1,\u201dminutesAsleep\u201d:562,\u201dminutesAwake\u201d:132,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-11T00:12:30.000\u201d,\u201dtimeInBed\u201d:694,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:52,\u201dlight\u201d:442,\u201drem\u201d:68,\u201dwake\u201d:132},\u201dtotalMinutesAsleep\u201d:562,\u201dtotalSleepRecords\u201d:1,\u201dtotalTimeInBed\u201d:694}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-12\u201d,\u201dduration\u201d:28980000,\u201defficiency\u201d:93,\u201dendTime\u201d:\u201d2020-10-12T09:34:30.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-12T01:31:00.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:600},{\u201cdateTime\u201d:\u201d2020-10-12T01:41:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:60},{\u201cdateTime\u201d:\u201d2020-10-12T01:42:00.000\u201d,\u201dlevel\u201d:\u201ddeep\u201d,\u201dseconds\u201d:2340},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:63,\u201dthirtyDayAvgMinutes\u201d:59},\u201dlight\u201d:{\u201ccount\u201d:27,\u201dminutes\u201d:257,\u201dthirtyDayAvgMinutes\u201d:364},\u201drem\u201d:{\u201ccount\u201d:5,\u201dminutes\u201d:94,\u201dthirtyDayAvgMinutes\u201d:58},\u201dwake\u201d:{\u201ccount\u201d:24,\u201dminutes\u201d:69,\u201dthirtyDayAvgMinutes\u201d:95}}},\u201dlogId\u201d:26589710673,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:415,\u201dminutesAwake\u201d:68,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-12T01:31:00.000\u201d,\u201dtimeInBed\u201d:483,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:63,\u201dlight\u201d:257,\u201drem\u201d:94,\u201dwake\u201d:69},\u201dtotalMinutesAsleep\u201d:415,\u201dtotalSleepRecords\u201d:1,\u201dtotalTimeInBed\u201d:483}} </li> </ul> FITBIT_STEPS_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE DEVICE_ID device_id LOCAL_DATE_TIME FLAG_TO_MUTATE STEPS FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_steps_summary_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p><code>TIMESTAMP</code>, <code>LOCAL_DATE_TIME</code>, and <code>STEPS</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the expected raw data device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-07\u201d,\u201dvalue\u201d:\u201d1775\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:5},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:3},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:0},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-08\u201d,\u201dvalue\u201d:\u201d3201\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:14},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:11},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:10},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-09\u201d,\u201dvalue\u201d:\u201d998\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:0},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:0},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:0},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} </li> </ul> FITBIT_STEPS_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE DEVICE_ID device_id LOCAL_DATE_TIME FLAG_TO_MUTATE STEPS FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_steps_intraday_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p><code>TIMESTAMP</code>, <code>LOCAL_DATE_TIME</code>, and <code>STEPS</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the expected raw data device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-07\u201d,\u201dvalue\u201d:\u201d1775\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:5},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:3},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:0},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-08\u201d,\u201dvalue\u201d:\u201d3201\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:14},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:11},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:10},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-09\u201d,\u201dvalue\u201d:\u201d998\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:0},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:0},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:0},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} </li> </ul>"},{"location":"datastreams/fitbitparsed-csv/","title":"<code>fitbitparsed_csv</code>","text":"<p>This data stream handles Fitbit sensor data downloaded using the Fitbit Web API, parsed, and stored in a CSV file. Please note that RAPIDS cannot query the API directly; you need to use other available tools or implement your own. Once you have your parsed sensor data in a CSV file, RAPIDS can process it.</p> <p>What is the difference between JSON and plain data streams</p> <p>Most people will only need <code>fitbitjson_*</code> because they downloaded and stored their data directly from Fitbit\u2019s API. However, if, for some reason, you don\u2019t have access to that JSON data and instead only have the parsed data (columns and rows), you can use this data stream.</p> <p>Warning</p> <p>The CSV files have to use <code>,</code> as separator, <code>\\</code> as escape character (do not escape <code>\"</code> with <code>\"\"</code>), and wrap any string columns with <code>\"</code>.</p> Example of a valid CSV file <pre><code>\"device_id\",\"heartrate\",\"heartrate_zone\",\"local_date_time\",\"timestamp\"\n\"a748ee1a-1d0b-4ae9-9074-279a2b6ba524\",69,\"outofrange\",\"2020-04-23 00:00:00\",0\n\"a748ee1a-1d0b-4ae9-9074-279a2b6ba524\",69,\"outofrange\",\"2020-04-23 00:01:00\",0\n\"a748ee1a-1d0b-4ae9-9074-279a2b6ba524\",67,\"outofrange\",\"2020-04-23 00:02:00\",0\n\"a748ee1a-1d0b-4ae9-9074-279a2b6ba524\",69,\"outofrange\",\"2020-04-23 00:03:00\",0\n</code></pre>"},{"location":"datastreams/fitbitparsed-csv/#container","title":"Container","text":"<p>The container should be a CSV file per sensor, each containing all participants\u2019 data.</p> <p>The script to connect and download data from this container is at: <pre><code>src/data/streams/fitbitparsed_csv/container.R\n</code></pre></p>"},{"location":"datastreams/fitbitparsed-csv/#format","title":"Format","text":"<p>The <code>format.yaml</code> maps and transforms columns in your raw data stream to the mandatory columns RAPIDS needs for Fitbit sensors. This file is at:</p> <pre><code>src/data/streams/fitbitparsed_mysql/format.yaml\n</code></pre> <p>If you want to use this stream with your data, modify every sensor in <code>format.yaml</code> to map all columns except <code>TIMESTAMP</code> in <code>[RAPIDS_COLUMN_MAPPINGS]</code> to your raw data column names.</p> <p>All columns are mandatory; however, all except <code>device_id</code> and <code>local_date_time</code> can be empty if you don\u2019t have that data. Just have in mind that some features will be empty if some of these columns are empty.</p> FITBIT_HEARTRATE_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME local_date_time DEVICE_ID device_id HEARTRATE_DAILY_RESTINGHR heartrate_daily_restinghr HEARTRATE_DAILY_CALORIESOUTOFRANGE heartrate_daily_caloriesoutofrange HEARTRATE_DAILY_CALORIESFATBURN heartrate_daily_caloriesfatburn HEARTRATE_DAILY_CALORIESCARDIO heartrate_daily_caloriescardio HEARTRATE_DAILY_CALORIESPEAK heartrate_daily_caloriespeak <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> Example of the raw data RAPIDS expects for this data stream device_id local_date_time heartrate_daily_restinghr heartrate_daily_caloriesoutofrange heartrate_daily_caloriesfatburn heartrate_daily_caloriescardio heartrate_daily_caloriespeak a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 72 1200.6102 760.3020 15.2048 0 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-08 70 1100.1120 660.0012 23.7088 0 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-09 69 750.3615 734.1516 131.8579 0 FITBIT_HEARTRATE_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME local_date_time DEVICE_ID device_id HEARTRATE heartrate HEARTRATE_ZONE heartrate_zone <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> Example of the raw data RAPIDS expects for this data stream device_id local_date_time heartrate heartrate_zone a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:00:00 68 outofrange a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:01:00 67 outofrange a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:02:00 67 outofrange FITBIT_SLEEP_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME FLAG_TO_MUTATE LOCAL_START_DATE_TIME local_start_date_time LOCAL_END_DATE_TIME local_end_date_time DEVICE_ID device_id EFFICIENCY efficiency MINUTES_AFTER_WAKEUP minutes_after_wakeup MINUTES_ASLEEP minutes_asleep MINUTES_AWAKE minutes_awake MINUTES_TO_FALL_ASLEEP minutes_to_fall_asleep MINUTES_IN_BED minutes_in_bed IS_MAIN_SLEEP is_main_sleep TYPE type <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>- src/data/streams/mutations/fitbit/add_local_date_time.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> <p>Fitbit API has two versions for sleep data, v1 and v1.2. We support both but ignore v1\u2019s <code>count_awake</code>, <code>duration_awake</code>, and <code>count_awakenings</code>, <code>count_restless</code>, <code>duration_restless</code> columns.</p> Example of the expected raw data device_id local_start_date_time local_end_date_time efficiency minutes_after_wakeup minutes_asleep minutes_awake minutes_to_fall_asleep minutes_in_bed is_main_sleep type a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-10 15:36:30 2020-10-10 16:37:00 92 0 55 5 0 60 0 classic a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-10 01:46:30 2020-10-10 08:10:00 88 0 318 65 0 383 1 stages a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-11 00:12:30 2020-10-11 11:47:00 89 1 562 132 0 694 1 stages a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-12 01:31:00 2020-10-12 09:34:30 93 0 415 68 0 483 1 stages FITBIT_SLEEP_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME local_date_time DEVICE_ID device_id TYPE_EPISODE_ID type_episode_id DURATION duration IS_MAIN_SLEEP is_main_sleep TYPE type LEVEL level <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> <p>Fitbit API has two versions for sleep data, v1 and v1.2, we support both.</p> Example of the expected raw data device_id type_episode_id local_date_time duration level is_main_sleep type a748ee1a-1d0b-4ae9-9074-279a2b6ba524 0 2020-10-10 15:36:30 60 restless 0 classic a748ee1a-1d0b-4ae9-9074-279a2b6ba524 0 2020-10-10 15:37:30 660 asleep 0 classic a748ee1a-1d0b-4ae9-9074-279a2b6ba524 0 2020-10-10 15:48:30 60 restless 0 classic a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 1 2020-10-10 01:46:30 420 light 1 stages a748ee1a-1d0b-4ae9-9074-279a2b6ba524 1 2020-10-10 01:53:30 1230 deep 1 stages FITBIT_STEPS_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE DEVICE_ID device_id LOCAL_DATE_TIME local_date_time STEPS steps <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> Example of the expected raw data device_id local_date_time steps a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 1775 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-08 3201 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-09 998 FITBIT_STEPS_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE DEVICE_ID device_id LOCAL_DATE_TIME local_date_time STEPS steps <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> Example of the expected raw data device_id local_date_time steps a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:00:00 5 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:01:00 3 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:02:00 0"},{"location":"datastreams/fitbitparsed-mysql/","title":"<code>fitbitparsed_mysql</code>","text":"<p>This data stream handles Fitbit sensor data downloaded using the Fitbit Web API, parsed, and stored in a MySQL database. Please note that RAPIDS cannot query the API directly; you need to use other available tools or implement your own. Once you have your parsed sensor data in a MySQL database, RAPIDS can process it.</p> <p>What is the difference between JSON and plain data streams</p> <p>Most people will only need <code>fitbitjson_*</code> because they downloaded and stored their data directly from Fitbit\u2019s API. However, if, for some reason, you don\u2019t have access to that JSON data and instead only have the parsed data (columns and rows), you can use this data stream.</p>"},{"location":"datastreams/fitbitparsed-mysql/#container","title":"Container","text":"<p>The container should be a MySQL database with a table per sensor, each containing all participants\u2019 data.</p> <p>The script to connect and download data from this container is at: <pre><code>src/data/streams/fitbitparsed_mysql/container.R\n</code></pre></p>"},{"location":"datastreams/fitbitparsed-mysql/#format","title":"Format","text":"<p>The <code>format.yaml</code> maps and transforms columns in your raw data stream to the mandatory columns RAPIDS needs for Fitbit sensors. This file is at:</p> <pre><code>src/data/streams/fitbitparsed_mysql/format.yaml\n</code></pre> <p>If you want to use this stream with your data, modify every sensor in <code>format.yaml</code> to map all columns except <code>TIMESTAMP</code> in <code>[RAPIDS_COLUMN_MAPPINGS]</code> to your raw data column names.</p> <p>All columns are mandatory; however, all except <code>device_id</code> and <code>local_date_time</code> can be empty if you don\u2019t have that data. Just have in mind that some features will be empty if some of these columns are empty.</p> FITBIT_HEARTRATE_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME local_date_time DEVICE_ID device_id HEARTRATE_DAILY_RESTINGHR heartrate_daily_restinghr HEARTRATE_DAILY_CALORIESOUTOFRANGE heartrate_daily_caloriesoutofrange HEARTRATE_DAILY_CALORIESFATBURN heartrate_daily_caloriesfatburn HEARTRATE_DAILY_CALORIESCARDIO heartrate_daily_caloriescardio HEARTRATE_DAILY_CALORIESPEAK heartrate_daily_caloriespeak <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> Example of the raw data RAPIDS expects for this data stream device_id local_date_time heartrate_daily_restinghr heartrate_daily_caloriesoutofrange heartrate_daily_caloriesfatburn heartrate_daily_caloriescardio heartrate_daily_caloriespeak a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 72 1200.6102 760.3020 15.2048 0 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-08 70 1100.1120 660.0012 23.7088 0 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-09 69 750.3615 734.1516 131.8579 0 FITBIT_HEARTRATE_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME local_date_time DEVICE_ID device_id HEARTRATE heartrate HEARTRATE_ZONE heartrate_zone <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> Example of the raw data RAPIDS expects for this data stream device_id local_date_time heartrate heartrate_zone a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:00:00 68 outofrange a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:01:00 67 outofrange a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:02:00 67 outofrange FITBIT_SLEEP_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME FLAG_TO_MUTATE LOCAL_START_DATE_TIME local_start_date_time LOCAL_END_DATE_TIME local_end_date_time DEVICE_ID device_id EFFICIENCY efficiency MINUTES_AFTER_WAKEUP minutes_after_wakeup MINUTES_ASLEEP minutes_asleep MINUTES_AWAKE minutes_awake MINUTES_TO_FALL_ASLEEP minutes_to_fall_asleep MINUTES_IN_BED minutes_in_bed IS_MAIN_SLEEP is_main_sleep TYPE type <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>- src/data/streams/mutations/fitbit/add_local_date_time.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> <p>Fitbit API has two versions for sleep data, v1 and v1.2. We support both but ignore v1\u2019s <code>count_awake</code>, <code>duration_awake</code>, and <code>count_awakenings</code>, <code>count_restless</code>, <code>duration_restless</code> columns.</p> Example of the expected raw data device_id local_start_date_time local_end_date_time efficiency minutes_after_wakeup minutes_asleep minutes_awake minutes_to_fall_asleep minutes_in_bed is_main_sleep type a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-10 15:36:30 2020-10-10 16:37:00 92 0 55 5 0 60 0 classic a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-10 01:46:30 2020-10-10 08:10:00 88 0 318 65 0 383 1 stages a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-11 00:12:30 2020-10-11 11:47:00 89 1 562 132 0 694 1 stages a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-12 01:31:00 2020-10-12 09:34:30 93 0 415 68 0 483 1 stages FITBIT_SLEEP_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME local_date_time DEVICE_ID device_id TYPE_EPISODE_ID type_episode_id DURATION duration IS_MAIN_SLEEP is_main_sleep TYPE type LEVEL level <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> <p>Fitbit API has two versions for sleep data, v1 and v1.2, we support both.</p> Example of the expected raw data device_id type_episode_id local_date_time duration level is_main_sleep type a748ee1a-1d0b-4ae9-9074-279a2b6ba524 0 2020-10-10 15:36:30 60 restless 0 classic a748ee1a-1d0b-4ae9-9074-279a2b6ba524 0 2020-10-10 15:37:30 660 asleep 0 classic a748ee1a-1d0b-4ae9-9074-279a2b6ba524 0 2020-10-10 15:48:30 60 restless 0 classic a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 1 2020-10-10 01:46:30 420 light 1 stages a748ee1a-1d0b-4ae9-9074-279a2b6ba524 1 2020-10-10 01:53:30 1230 deep 1 stages FITBIT_STEPS_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE DEVICE_ID device_id LOCAL_DATE_TIME local_date_time STEPS steps <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> Example of the expected raw data device_id local_date_time steps a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 1775 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-08 3201 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-09 998 FITBIT_STEPS_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE DEVICE_ID device_id LOCAL_DATE_TIME local_date_time STEPS steps <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> Example of the expected raw data device_id local_date_time steps a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:00:00 5 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:01:00 3 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:02:00 0"},{"location":"datastreams/mandatory-empatica-format/","title":"Mandatory Empatica Format","text":"<p>This is a description of the format RAPIDS needs to process data for the following Empatica sensors.</p> EMPATICA_ACCELEROMETER RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device DOUBLE_VALUES_0 x axis of acceleration DOUBLE_VALUES_1 y axis of acceleration DOUBLE_VALUES_2 z axis of acceleration EMPATICA_HEARTRATE RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged (automatically created by RAPIDS) DEVICE_ID A string that uniquely identifies a device HEARTRATE Intraday heartrate EMPATICA_TEMPERATURE RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged (automatically created by RAPIDS) DEVICE_ID A string that uniquely identifies a device TEMPERATURE temperature EMPATICA_ELECTRODERMAL_ACTIVITY RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged (automatically created by RAPIDS) DEVICE_ID A string that uniquely identifies a device ELECTRODERMAL_ACTIVITY electrical conductance EMPATICA_BLOOD_VOLUME_PULSE RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged (automatically created by RAPIDS) DEVICE_ID A string that uniquely identifies a device BLOOD_VOLUME_PULSE blood volume pulse EMPATICA_INTER_BEAT_INTERVAL RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged (automatically created by RAPIDS) DEVICE_ID A string that uniquely identifies a device INTER_BEAT_INTERVAL inter beat interval EMPATICA_TAGS RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged (automatically created by RAPIDS) DEVICE_ID A string that uniquely identifies a device TAGS tags"},{"location":"datastreams/mandatory-fitbit-format/","title":"Mandatory Fitbit Format","text":"<p>This is a description of the format RAPIDS needs to process data for the following Fitbit sensors.</p> FITBIT_HEARTRATE_SUMMARY RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged (automatically created by RAPIDS) LOCAL_DATE_TIME Date time string with format <code>yyyy-mm-dd hh:mm:ss</code> DEVICE_ID A string that uniquely identifies a device HEARTRATE_DAILY_RESTINGHR Daily resting heartrate HEARTRATE_DAILY_CALORIESOUTOFRANGE Calories spent while heartrate was oustide a heartrate zone HEARTRATE_DAILY_CALORIESFATBURN Calories spent while heartrate was inside the fat burn zone HEARTRATE_DAILY_CALORIESCARDIO Calories spent while heartrate was inside the cardio zone HEARTRATE_DAILY_CALORIESPEAK Calories spent while heartrate was inside the peak zone FITBIT_HEARTRATE_INTRADAY RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged (automatically created by RAPIDS) LOCAL_DATE_TIME Date time string with format <code>yyyy-mm-dd hh:mm:ss</code> DEVICE_ID A string that uniquely identifies a device HEARTRATE Intraday heartrate HEARTRATE_ZONE Heartrate zone that HEARTRATE belongs to. It is based on the heartrate zone ranges of each device FITBIT_SLEEP_SUMMARY RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged (automatically created by RAPIDS) LOCAL_DATE_TIME Date time string with format <code>yyyy-mm-dd 00:00:00</code>, the date is the same as the start date of a daily sleep episode if its time is after SLEEP_SUMMARY_LAST_NIGHT_END, otherwise it is the day before the start date of that sleep episode LOCAL_START_DATE_TIME Date time string with format <code>yyyy-mm-dd hh:mm:ss</code> representing the start of a daily sleep episode LOCAL_END_DATE_TIME Date time string with format <code>yyyy-mm-dd hh:mm:ss</code>  representing the end of a daily sleep episode DEVICE_ID A string that uniquely identifies a device EFFICIENCY Sleep efficiency computed by fitbit as time asleep / (total time in bed - time to fall asleep) MINUTES_AFTER_WAKEUP Minutes the participant spent in bed after waking up MINUTES_ASLEEP Minutes the participant was asleep MINUTES_AWAKE Minutes the participant was awake MINUTES_TO_FALL_ASLEEP Minutes the participant spent in bed before falling asleep MINUTES_IN_BED Minutes the participant spent in bed across the sleep episode IS_MAIN_SLEEP 0 if this episode is a nap, or 1 if it is a main sleep episode TYPE stages or classic sleep data FITBIT_SLEEP_INTRADAY RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged (automatically created by RAPIDS) LOCAL_DATE_TIME Date time string with format <code>yyyy-mm-dd hh:mm:ss</code>, this either is a copy of LOCAL_START_DATE_TIME or LOCAL_END_DATE_TIME depending on which column is used to assign an episode to a specific day DEVICE_ID A string that uniquely identifies a device TYPE_EPISODE_ID An id for each unique main or nap episode. Main and nap episodes have different levels, each row in this table is one of such levels, so multiple rows can have the same TYPE_EPISODE_ID DURATION Duration of the episode level in minutes IS_MAIN_SLEEP 0 if this episode level belongs to a nap, or 1 if it belongs to a main sleep episode TYPE type of level: stages or classic sleep data LEVEL For stages levels one of <code>wake</code>, <code>deep</code>, <code>light</code>, or <code>rem</code>. For classic levels one of <code>awake</code>, <code>restless</code>, and <code>asleep</code> FITBIT_STEPS_SUMMARY RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged (automatically created by RAPIDS) LOCAL_DATE_TIME Date time string with format <code>yyyy-mm-dd hh:mm:ss</code> DEVICE_ID A string that uniquely identifies a device STEPS Daily step count FITBIT_STEPS_INTRADAY RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged (automatically created by RAPIDS) LOCAL_DATE_TIME Date time string with format <code>yyyy-mm-dd hh:mm:ss</code> DEVICE_ID A string that uniquely identifies a device STEPS Intraday step count (usually every minute)"},{"location":"datastreams/mandatory-phone-format/","title":"Mandatory Phone Format","text":"<p>This is a description of the format RAPIDS needs to process data for the following PHONE sensors.</p> <p>See examples in the CSV files inside rapids_example_csv.zip</p> PHONE_ACCELEROMETER RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device DOUBLE_VALUES_0 x axis of acceleration DOUBLE_VALUES_1 y axis of acceleration DOUBLE_VALUES_2 z axis of acceleration PHONE_ACTIVITY_RECOGNITION RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device ACTIVITY_NAME An string that denotes current activity name: <code>in_vehicle</code>, <code>on_bicycle</code>, <code>on_foot</code>, <code>still</code>, <code>unknown</code>, <code>tilting</code>, <code>walking</code> or <code>running</code> ACTIVITY_TYPE An integer (ranged from 0 to 8) that denotes current activity type CONFIDENCE An integer (ranged from 0 to 100) that denotes the prediction accuracy PHONE_APPLICATIONS_CRASHES RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device PACKAGE_NAME Application\u2019s package name APPLICATION_NAME Application\u2019s localized name APPLICATION_VERSION Application\u2019s version code ERROR_SHORT Short description of the error ERROR_LONG More verbose version of the error description ERROR_CONDITION 1 = code error; 2 = non-responsive (ANR error) IS_SYSTEM_APP Device\u2019s pre-installed application PHONE_APPLICATIONS_FOREGROUND RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device PACKAGE_NAME Application\u2019s package name APPLICATION_NAME Application\u2019s localized name IS_SYSTEM_APP Device\u2019s pre-installed application PHONE_APPLICATIONS_NOTIFICATIONS RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device PACKAGE_NAME Application\u2019s package name APPLICATION_NAME Application\u2019s localized name TEXT Notification\u2019s header text, not the content SOUND Notification\u2019s sound source (if applicable) VIBRATE Notification\u2019s vibration pattern (if applicable) DEFAULTS If notification was delivered according to device\u2019s default settings FLAGS An integer that denotes Android notification flag PHONE_BATTERY RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device BATTERY_STATUS An integer that denotes battery status: 0 or 1 = unknown, 2 = charging, 3 = discharging, 4 = not charging, 5 = full BATTERY_LEVEL An integer that denotes battery level, between 0 and <code>BATTERY_SCALE</code> BATTERY_SCALE An integer that denotes the maximum battery level PHONE_BLUETOOTH RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device BT_ADDRESS MAC address of the device\u2019s Bluetooth sensor BT_NAME User assigned name of the device\u2019s Bluetooth sensor BT_RSSI The RSSI dB to the scanned device PHONE_CALLS RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device CALL_TYPE An integer that denotes call type: 1 = incoming, 2 = outgoing, 3 = missed CALL_DURATION Length of the call session TRACE SHA-1 one-way source/target of the call PHONE_CONVERSATION RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device DOUBLE_ENERGY A number that denotes the amplitude of an audio sample (L2-norm of the audio frame) INFERENCE An integer (ranged from 0 to 3) that denotes the type of an audio sample: 0 = silence, 1 = noise, 2 = voice, 3 = unknown DOUBLE_CONVO_START UNIX timestamp (13 digits) of the beginning of a conversation DOUBLE_CONVO_END UNIX timestamp (13 digits) of the end of a conversation PHONE_KEYBOARD RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device PACKAGE_NAME The application\u2019s package name of keyboard interaction BEFORE_TEXT The previous keyboard input (empty if password) CURRENT_TEXT The current keyboard input (empty if password) IS_PASSWORD An integer: 0 = not password; 1 = password PHONE_LIGHT RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device DOUBLE_LIGHT_LUX The ambient luminance in lux units ACCURACY An integer that denotes the sensor\u2019s accuracy level: 3 = maximum accuracy, 2 = medium accuracy, 1 = low accuracy PHONE_LOCATIONS RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device DOUBLE_LATITUDE The location\u2019s latitude, in degrees DOUBLE_LONGITUDE The location\u2019s longitude, in degrees DOUBLE_BEARING The location\u2019s bearing, in degrees DOUBLE_SPEED The speed if available, in meters/second over ground DOUBLE_ALTITUDE The altitude if available, in meters above sea level PROVIDER A string that denotes the provider: <code>gps</code>, <code>fused</code> or <code>network</code> ACCURACY The estimated location accuracy PHONE_LOG RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device LOG_MESSAGE A string that denotes log message PHONE_MESSAGES RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device MESSAGE_TYPE An integer that denotes message type: 1 = received, 2 = sent TRACE SHA-1 one-way source/target of the message PHONE_SCREEN RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device SCREEN_STATUS An integer that denotes screen status: 0 = off, 1 = on, 2 = locked, 3 = unlocked PHONE_WIFI_CONNECTED RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device MAC_ADDRESS Device\u2019s MAC address SSID Currently connected access point network name BSSID Currently connected access point MAC address PHONE_WIFI_VISIBLE RAPIDS column Description TIMESTAMP An UNIX timestamp (13 digits) when a row of data was logged DEVICE_ID A string that uniquely identifies a device SSID Detected access point network name BSSID Detected access point MAC address SECURITY Active security protocols FREQUENCY Wi-Fi band frequency (e.g., 2427, 5180), in Hz RSSI RSSI dB to the scanned device"},{"location":"developers/documentation/","title":"Documentation","text":"<p>We use mkdocs with the material theme to write these docs. Whenever you make any changes, just push them back to the repo and the documentation will be deployed automatically.</p>"},{"location":"developers/documentation/#set-up-development-environment","title":"Set up development environment","text":"<ol> <li>Make sure your conda environment is active</li> <li><code>pip install mkdocs</code></li> <li><code>pip install mkdocs-material</code></li> </ol>"},{"location":"developers/documentation/#preview","title":"Preview","text":"<p>Run the following command in RAPIDS root folder and go to http://127.0.0.1:8000:</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"developers/documentation/#file-structure","title":"File Structure","text":"<p>The documentation config file is <code>/mkdocs.yml</code>, if you are adding new <code>.md</code> files to the docs modify the <code>nav</code> attribute at the bottom of that file. You can use the hierarchy there to find all the files that appear in the documentation.</p>"},{"location":"developers/documentation/#reference","title":"Reference","text":"<p>Check this page to get familiar with the different visual elements we can use in the docs (admonitions, code blocks, tables, etc.) You can also refer to <code>/docs/setup/installation.md</code> and <code>/docs/setup/configuration.md</code> to see practical examples of these elements.</p> <p>Hint</p> <p>Any links to internal pages should be relative to the current page. For example, any link from this page (documentation) which is inside <code>./developers</code> should begin with <code>../</code> to go one folder level up like: <pre><code>[mylink](../setup/installation.md)\n</code></pre></p>"},{"location":"developers/documentation/#extras","title":"Extras","text":"<p>You can insert emojis using this syntax <code>:[SOURCE]-[ICON_NAME]</code> from the following sources:</p> <ul> <li>https://materialdesignicons.com/</li> <li>https://fontawesome.com/icons/tasks?style=solid</li> <li>https://primer.style/octicons/</li> </ul> <p>You can use this page to create markdown tables more easily</p>"},{"location":"developers/git-flow/","title":"Git Flow","text":"<p>We use the <code>develop/master</code> variation of the OneFlow git flow</p>"},{"location":"developers/git-flow/#add-new-features","title":"Add New Features","text":"<p>We use feature (topic) branches to implement new features</p> Internal Developer <p>You are an internal developer if you have writing permissions to the repository.</p> <p>Most feature branches are never pushed to the repo, only do so if you expect that its development will take days (to avoid losing your work if you computer is damaged). Otherwise follow the following instructions to locally rebase your feature branch into <code>develop</code> and push those rebased changes online.</p> <p>Starting your feature branch</p> <ol> <li>Pull the latest develop  <pre><code>git checkout develop\ngit pull\n</code></pre></li> <li>Create your feature branch <pre><code>git checkout -b feature/feature1\n</code></pre></li> <li>Add, modify or delete the necessary files to add your new feature</li> <li>Update the change log (<code>docs/change-log.md</code>)</li> <li>Stage and commit your changes using VS Code git GUI or the following commands <pre><code>git add modified-file1 modified-file2\ngit commit -m \"Add my new feature\" # use a concise description\n</code></pre></li> </ol> <p>Merging back your feature branch</p> <p>If your changes took time to be implemented it is possible that there are new commits in our <code>develop</code> branch, so we need to rebase your feature branch.</p> <ol> <li> <p>Fetch the latest changes to develop <pre><code>git fetch origin develop\n</code></pre></p> </li> <li> <p>Rebase your feature branch <pre><code>git checkout feature/feature1\ngit rebase -i develop\n</code></pre></p> </li> <li> <p>Integrate your new feature to <code>develop</code> <pre><code>git checkout develop\ngit merge --no-ff feature/feature1 # (use the default merge message)\ngit push origin develop\ngit branch -d feature/feature1\n</code></pre></p> </li> </ol> External Developer <p>You are an external developer if you do NOT have writing permissions to the repository.</p> <p>Starting your feature branch</p> <ol> <li>Fork and clone our repository on Github</li> <li>Switch to the latest develop  <pre><code>git checkout develop\n</code></pre></li> <li>Create your feature branch <pre><code>git checkout -b feature/external-test\n</code></pre></li> <li>Add, modify or delete the necessary files to add your new feature</li> <li>Stage and commit your changes using VS Code git GUI or the following commands <pre><code>git add modified-file1 modified-file2\ngit commit -m \"Add my new feature\" # use a concise description\n</code></pre></li> </ol> <p>Merging back your feature branch</p> <p>If your changes took time to be implemented, it is possible that there are new commits in our <code>develop</code> branch, so we need to rebase your feature branch.</p> <ol> <li> <p>Add our repo as another <code>remote</code> <pre><code>git remote add upstream https://github.com/carissalow/rapids/\n</code></pre></p> </li> <li> <p>Fetch the latest changes to develop <pre><code>git fetch upstream develop \n</code></pre></p> </li> <li> <p>Rebase your feature branch <pre><code>git checkout feature/external-test\ngit rebase -i develop\n</code></pre></p> </li> <li> <p>Push your feature branch online <pre><code>git push --set-upstream origin feature/external-test\n</code></pre></p> </li> <li> <p>Open a pull request to the <code>develop</code> branch using Github\u2019s GUI</p> </li> </ol>"},{"location":"developers/git-flow/#release-a-new-version","title":"Release a New Version","text":"<ol> <li>Pull the latest develop  <pre><code>git checkout develop\ngit pull\n</code></pre></li> <li>Create a new release branch <pre><code>git describe --abbrev=0 --tags # Bump the release (0.1.0 to 0.2.0 =&gt; NEW_HOTFIX)\ngit checkout -b release/v[NEW_RELEASE] develop\n</code></pre></li> <li>Add new tag <pre><code>git tag v[NEW_RELEASE]\n</code></pre></li> <li>Merge and push the release branch <pre><code>git checkout develop\ngit merge release/v[NEW_RELEASE]\ngit push --tags origin develop\ngit branch -d release/v[NEW_RELEASE]\n</code></pre></li> <li>Fast-forward master <pre><code>git checkout master\ngit merge --ff-only develop\ngit push\n</code></pre></li> <li>Go to GitHub and create a new release based on the newest tag <code>v[NEW_RELEASE]</code> (remember to add the change log)</li> </ol>"},{"location":"developers/git-flow/#release-a-hotfix","title":"Release a Hotfix","text":"<ol> <li>Pull the latest master <pre><code>git checkout master\ngit pull\n</code></pre></li> <li>Start a hotfix branch <pre><code>git describe --abbrev=0 --tags # Bump the hotfix (0.1.0 to 0.1.1 =&gt; NEW_HOTFIX)\ngit checkout -b hotfix/v[NEW_HOTFIX] master\n</code></pre></li> <li>Fix whatever needs to be fixed</li> <li>Update the change log</li> <li>Tag and merge the hotfix <pre><code>git tag v[NEW_HOTFIX]\ngit checkout develop\ngit merge hotfix/v[NEW_HOTFIX]\ngit push --tags origin develop\ngit branch -d hotfix/v[NEW_HOTFIX]\n</code></pre></li> <li>Fast-forward master <pre><code>git checkout master\ngit merge --ff-only v[NEW_HOTFIX]\ngit push\n</code></pre></li> <li>Go to GitHub and create a new release based on the newest tag <code>v[NEW_HOTFIX]</code> (remember to add the change log)</li> </ol>"},{"location":"developers/remote-support/","title":"Remote Support","text":"<p>We use the Live Share extension of Visual Studio Code to debug bugs when sharing data or database credentials is not possible.</p> <ol> <li>Install Visual Studio Code</li> <li>Open your RAPIDS root folder in a new VSCode window</li> <li>Open a new terminal in Visual Studio Code <code>Terminal &gt; New terminal</code></li> <li>Install the Live Share extension pack</li> <li> <p>Press Ctrl+P or Cmd+P and run this command:</p> <pre><code>&gt;live share: start collaboration session\n</code></pre> </li> <li> <p>Follow the instructions and share the session link you receive</p> </li> </ol>"},{"location":"developers/test-cases/","title":"Test Cases","text":"<p>Along with the continued development and the addition of new sensors and features to the RAPIDS pipeline, tests for the currently available sensors and features are being implemented. Since this is a Work In Progress this page will be updated with the list of sensors and features for which testing is available. For each of the sensors listed a description of the data used for testing (test cases) are outline. Currently for all intent and testing purposes the <code>tests/data/raw/test01/</code> contains all the test data files for testing android data formats and <code>tests/data/raw/test02/</code> contains all the test data files for testing iOS data formats. It follows that the expected (verified output) are contained in the <code>tests/data/processed/test01/</code> and <code>tests/data/processed/test02/</code> for Android and iOS respectively. <code>tests/data/raw/test03/</code> and <code>tests/data/raw/test04/</code> contain data files for testing empty raw data files for android and iOS respectively.</p> <p>The following is a list of the sensors that testing is currently available.</p> Sensor Provider Periodic Frequency Event Phone Accelerometer Panda N N N Phone Accelerometer RAPIDS N N N Phone Activity Recognition RAPIDS N N N Phone Applications Foreground RAPIDS N N N Phone Battery RAPIDS Y Y N Phone Bluetooth Doryab N N N Phone Bluetooth RAPIDS Y Y Y Phone Calls RAPIDS Y Y N Phone Conversation RAPIDS Y Y N Phone Data Yield RAPIDS N N N Phone Light RAPIDS Y Y N Phone Locations Doryab N N N Phone Locations Barnett N N N Phone Messages RAPIDS Y Y N Phone Screen RAPIDS Y N N Phone WiFi Connected RAPIDS Y Y N Phone WiFi Visible RAPIDS Y Y N Fitbit Calories Intraday RAPIDS Y Y Y Fitbit Data Yield RAPIDS N N N Fitbit Heart Rate Summary RAPIDS N N N Fitbit Heart Rate Intraday RAPIDS N N N Fitbit Sleep Summary RAPIDS N N N Fitbit Sleep Intraday RAPIDS Y Y Y Fitbit Sleep Intraday PRICE Y Y Y Fitbit Steps Summary RAPIDS N N N Fitbit Steps Intraday RAPIDS N N N"},{"location":"developers/test-cases/#messages-sms","title":"Messages (SMS)","text":"<ul> <li>The raw message data file contains data for 2 separate days.</li> <li>The data for the first day contains records 5 records for every     <code>epoch</code>.</li> <li>The second day's data contains 6 records for each of only 2     <code>epoch</code> (currently <code>morning</code> and <code>evening</code>)</li> <li>The raw message data contains records for both <code>message_types</code>     (i.e. <code>recieved</code> and <code>sent</code>) in both days in all epochs. The     number records with each <code>message_types</code> per epoch is randomly     distributed There is at least one records with each     <code>message_types</code> per epoch.</li> <li>There is one raw message data file each, as described above, for     testing both iOS and Android data.</li> <li>There is also an additional empty data file for both android and     iOS for testing empty data files</li> </ul>"},{"location":"developers/test-cases/#calls","title":"Calls","text":"<p>Due to the difference in the format of the raw call data for iOS and Android the following is the expected results the <code>calls_with_datetime_unified.csv</code>. This would give a better idea of the use cases being tested since the <code>calls_with_datetime_unified.csv</code> would make both the iOS and Android data comparable.</p> <ul> <li>The call data would contain data for 2 days.</li> <li>The data for the first day contains 6 records for every <code>epoch</code>.</li> <li>The second day's data contains 6 records for each of only 2     <code>epoch</code> (currently <code>morning</code> and <code>evening</code>)</li> <li>The call data contains records for all <code>call_types</code> (i.e.     <code>incoming</code>, <code>outgoing</code> and <code>missed</code>) in both days in all epochs.     The number records with each of the <code>call_types</code> per epoch is     randomly distributed. There is at least one records with each     <code>call_types</code> per epoch.</li> <li>There is one call data file each, as described above, for testing     both iOS and Android data.</li> <li>There is also an additional empty data file for both android and     iOS for testing empty data files</li> </ul>"},{"location":"developers/test-cases/#screen","title":"Screen","text":"<p>Due to the difference in the format of the raw screen data for iOS and Android the following is the expected results the <code>screen_deltas.csv</code>. This would give a better idea of the use cases being tested since the <code>screen_eltas.csv</code> would make both the iOS and Android data comparable These files are used to calculate the features for the screen sensor</p> <ul> <li>The screen delta data file contains data for 1 day.</li> <li>The screen delta data contains 1 record to represent an <code>unlock</code>     episode that falls within an <code>epoch</code> for every <code>epoch</code>.</li> <li>The screen delta data contains 1 record to represent an <code>unlock</code>     episode that falls across the boundary of 2 epochs. Namely the     <code>unlock</code> episode starts in one epoch and ends in the next, thus     there is a record for <code>unlock</code> episodes that fall across <code>night</code>     to <code>morning</code>, <code>morning</code> to <code>afternoon</code> and finally <code>afternoon</code> to     <code>night</code></li> <li>The testing is done for <code>unlock</code> episode_type.</li> <li>There is one screen data file each for testing both iOS and     Android data formats.</li> <li>There is also an additional empty data file for both android and     iOS for testing empty data files</li> </ul>"},{"location":"developers/test-cases/#battery","title":"Battery","text":"<p>Due to the difference in the format of the raw battery data for iOS and Android as well as versions of iOS the following is the expected results the <code>battery_deltas.csv</code>. This would give a better idea of the use cases being tested since the <code>battery_deltas.csv</code> would make both the iOS and Android data comparable. These files are used to calculate the features for the battery sensor.</p> <ul> <li>The battery delta data file contains data for 1 day.</li> <li>The battery delta data contains 1 record each for a <code>charging</code> and     <code>discharging</code> episode that falls within an <code>epoch</code> for every     <code>epoch</code>. Thus, for the <code>daily</code> epoch there would be multiple     <code>charging</code> and <code>discharging</code> episodes</li> <li>Since either a <code>charging</code> episode or a <code>discharging</code> episode and     not both can occur across epochs, in order to test episodes that     occur across epochs alternating episodes of <code>charging</code> and     <code>discharging</code> episodes that fall across <code>night</code> to <code>morning</code>,     <code>morning</code> to <code>afternoon</code> and finally <code>afternoon</code> to <code>night</code> are     present in the battery delta data. This starts with a     <code>discharging</code> episode that begins in <code>night</code> and end in <code>morning</code>.</li> <li>There is one battery data file each, for testing both iOS and     Android data formats.</li> <li>There is also an additional empty data file for both android and     iOS for testing empty data files</li> </ul>"},{"location":"developers/test-cases/#bluetooth","title":"Bluetooth","text":"<ul> <li>The raw Bluetooth data file contains data for 1 day.</li> <li>The raw Bluetooth data contains at least 2 records for each     <code>epoch</code>. Each <code>epoch</code> has a record with a <code>timestamp</code> for the     beginning boundary for that <code>epoch</code> and a record with a     <code>timestamp</code> for the ending boundary for that <code>epoch</code>. (e.g. For     the <code>morning</code> epoch there is a record with a <code>timestamp</code> for     <code>6:00AM</code> and another record with a <code>timestamp</code> for <code>11:59:59AM</code>.     These are to test edge cases)</li> <li>An option of 5 Bluetooth devices are randomly distributed     throughout the data records.</li> <li>There is one raw Bluetooth data file each, for testing both iOS     and Android data formats.</li> <li>There is also an additional empty data file for both android and     iOS for testing empty data files.</li> </ul>"},{"location":"developers/test-cases/#wifi","title":"WIFI","text":"<ul> <li>There are 2 data files (<code>wifi_raw.csv</code> and <code>sensor_wifi_raw.csv</code>)     for each fake participant for each phone platform. </li> <li>The raw WIFI data files contain data for 1 day.</li> <li>The <code>sensor_wifi_raw.csv</code> data contains at least 2 records for     each <code>epoch</code>. Each <code>epoch</code> has a record with a <code>timestamp</code> for the     beginning boundary for that <code>epoch</code> and a record with a     <code>timestamp</code> for the ending boundary for that <code>epoch</code>. (e.g. For     the <code>morning</code> epoch there is a record with a <code>timestamp</code> for     <code>6:00AM</code> and another record with a <code>timestamp</code> for <code>11:59:59AM</code>.     These are to test edge cases)</li> <li>The <code>wifi_raw.csv</code> data contains 3 records with random timestamps     for each <code>epoch</code> to represent visible broadcasting WIFI network.     This file is empty for the iOS phone testing data.</li> <li>An option of 10 access point devices is randomly distributed     throughout the data records. 5 each for <code>sensor_wifi_raw.csv</code> and     <code>wifi_raw.csv</code>.</li> <li>There data files for testing both iOS and Android data formats.</li> <li>There are also additional empty data files for both android and     iOS for testing empty data files.</li> </ul>"},{"location":"developers/test-cases/#light","title":"Light","text":"<ul> <li>The raw light data file contains data for 1 day.</li> <li>The raw light data contains 3 or 4 rows of data for each <code>epoch</code>     except <code>night</code>. The single row of data for <code>night</code> is for testing     features for single values inputs. (Example testing the standard     deviation of one input value)</li> <li>Since light is only available for Android there is only one file     that contains data for Android. All other files (i.e. for iPhone)     are empty data files.</li> </ul>"},{"location":"developers/test-cases/#application-foreground","title":"Application Foreground","text":"<ul> <li>The raw application foreground data file contains data for 1 day.</li> <li>The raw application foreground data contains 7 - 9 rows of data     for each <code>epoch</code>. The records for each <code>epoch</code> contains apps that     are randomly selected from a list of apps that are from the     <code>MULTIPLE_CATEGORIES</code> and <code>SINGLE_CATEGORIES</code> (See     testing_config.yaml). There are also records in each epoch     that have apps randomly selected from a list of apps that are from     the <code>EXCLUDED_CATEGORIES</code> and <code>EXCLUDED_APPS</code>. This is to test     that these apps are actually being excluded from the calculations     of features. There are also records to test <code>SINGLE_APPS</code>     calculations.</li> <li>Since application foreground is only available for Android there     is only one file that contains data for Android. All other files     (i.e. for iPhone) are empty data files.</li> </ul>"},{"location":"developers/test-cases/#activity-recognition","title":"Activity Recognition","text":"<ul> <li>The raw Activity Recognition data file contains data for 1 day.</li> <li>The raw Activity Recognition data each <code>epoch</code> period contains     rows that records 2 - 5 different <code>activity_types</code>. The is such     that durations of activities can be tested. Additionally, there     are records that mimic the duration of an activity over the time     boundary of neighboring epochs. (For example, there a set of     records that mimic the participant <code>in_vehicle</code> from <code>afternoon</code>     into <code>evening</code>)</li> <li>There is one file each with raw Activity Recognition data for     testing both iOS and Android data formats.     (plugin_google_activity_recognition_raw.csv for android and     plugin_ios_activity_recognition_raw.csv for iOS)</li> <li>There is also an additional empty data file for both android and     iOS for testing empty data files.</li> </ul>"},{"location":"developers/test-cases/#conversation","title":"Conversation","text":"<ul> <li>The raw conversation data file contains data for 2 day.</li> <li>The raw conversation data contains records with a sample of both     <code>datatypes</code> (i.e. <code>voice/noise</code> = <code>0</code>, and <code>conversation</code> = <code>2</code> )     as well as rows with for samples of each of the <code>inference</code> values     (i.e. <code>silence</code> = <code>0</code>, <code>noise</code> = <code>1</code>, <code>voice</code> = <code>2</code>, and <code>unknown</code>     = <code>3</code>) for each <code>epoch</code>. The different <code>datatype</code> and <code>inference</code>     records are randomly distributed throughout the <code>epoch</code>.</li> <li>Additionally there are 2 - 5 records for conversations (<code>datatype</code>     = 2, and <code>inference</code> = -1) in each <code>epoch</code> and for each <code>epoch</code>     except night, there is a conversation record that has a     <code>double_convo_start</code> <code>timestamp</code> that is from the previous     <code>epoch</code>. This is to test the calculations of features across     <code>epochs</code>.</li> <li>There is a raw conversation data file for both android and iOS     platforms (<code>plugin_studentlife_audio_android_raw.csv</code> and     <code>plugin_studentlife_audio_raw.csv</code> respectively).</li> <li>Finally, there are also additional empty data files for both     android and iOS for testing empty data files</li> </ul>"},{"location":"developers/test-cases/#fitbit-calories-intraday","title":"Fitbit Calories Intraday","text":"<p>Description</p> <ul> <li>A five-minute sedentary episode on Fri 11:00:00</li> <li>A one-minute sedentary episode on Sun 02:00:00. It exists in November but not in February in STZ</li> <li>A five-minute sedentary episode on Fri 11:58:00. It is split within two 30-min segments and the morning</li> <li>A three-minute lightly active episode on Fri 11:10:00, a one-minute at 11:18:00 and a one-minute 11:24:00. These check for start and end times of first/last/longest episode</li> <li>A three-minute fairly active episode on Fri 11:40:00, a one-minute at 11:48:00 and a one-minute 11:54:00. These check for start and end times of first/last/longest episode</li> <li>A three-minute very active episode on Fri 12:10:00, a one-minute at 12:18:00 and a one-minute 12:24:00. These check for start and end times of first/last/longest episode</li> <li>A eight-minute MVPA episode with intertwined fairly and very active rows on Fri 12:30:00</li> <li>The above episodes contain six higmet (&gt;= 3 MET) episodes and nine lowmet episodes.</li> <li>One two-minute sedentary episode with a 1-minute row on Sun 09:00:00 and another on Sun 12:01:01 that are considering a single episode in multi-timezone event segments to showcase how inferring time zone data for Fitbit from phone data can produce inaccurate results around the tz change. This happens because the device was on LA time until 11:59 and switched to NY time at 12pm, in terms of actual time 09 am LA and 12 pm NY represent the same moment in time so 09:00 LA and 12:01 NY are consecutive minutes.</li> <li>A three-minute sedentary episode on Sat 08:59 that will be ignored for multi-timezone event segments.</li> <li>A three-minute sedentary episode on Sat 12:59 of which the first minute will be ignored for multi-timezone event segments since the test segment starts at 13:00</li> <li>A three-minute sedentary episode on Sat 16:00</li> <li>A four-minute sedentary episode on Sun 10:01 that will be ignored for Novembers\u2019s multi-timezone event segments since the test segment ends at 10am on that weekend.</li> <li>A three-minute very active episode on Sat 16:03. This episode and the one at 16:00 are counted as one for lowmet episodes</li> </ul> <p>Checklist</p> time segment single tz multi tz platform 30min OK OK fitbit morning OK OK fitbit daily OK OK fitbit threeday OK OK fitbit weekend OK OK fitbit beforeMarchEvent OK OK fitbit beforeNovemberEvent OK OK fitbit"},{"location":"developers/test-cases/#fitbit-sleep-summary","title":"Fitbit Sleep Summary","text":"<p>Description</p> <ul> <li>A main sleep episode that starts on Fri 20:00:00 and ends on Sat 02:00:00. This episode starts after 11am (Last Night End) which will be considered as today\u2019s (Fri) data.</li> <li>A nap that starts on Sat 04:00:00 and ends on Sat 06:00:00. This episode starts before 11am (Last Night End) which will be considered as yesterday\u2019s (Fri) data.</li> <li>A nap that starts on Sat 13:00:00 and ends on Sat 15:00:00. This episode starts after 11am (Last Night End) which will be considered as today\u2019s (Sat) data.</li> <li>A main sleep that starts on Sun 01:00:00 and ends on Sun 12:00:00. This episode starts before 11am (Last Night End) which will be considered as yesterday\u2019s (Sat) data.</li> <li>A main sleep that starts on Sun 23:00:00 and ends on Mon 07:00:00. This episode starts after 11am (Last Night End) which will be considered as today\u2019s (Sun) data.</li> <li>Any segment shorter than one day will be ignored for sleep RAPIDS features.</li> </ul> <p>Checklist</p> time segment single tz multi tz platform 30min OK OK fitbit morning OK OK fitbit daily OK OK fitbit threeday OK OK fitbit weekend OK OK fitbit beforeMarchEvent OK OK fitbit beforeNovemberEvent OK OK fitbit"},{"location":"developers/test-cases/#fitbit-sleep-intraday","title":"Fitbit Sleep Intraday","text":"<p>Description</p> <ul> <li>A five-minute main sleep episode with asleep-classic level on Fri 11:00:00.</li> <li>An eight-hour main sleep episode on Fri 17:00:00. It is split into 2 parts for daily segment: a seven-hour sleep episode on Fri 17:00:00 and an one-hour sleep episode on Sat 00:00:00.</li> <li>A two-hour nap on Sat 01:00:00 that will be ignored for main sleep features.</li> <li>An one-hour nap on Sat 13:00:00 that will be ignored for main sleep features.</li> <li>An eight-hour main sleep episode on Sat 22:00:00. This episode ends on Sun 08:00:00 (NY) for March and Sun 06:00:00 (NY) for Novembers due to daylight savings. It will be considered for <code>beforeMarchEvent</code> segment and ignored for <code>beforeNovemberEvent</code> segment.</li> <li>A nine-hour main sleep episode on Sun 11:00:00. Start time will be assigned as NY time zone and converted to 14:00:00.</li> <li>A seven-hour main sleep episode on Mon 06:00:00. This episode will be split into two parts: a five-hour sleep episode on Mon 06:00:00 and a two-hour sleep episode on Mon 11:00:00. The first part will be discarded as it is before 11am (Last Night End)</li> <li>Any segment shorter than one day will be ignored for sleep PRICE features.</li> </ul> <p>Checklist</p> time segment single tz multi tz platform 30min OK OK fitbit morning OK OK fitbit daily OK OK fitbit threeday OK OK fitbit weekend OK OK fitbit beforeMarchEvent OK OK fitbit beforeNovemberEvent OK OK fitbit"},{"location":"developers/testing/","title":"Testing","text":"<p>The following is a simple guide to run RAPIDS\u2019 tests. All files necessary for testing are stored in the <code>./tests/</code> directory</p>"},{"location":"developers/testing/#steps-for-testing","title":"Steps for Testing","text":"Testing Overview <ol> <li>You have to create a single four day test dataset for the sensor you are working on. </li> <li>You will adjust your dataset with <code>tests/script/assign_test_timestamps.py</code> to fit <code>Fri March 6th 2020 - Mon March 9th 2020</code> and <code>Fri Oct 30th 2020 - Mon Nov 2nd 2020</code>. We test daylight saving times with these dates.</li> <li>We have one test participant per platform (<code>pids</code>: <code>android</code>, <code>ios</code>, <code>fitbit</code>, <code>empatica</code>, <code>empty</code>). The data <code>device_id</code> should be equal to the <code>pid</code>.</li> <li>We will run this test dataset against six test pipelines, three for <code>frequency</code>, <code>periodic</code>, and <code>event</code> time segments in a <code>single</code> time zone, and the same three in <code>multiple</code> time zones.</li> <li>You will have to create your test data to cover as many corner cases as possible. These cases depend on the sensor you are working on.</li> <li>The time segments and time zones to be tested are:</li> </ol> Frequency <ul> <li>30 minutes (<code>30min,30</code>)</li> </ul> Periodic <ul> <li>morning (<code>morning,06:00:00,5H 59M 59S,every_day,0</code>)</li> <li>daily (<code>daily,00:00:00,23H 59M 59S,every_day,0</code>)</li> <li>three-day segments that repeat every day (<code>threeday,00:00:00,71H 59M 59S,every_day,0</code>)</li> <li>three-day segments that repeat every Friday (<code>weekend,00:00:00,71H 59M 59S,wday,5</code>)</li> </ul> Event <ul> <li>A segment that starts 3 hour before an event (Sat Mar 07 2020 19:00:00 EST) and lasts for 22 hours. Note that the last part of this segment will happen during a daylight saving change on Sunday at 2am when the clock moves forward and the period 2am-3am does not exist. In this case, the segment would start on Sat Mar 07 2020 16:00:00 EST (timestamp: 1583614800000) and end on Sun Mar 08 2020 15:00:00 EST (timestamp: 1583694000000). (<code>beforeMarchEvent,1583625600000,22H,3H,-1,android</code>)</li> <li>A segment that starts 3 hour before an event (Sat Oct 31 2020 19:00:00 EST) and lasts for 22 hours. Note that the last part of this segment will happen during a daylight saving change on Sunday at 2am when the clock moves back and the period 1am-2am exists twice. In this case, the segment would start on Sat Oct 31 2020 16:00:00 EST (timestamp: 1604174400000) and end on Sun Nov 01 2020 13:00:00 EST (timestamp: 1604253600000). (<code>beforeNovemberEvent,1604185200000,22H,3H,-1,android</code>)</li> </ul> Single time zone to test <p>America/New_York</p> Multi time zones to test <ul> <li>America/New_York starting at <code>0</code></li> <li>America/Los_Angeles starting at <code>1583600400000</code> (Sat Mar 07 2020 12:00:00 EST)</li> <li>America/New_York starting at <code>1583683200000</code> (Sun Mar 08 2020 12:00:00 EST)</li> <li>America/Los_Angeles starting at <code>1604160000000</code> (Sat Oct 31 2020 12:00:00 EST)</li> <li>America/New_York starting at <code>1604250000000</code> (Sun Nov 01 2020 12:00:00 EST)</li> </ul> Understanding event segments with multi timezones <p> </p> Document your tests <ul> <li>Before you start implementing any test data you need to document your tests. </li> <li>The documentation of your tests should be added to <code>docs/developers/test-cases.md</code> under the corresponding sensor. </li> <li>You will need to add two subsections <code>Description</code> and the <code>Checklist</code></li> <li>The amount of data you need depends on each sensor but you can be efficient by creating data that covers corner cases in more than one time segment. For example, a battery episode from 11am to 1pm, covers the case when an episode has to be split for 30min frequency segments and for morning segments.</li> <li>As a rule of thumb think about corner cases for 30min segments as they will give you the most flexibility.</li> <li>Only add tests for iOS if the raw data format is different than Android\u2019s (for example for screen)</li> <li>Create specific tests for Sunday before and after 02:00. These will test daylight saving switches, in March 02:00 to 02:59 do not exist, and in November 01:00 to 01:59 exist twice (read below how <code>tests/script/assign_test_timestamps.py</code> handles this)</li> </ul> Example of Description <p><code>Description</code> is a list and every item describes the different scenarios your test data is covering. For example, if we are testing PHONE_BATTERY:</p> <pre><code>- We test 24 discharge episodes, 24 charge episodes and 2 episodes with a 0 discharge rate\n- One episode is shorter than 30 minutes (`start timestamp` to `end timestamp`)\n- One episode is 120 minutes long from 11:00 to 13:00 (`start timestamp` to `end timestamp`). This one covers the case when an episode has to be chunked for 30min frequency segments and for morning segments\n- One episode is 60 minutes long from 23:30 to 00:30 (`start timestamp` to `end timestamp`). This one covers the case when an episode has to be chunked for 30min frequency segments and for daly segments (overnight)\n- One 0 discharge rate episode 10 minutes long that happens within a 30-minute segment (10:00 to 10:29) (`start timestamp` to `end timestamp`)\n- Three discharge episodes that happen between during beforeMarchEvent (start/end timestamps of those discharge episodes)\n- Three charge episodes that happen between during beforeMarchEvent (start/end timestamps of those charge episodes)\n- One discharge episode that happen between 00:30 and 04:00 to test for daylight saving times in March and Novemeber 2020.\n- ... any other test corner cases you can think of\n</code></pre> <p>Describe your test cases in as much detail as possible so in the future if we find a bug in RAPIDS, we know what test case we did not include and should add.</p> Example of Checklist <p><code>Checklist</code> is a table where you confirm you have verified the output of your dataset for the different time segments and time zones</p> time segment single tz multi tz platform 30min OK OK android and iOS morning OK OK android and iOS daily OK OK android and iOS threeday OK OK android and iOS weekend OK OK android and iOS beforeMarchEvent OK OK android and iOS beforeNovemberEvent OK OK android and iOS Add raw input data. <ol> <li>Add the raw test data to the corresponding sensor CSV file in <code>tests/data/manual/aware_csv/SENSOR_raw.csv</code>. Create the CSV if it does not exist.</li> <li>The test data you create will have the same columns as normal raw data except <code>test_time</code> replaces <code>timestamp</code>. To make your life easier, you can place a test data row in time using the <code>test_time</code> column with the following format: <code>Day HH:MM:SS.XXX</code>, for example <code>Fri 22:54:30.597</code>.</li> <li> <p>You can convert your manual test data to actual raw test data with the following commands:</p> <ul> <li> <p>For the selected files: (It could be a single file name or multiple file names separated by whitespace(s))     <pre><code>python tests/scripts/assign_test_timestamps.py -f file_name_1 file_name_2\n</code></pre></p> </li> <li> <p>For all files under the <code>tests/data/manual/aware_csv</code> folder:      <pre><code>python tests/scripts/assign_test_timestamps.py -a\n</code></pre></p> </li> </ul> </li> <li> <p>The script <code>assign_test_timestamps.py</code> converts you <code>test_time</code> column into a <code>timestamp</code>. For example, <code>Fri 22:54:30.597</code> is converted to <code>1583553270597</code> (<code>Fri Mar 06 2020 22:54:30 GMT-0500</code>) and to <code>1604112870597</code> (<code>Fri Oct 30 2020 22:54:30 GMT-0400</code>). Note you can include milliseconds.</p> </li> <li>The <code>device_id</code> should be the same as <code>pid</code>.</li> </ol> Example of test data you need to create <p>The <code>test_time</code> column will be automatically converted to a timestamp that fits our testing periods in March and November by <code>tests/script/assign_test_timestamps.py</code></p> <pre><code>test_time,device_id,battery_level,battery_scale,battery_status\nFri 01:00:00.000,ios,90,100,4\nFri 01:00:30.500,ios,89,100,4\nFri 01:01:00.000,ios,80,100,4\nFri 01:01:45.500,ios,79,100,4\n...\nSat 08:00:00.000,ios,78,100,4\nSat 08:01:00.000,ios,50,100,4\nSat 08:02:00.000,ios,49,100,4\n</code></pre> Add expected output data. <ol> <li>Add or update the expected output feature file of the participant and sensor you are testing: <pre><code>tests/data/processed/features/{type_of_time_segment}/{pid}/device_sensor.csv \n\n# this example is expected output data for battery tests for periodic segments in a single timezone\ntests/data/processed/features/stz_periodic/android/phone_sensor.csv \n\n# this example is expected output data for battery tests for periodic segments in multi timezones\ntests/data/processed/features/mtz_periodic/android/phone_sensor.csv \n</code></pre></li> </ol> Edit the config file(s). <ol> <li>Activate the sensor provider you are testing if it isn\u2019t already. Set <code>[SENSOR][PROVIDER][COMPUTE]</code> to <code>TRUE</code> in the <code>config.yaml</code> of the time segments and time zones you are testing: <pre><code>- tests/settings/stz_frequency_config.yaml # For single-timezone frequency time segments\n- tests/settings/stz_periodic_config.yaml # For single-timezone periodic time segments\n- tests/settings/stz_event_config.yaml # For single-timezone event time segments\n\n- tests/settings/mtz_frequency_config.yaml # For multi-timezone frequency time segments\n- tests/settings/mtz_periodic_config.yaml # For multi-timezone periodic time segments\n- tests/settings/mtz_event_config.yaml # For multi-timezone event time segments\n</code></pre></li> </ol> Run the pipeline and tests. <ol> <li>You can run all six segment pipelines and their tests <pre><code>bash tests/scripts/run_tests.sh -t all\n</code></pre></li> <li>You can run only the pipeline of a specific time segment and its tests <pre><code>bash tests/scripts/run_tests.sh -t stz_frequency -a both # swap stz_frequency for mtz_frequency, stz_event, mtz_event, etc\n</code></pre></li> <li>Or, if you are working on your tests and you want to run a pipeline and its tests independently <pre><code>bash tests/scripts/run_tests.sh -t stz_frequency -a run\nbash tests/scripts/run_tests.sh -t stz_frequency -a test\n</code></pre></li> </ol> How does the test execution work? <p>This bash script <code>tests/scripts/run_tests.sh</code> executes one or all test pipelines for different time segment types (<code>frequency</code>, <code>periodic</code>, and <code>events</code>) and single or multiple timezones.</p> <p>The python script <code>tests/scripts/run_tests.py</code> runs the tests. It parses the involved participants and active sensor providers in the <code>config.yaml</code> file of the time segment type and time zone being tested. We test that the output file we expect exists and that its content matches the expected values.</p> Output Example <p>The following is a snippet of the output you should see after running your test.</p> <pre><code>test_sensors_files_exist (test_sensor_features.TestSensorFeatures) ... stz_periodic\nok\ntest_sensors_features_calculations (test_sensor_features.TestSensorFeatures) ... stz_periodic\nok\n\ntest_sensors_files_exist (test_sensor_features.TestSensorFeatures) ... stz_frequency\nok\ntest_sensors_features_calculations (test_sensor_features.TestSensorFeatures) ... stz_frequency\nFAIL\n</code></pre> <p>The results above show that the for stz_periodic, both <code>test_sensors_files_exist</code> and <code>test_sensors_features_calculations</code> passed. While for stz_frequency, the first test <code>test_sensors_files_exist</code> passed while <code>test_sensors_features_calculations</code> failed. Additionally, you should get the traceback of the failure (not shown here).</p>"},{"location":"developers/validation-schema-config/","title":"Validation schema of <code>config.yaml</code>","text":"<p>Why do we need to validate the <code>config.yaml</code>?</p> <p>Most of the key/values in the <code>config.yaml</code> are constrained to a set of possible values or types. For example <code>[TIME_SEGMENTS][TYPE]</code> can only be one of <code>[\"FREQUENCY\", \"PERIODIC\", \"EVENT\"]</code>, and <code>[TIMEZONE]</code> has to be a string. </p> <p>We should show the user an error if that\u2019s not the case. We could validate this in Python or R but since we reuse scripts and keys in multiple places, tracking these validations can be time consuming and get out of control. Thus, we do these validations through a schema and check that schema before RAPIDS starts processing any data so the user can see the error right away.</p> <p>Keep in mind these validations can only cover certain base cases. Some validations that require more complex logic should still be done in the respective script. For example, we can check that a CSV file path actually ends in <code>.csv</code> but we can only check that the file actually exists in a Python script.</p> <p>The structure and values of the <code>config.yaml</code> file are validated using a YAML schema stored in <code>tools/config.schema.yaml</code>. Each key in <code>config.yaml</code>, for example <code>PIDS</code>, has a corresponding entry in the schema where we can validate its type, possible values, required properties, min and max values, among other things. </p> <p>The <code>config.yaml</code> is validated against the schema every time RAPIDS runs (see the top of the <code>Snakefile</code>):</p> <pre><code>validate(config, \"tools/config.schema.yaml\")\n</code></pre>"},{"location":"developers/validation-schema-config/#structure-of-the-schema","title":"Structure of the schema","text":"<p>The schema has three main sections <code>required</code>, <code>definitions</code>, and <code>properties</code>. All of them are just nested key/value YAML pairs, where the value can be a primitive type (<code>integer</code>, <code>string</code>, <code>boolean</code>, <code>number</code>) or can be another key/value pair (<code>object</code>).</p>"},{"location":"developers/validation-schema-config/#required","title":"required","text":"<p><code>required</code> lists <code>properties</code> that should be present in the <code>config.yaml</code>. We will almost always add every <code>config.yaml</code> key to this list (meaning that the user cannot delete any of those keys like <code>TIMEZONE</code> or <code>PIDS</code>). </p>"},{"location":"developers/validation-schema-config/#definitions","title":"definitions","text":"<p><code>definitions</code> lists key/values that are common to different <code>properties</code> so we can reuse them. You can define a key/value under <code>definitions</code> and use <code>$ref</code> to refer to it in any <code>property</code>. </p> <p>For example, every sensor like <code>[PHONE_ACCELEROMETER]</code> has one or more providers like <code>RAPIDS</code> and <code>PANDA</code>, these providers have some common properties like the <code>COMPUTE</code> flag or the <code>SRC_SCRIPT</code> string. Therefore we define a shared provider \u201ctemplate\u201d that is used by every provider and extended with properties exclusive to each one of them. For example:</p> provider definition (template) <p>The <code>PROVIDER</code> definition will be used later on different <code>properties</code>.</p> <pre><code>PROVIDER:\n    type: object\n    required: [COMPUTE, SRC_SCRIPT, FEATURES]\n    properties:\n    COMPUTE:\n        type: boolean\n    FEATURES:\n        type: [array, object]\n    SRC_SCRIPT:\n        type: string\n        pattern: \"^.*\\\\.(py|R)$\"\n</code></pre> provider reusing and extending the template <p>Notice that <code>RAPIDS</code> (a provider) uses and extends the <code>PROVIDER</code> template in this example. The <code>FEATURES</code> key is overriding the <code>FEATURES</code> key from the <code>#/definitions/PROVIDER</code> template but is keeping the validation for <code>COMPUTE</code>, and <code>SRC_SCRIPT</code>. For more details about reusing properties, go to this link</p> <pre><code>PHONE_ACCELEROMETER:\n    type: object\n     # .. other properties\n    PROVIDERS:\n        type: [\"null\", object]\n        properties:\n        RAPIDS:\n            allOf:\n            - $ref: \"#/definitions/PROVIDER\"\n            - properties:\n                FEATURES: \n                    type: array\n                    uniqueItems: True\n                    items:\n                    type: string\n                    enum: [\"maxmagnitude\", \"minmagnitude\", \"avgmagnitude\", \"medianmagnitude\", \"stdmagnitude\"]\n</code></pre>"},{"location":"developers/validation-schema-config/#properties","title":"properties","text":"<p><code>properties</code> are nested key/values that describe the different components of our <code>config.yaml</code> file. Values can be of one or more primitive types like <code>string</code>, <code>number</code>, <code>array</code>, <code>boolean</code> and <code>null</code>. Values can also be another key/value pair (of type <code>object</code>) that are similar to a dictionary in Python.</p> <p>For example, the following property validates the <code>PIDS</code> of our <code>config.yaml</code>. It checks that <code>PIDS</code> is an <code>array</code> with unique items of type <code>string</code>.</p> <pre><code>PIDS:\n    type: array\n    uniqueItems: True\n    items:\n      type: string\n</code></pre>"},{"location":"developers/validation-schema-config/#modifying-the-schema","title":"Modifying the schema","text":"<p>Validating the <code>config.yaml</code> during development</p> <p>If you updated the schema and want to check the <code>config.yaml</code> is compliant, you can run the command <code>snakemake --list-params-changes</code>. You will see <code>Building DAG of jobs...</code> if there are no problems or an error message otherwise (try setting any <code>COMPUTE</code> flag to a string like <code>test</code> instead of <code>False/True</code>).</p> <p>You can use this command without having to configure RAPIDS to process any participants or sensors.</p> <p>You can validate different aspects of each key/value in our <code>config.yaml</code> file:</p> number/integer <p>Including min and max values <pre><code>MINUTE_RATIO_THRESHOLD_FOR_VALID_YIELDED_HOURS:\n    type: number\n    minimum: 0\n    maximum: 1\n\nFUSED_RESAMPLED_CONSECUTIVE_THRESHOLD:\n    type: integer\n    exclusiveMinimum: 0\n</code></pre></p> string <p>Including valid values (<code>enum</code>) <pre><code>items:\n    type: string\n    enum: [\"count\", \"maxlux\", \"minlux\", \"avglux\", \"medianlux\", \"stdlux\"]\n</code></pre></p> boolean <pre><code>MINUTES_DATA_USED:\n    type: boolean\n</code></pre> array <p>Including whether or not it should have unique values, the type of the array\u2019s elements (<code>strings</code>, <code>numbers</code>) and valid values (<code>enum</code>). <pre><code>MESSAGES_TYPES:\n    type: array\n    uniqueItems: True\n    items:\n        type: string\n        enum: [\"received\", \"sent\"]\n</code></pre></p> object <p><code>PARENT</code> is an object that has two properties. <code>KID1</code> is one of those properties that are, in turn, another object that will reuse the  <code>\"#/definitions/PROVIDER\"</code> <code>definition</code> AND also include (extend) two extra properties <code>GRAND_KID1</code> of type <code>array</code> and <code>GRAND_KID2</code> of type <code>number</code>. <code>KID2</code> is another property of <code>PARENT</code> of type <code>boolean</code>.</p> <p>The schema validation looks like this <pre><code>PARENT:\n    type: object\n    properties:\n      KID1:\n        allOf:\n          - $ref: \"#/definitions/PROVIDER\"\n          - properties:\n              GRAND_KID1:\n                type: array\n                uniqueItems: True\n              GRAND_KID2:\n                type: number\n      KID2:\n        type: boolean\n</code></pre></p> <p>The <code>config.yaml</code> key that the previous schema validates looks like this: <pre><code>PARENT:\n    KID1:\n        # These four come from the `PROVIDER` definition (template)\n        COMPUTE: False\n        FEATURES: [x, y] # an array\n        SRC_SCRIPT: \"a path to a py or R script\"\n\n        # This two come from the extension\n        GRAND_KID1: [a, b] # an array\n        GRAND_KID2: 5.1 # an number\n     KID2: True # a boolean\n</code></pre></p>"},{"location":"developers/validation-schema-config/#verifying-the-schema-is-correct","title":"Verifying the schema is correct","text":"<p>We recommend that before you start modifying the schema you modify the <code>config.yaml</code> key that you want to validate with an invalid value. For example, if you want to validate that <code>COMPUTE</code> is boolean, you set <code>COMPUTE: 123</code>. Then create your validation, run <code>snakemake --list-params-changes</code> and make sure your validation fails (123 is not <code>boolean</code>), and then set the key to the correct value. In other words, make sure it\u2019s broken first so that you know that your validation works.</p> <p>Warning</p> <p>Be careful. You can check that the schema <code>config.schema.yaml</code> has a valid format by running <code>python tools/check_schema.py</code>. You will see this message if its structure is correct: <code>Schema is OK</code>. However, we don\u2019t have a way to detect typos, for example <code>allOf</code> will work but <code>allOF</code> won\u2019t (capital <code>F</code>) and it won\u2019t show any error. That\u2019s why we recommend to start with an invalid key/value in your <code>config.yaml</code> so that you can be sure the schema validation finds the problem.</p>"},{"location":"developers/validation-schema-config/#useful-resources","title":"Useful resources","text":"<p>Read the following links to learn more about what we can validate with schemas. They are based on <code>JSON</code> instead of <code>YAML</code> schemas but the same concepts apply.</p> <ul> <li>Understanding JSON Schemas</li> <li>Specification of the JSON schema we use</li> </ul>"},{"location":"developers/virtual-environments/","title":"Virtual Environments","text":""},{"location":"developers/virtual-environments/#python-virtual-environment","title":"Python Virtual Environment","text":""},{"location":"developers/virtual-environments/#add-new-packages","title":"Add new packages","text":"<p>Try to install any new package using <code>conda install -c CHANNEL PACKAGE_NAME</code> (you can use <code>pip</code> if the package is only available there). Make sure your Python virtual environment is active (<code>conda activate YOUR_ENV</code>).</p>"},{"location":"developers/virtual-environments/#remove-packages","title":"Remove packages","text":"<p>Uninstall packages using the same manager you used to install them <code>conda remove PACKAGE_NAME</code> or <code>pip uninstall PACKAGE_NAME</code></p>"},{"location":"developers/virtual-environments/#updating-all-packages","title":"Updating all packages","text":"<p>Make sure your Python virtual environment is active (<code>conda activate YOUR_ENV</code>), then run <pre><code>conda update --all\n</code></pre></p>"},{"location":"developers/virtual-environments/#update-your-conda-environmentyaml","title":"Update your conda <code>environment.yaml</code>","text":"<p>After installing or removing a package you can use the following command in your terminal to update your <code>environment.yaml</code> before publishing your pipeline. Note that we ignore the package version for <code>libfortran</code> and <code>mkl</code> to keep compatibility with Linux: <pre><code>conda env export --no-builds | sed 's/^.*libgfortran.*$/  - libgfortran/' | sed 's/^.*mkl=.*$/  - mkl/' &gt;  environment.yml\n</code></pre></p>"},{"location":"developers/virtual-environments/#r-virtual-environment","title":"R Virtual Environment","text":""},{"location":"developers/virtual-environments/#add-new-packages_1","title":"Add new packages","text":"<ol> <li>Open your terminal and navigate to RAPIDS\u2019 root folder</li> <li>Run <code>R</code> to open an R interactive session</li> <li>Run <code>renv::install(\"PACKAGE_NAME\")</code></li> </ol>"},{"location":"developers/virtual-environments/#remove-packages_1","title":"Remove packages","text":"<ol> <li>Open your terminal and navigate to RAPIDS\u2019 root folder</li> <li>Run <code>R</code> to open an R interactive session</li> <li>Run <code>renv::remove(\"PACKAGE_NAME\")</code></li> </ol>"},{"location":"developers/virtual-environments/#updating-all-packages_1","title":"Updating all packages","text":"<ol> <li>Open your terminal and navigate to RAPIDS\u2019 root folder</li> <li>Run <code>R</code> to open an R interactive session</li> <li>Run <code>renv::update()</code></li> </ol>"},{"location":"developers/virtual-environments/#update-your-r-renvlock","title":"Update your R <code>renv.lock</code>","text":"<p>After installing or removing a package you can use the following command in your terminal to update your <code>renv.lock</code> before publishing your pipeline.</p> <ol> <li>Open your terminal and navigate to RAPIDS\u2019 root folder</li> <li>Run <code>R</code> to open an R interactive session</li> <li>Run <code>renv::snapshot()</code> (renv will ask you to confirm any updates to this file)</li> </ol>"},{"location":"features/add-new-features/","title":"Add New Features","text":"<p>Hint</p> <ul> <li>We recommend reading the Behavioral Features Introduction before reading this page.</li> <li>You can implement new features in Python or R scripts.</li> <li>You won\u2019t have to deal with time zones, dates, times, data cleaning, or preprocessing. The data that RAPIDS pipes to your feature extraction code are ready to process.</li> </ul>"},{"location":"features/add-new-features/#new-features-for-existing-sensors","title":"New Features for Existing Sensors","text":"<p>You can add new features to any existing sensors (see list below) by adding a new provider in three steps:</p> <ol> <li>Modify the <code>config.yaml</code> file </li> <li>Create your feature provider script</li> <li>Implement your features extraction code</li> </ol> <p>As a tutorial, we will add a new provider for <code>PHONE_ACCELEROMETER</code> called <code>VEGA</code> that extracts <code>feature1</code>, <code>feature2</code>, <code>feature3</code> with a Python script that requires a parameter from the user called <code>MY_PARAMETER</code>.</p> Existing Sensors <p>An existing sensor of any device with a configuration entry in <code>config.yaml</code>:</p> <p>Smartphone (AWARE)</p> <ul> <li>Phone Accelerometer</li> <li>Phone Activity Recognition</li> <li>Phone Applications Crashes</li> <li>Phone Applications Foreground</li> <li>Phone Applications Notifications</li> <li>Phone Battery</li> <li>Phone Bluetooth</li> <li>Phone Calls</li> <li>Phone Conversation</li> <li>Phone Data Yield</li> <li>Phone Keyboard</li> <li>Phone Light</li> <li>Phone Locations</li> <li>Phone Log</li> <li>Phone Messages</li> <li>Phone Screen</li> <li>Phone WiFI Connected</li> <li>Phone WiFI Visible</li> </ul> <p>Fitbit</p> <ul> <li>Fitbit Data Yield</li> <li>Fitbit Heart Rate Summary</li> <li>Fitbit Heart Rate Intraday</li> <li>Fitbit Sleep Summary</li> <li>Fitbit Sleep Intraday</li> <li>Fitbit Steps Summary</li> <li>Fitbit Steps Intraday</li> </ul> <p>Empatica</p> <ul> <li>Empatica Accelerometer</li> <li>Empatica Heart Rate</li> <li>Empatica Temperature</li> <li>Empatica Electrodermal Activity</li> <li>Empatica Blood Volume Pulse</li> <li>Empatica Inter Beat Interval</li> <li>Empatica Tags</li> </ul>"},{"location":"features/add-new-features/#modify-the-configyaml-file","title":"Modify the <code>config.yaml</code> file","text":"<p>In this step, you need to add your provider configuration section under the relevant sensor in <code>config.yaml</code>. See our example for our tutorial\u2019s <code>VEGA</code> provider for  <code>PHONE_ACCELEROMETER</code>:</p> Example configuration for a new accelerometer provider <code>VEGA</code> <pre><code>PHONE_ACCELEROMETER:\n    CONTAINER: accelerometer\n    PROVIDERS:\n        RAPIDS: # this is a feature provider\n            COMPUTE: False\n            ...\n\n        PANDA: # this is another feature provider\n            COMPUTE: False\n            ...\n\n        VEGA: # this is our new feature provider\n            COMPUTE: False\n            FEATURES: [\"feature1\", \"feature2\", \"feature3\"]\n            MY_PARAMTER: a_string\n            SRC_SCRIPT: src/features/phone_accelerometer/vega/main.py\n</code></pre> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Flag to activate/deactivate your provider <code>[FEATURES]</code> List of features your provider supports. Your provider code should only return the features on this list <code>[MY_PARAMTER]</code> An arbitrary parameter that our example provider <code>VEGA</code> needs. This can be a boolean, integer, float, string, or an array of any of such types. <code>[SRC_SCRIPT]</code> The relative path from RAPIDS\u2019 root folder to a script that computes the features for this provider. It can be implemented in R or Python."},{"location":"features/add-new-features/#create-a-feature-provider-script","title":"Create a feature provider script","text":"<p>Create your feature Python or R script called <code>main.py</code> or <code>main.R</code> in the correct folder, <code>src/feature/[sensorname]/[providername]/</code>. RAPIDS automatically loads and executes it based on the config key <code>[SRC_SCRIPT]</code> you added in the last step. For our example, this script is: <pre><code>src/feature/phone_accelerometer/vega/main.py\n</code></pre></p>"},{"location":"features/add-new-features/#implement-your-feature-extraction-code","title":"Implement your feature extraction code","text":"<p>Every feature script (<code>main.[py|R]</code>) needs a <code>[providername]_features</code> function with specific parameters. RAPIDS calls this function with the sensor data ready to process and with other functions and arguments you will need.</p> Python function <pre><code>def [providername]_features(sensor_data_files, time_segment, provider, filter_data_by_segment, *args, **kwargs):\n    # empty for now\n    return(your_features_df)\n</code></pre> R function <pre><code>[providername]_features &lt;- function(sensor_data, time_segment, provider){\n    # empty for now\n    return(your_features_df)\n}\n</code></pre> Parameter\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>sensor_data_files</code> Path to the CSV file containing the data of a single participant. This data has been cleaned and preprocessed. Your function will be automatically called for each participant in your study (in the <code>[PIDS]</code> array in <code>config.yaml</code>) <code>time_segment</code> The label of the time segment that should be processed. <code>provider</code> The parameters you configured for your provider in <code>config.yaml</code> will be available in this variable as a dictionary in Python or a list in R. In our example, this dictionary contains <code>{MY_PARAMETER:\"a_string\"}</code> <code>filter_data_by_segment</code> Python only. A function that you will use to filter your data. In R, this function is already available in the environment. <code>*args</code> Python only. Not used for now <code>**kwargs</code> Python only. Not used for now <p>The next step is to implement the code that computes your behavioral features in your provider script\u2019s function. As with any other script, this function can call other auxiliary methods, but in general terms, it should have three stages:</p> 1. Read a participant\u2019s data by loading the CSV data stored in the file pointed by <code>sensor_data_files</code> <pre><code>acc_data = pd.read_csv(sensor_data_files[\"sensor_data\"])\n</code></pre> <p>Note that the phone\u2019s battery, screen, and activity recognition data are given as episodes instead of event rows (for example, start and end timestamps of the periods the phone screen was on)</p> 2. Filter your data to process only those rows that belong to <code>time_segment</code> <p>This step is only one line of code, but keep reading to understand why we need it. <pre><code>acc_data = filter_data_by_segment(acc_data, time_segment)\n</code></pre></p> <p>You should use the <code>filter_data_by_segment()</code> function to process and group those rows that belong to each of the time segments RAPIDS could be configured with.</p> <p>Let\u2019s understand the <code>filter_data_by_segment()</code> function with an example. A RAPIDS user can extract features on any arbitrary time segment. A time segment is a period that has a label and one or more instances. For example, the user (or you) could have requested features on a daily, weekly, and weekend basis for <code>p01</code>. The labels are arbitrary, and the instances depend on the days a participant was monitored for: </p> <ul> <li>the daily segment could be named <code>my_days</code> and if <code>p01</code> was monitored for 14 days, it would have 14 instances</li> <li>the weekly segment could be named <code>my_weeks</code> and if <code>p01</code> was monitored for 14 days, it would have 2 instances.</li> <li>the weekend segment could be named <code>my_weekends</code> and if <code>p01</code> was monitored for 14 days, it would have 2 instances.</li> </ul> <p>For this example, RAPIDS will call your provider function three times for <code>p01</code>, once where <code>time_segment</code> is <code>my_days</code>, once where <code>time_segment</code> is <code>my_weeks</code>, and once where <code>time_segment</code> is <code>my_weekends</code>. In this example, not every row in <code>p01</code>\u2019s data needs to take part in the feature computation for either segment and the rows need to be grouped differently. </p> <p>Thus <code>filter_data_by_segment()</code> comes in handy, it will return a data frame that contains the rows that were logged during a time segment plus an extra column called <code>local_segment</code>. This new column will have as many unique values as time segment instances exist (14, 2, and 2 for our <code>p01</code>\u2019s <code>my_days</code>, <code>my_weeks</code>, and <code>my_weekends</code> examples). After filtering, you should group the data frame by this column and compute any desired features, for example:</p> <pre><code>acc_features[\"maxmagnitude\"] = acc_data.groupby([\"local_segment\"])[\"magnitude\"].max()\n</code></pre> <p>The reason RAPIDS does not filter the participant\u2019s data set for you is because your code might need to compute something based on a participant\u2019s complete dataset before computing their features. For example, you might want to identify the number that called a participant the most throughout the study before computing a feature with the number of calls the participant received from that number.</p> 3. Return a data frame with your features <p>After filtering, grouping your data, and computing your features, your provider function should return a data frame that has:</p> <ul> <li>One row per time segment instance (e.g., 14 our <code>p01</code>\u2019s <code>my_days</code> example)</li> <li>The <code>local_segment</code> column added by <code>filter_data_by_segment()</code></li> <li>One column per feature. The name of your features should only contain letters or numbers (<code>feature1</code>) by convention. RAPIDS automatically adds the correct sensor and provider prefix; in our example, this prefix is <code>phone_accelerometr_vega_</code>.</li> </ul> <code>PHONE_ACCELEROMETER</code> Provider Example <p>For your reference, this our own provider (<code>RAPIDS</code>) for <code>PHONE_ACCELEROMETER</code> that computes five acceleration features</p> <pre><code>import pandas as pd\nimport numpy as np\n\ndef rapids_features(sensor_data_files, time_segment, provider, filter_data_by_segment, *args, **kwargs):\n\n    acc_data = pd.read_csv(sensor_data_files[\"sensor_data\"])\n    requested_features = provider[\"FEATURES\"]\n    # name of the features this function can compute\n    base_features_names = [\"maxmagnitude\", \"minmagnitude\", \"avgmagnitude\", \"medianmagnitude\", \"stdmagnitude\"]\n    # the subset of requested features this function can compute\n    features_to_compute = list(set(requested_features) &amp; set(base_features_names))\n\n    acc_features = pd.DataFrame(columns=[\"local_segment\"] + features_to_compute)\n    if not acc_data.empty:\n        acc_data = filter_data_by_segment(acc_data, time_segment)\n\n        if not acc_data.empty:\n            acc_features = pd.DataFrame()\n            # get magnitude related features: magnitude = sqrt(x^2+y^2+z^2)\n            magnitude = acc_data.apply(lambda row: np.sqrt(row[\"double_values_0\"] ** 2 + row[\"double_values_1\"] ** 2 + row[\"double_values_2\"] ** 2), axis=1)\n            acc_data = acc_data.assign(magnitude = magnitude.values)\n\n            if \"maxmagnitude\" in features_to_compute:\n                acc_features[\"maxmagnitude\"] = acc_data.groupby([\"local_segment\"])[\"magnitude\"].max()\n            if \"minmagnitude\" in features_to_compute:\n                acc_features[\"minmagnitude\"] = acc_data.groupby([\"local_segment\"])[\"magnitude\"].min()\n            if \"avgmagnitude\" in features_to_compute:\n                acc_features[\"avgmagnitude\"] = acc_data.groupby([\"local_segment\"])[\"magnitude\"].mean()\n            if \"medianmagnitude\" in features_to_compute:\n                acc_features[\"medianmagnitude\"] = acc_data.groupby([\"local_segment\"])[\"magnitude\"].median()\n            if \"stdmagnitude\" in features_to_compute:\n                acc_features[\"stdmagnitude\"] = acc_data.groupby([\"local_segment\"])[\"magnitude\"].std()\n\n            acc_features = acc_features.reset_index()\n\n    return acc_features\n</code></pre>"},{"location":"features/add-new-features/#new-features-for-non-existing-sensors","title":"New Features for Non-Existing Sensors","text":"<p>If you want to add features for a device or a sensor that we do not support at the moment (those that do not appear in the <code>\"Existing Sensors\"</code> list above), open a new discussion in Github and we can add the necessary code so you can follow the instructions above.</p>"},{"location":"features/empatica-accelerometer/","title":"Empatica Accelerometer","text":"<p>Sensor parameters description for <code>[EMPATICA_ACCELEROMETER]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Name of the CSV file containing accelerometer data that is compressed inside an Empatica zip file. Since these zip files are created automatically by Empatica, there is no need to change the value of this attribute."},{"location":"features/empatica-accelerometer/#dbdp-provider","title":"DBDP provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/empatica_accelerometer_raw.csv\n- data/raw/{pid}/empatica_accelerometer_with_datetime.csv\n- data/interim/{pid}/empatica_accelerometer_features/empatica_accelerometer_{language}_{provider_key}.csv\n- data/processed/features/{pid}/empatica_accelerometer.csv\n</code></pre> <p>Parameters description for <code>[EMPATICA_ACCELEROMETER][PROVIDERS][DBDP]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>EMPATICA_ACCELEROMETER</code> features from the <code>DBDP</code> provider <code>[FEATURES]</code> Features to be computed, see table below <p>Features description for <code>[EMPATICA_ACCELEROMETER][PROVIDERS][RAPDBDPIDS]</code>:</p> Feature Units Description maxmagnitude m/s<sup>2</sup> The maximum magnitude of acceleration (\\(\\|acceleration\\| = \\sqrt{x^2 + y^2 + z^2}\\)). minmagnitude m/s<sup>2</sup> The minimum magnitude of acceleration. avgmagnitude m/s<sup>2</sup> The average magnitude of acceleration. medianmagnitude m/s<sup>2</sup> The median magnitude of acceleration. stdmagnitude m/s<sup>2</sup> The standard deviation of acceleration. <p>Assumptions/Observations</p> <ol> <li>Analyzing accelerometer data is a memory intensive task. If RAPIDS crashes is likely because the accelerometer dataset for a participant is too big to fit in memory. We are considering different alternatives to overcome this problem, if this is something you need, get in touch and we can discuss how to implement it.</li> </ol>"},{"location":"features/empatica-blood-volume-pulse/","title":"Empatica Blood Volume Pulse","text":"<p>Sensor parameters description for <code>[EMPATICA_BLOOD_VOLUME_PULSE]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Name of the CSV file containing blood volume pulse data that is compressed inside an Empatica zip file. Since these zip files are created automatically by Empatica, there is no need to change the value of this attribute."},{"location":"features/empatica-blood-volume-pulse/#dbdp-provider","title":"DBDP provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/empatica_blood_volume_pulse_raw.csv \n- data/raw/{pid}/empatica_blood_volume_pulse_with_datetime.csv\n- data/interim/{pid}/empatica_blood_volume_pulse_features/empatica_blood_volume_pulse_{language}_{provider_key}.csv\n- data/processed/features/{pid}/empatica_blood_volume_pulse.csv\n</code></pre> <p>Parameters description for <code>[EMPATICA_BLOOD_VOLUME_PULSE][PROVIDERS][DBDP]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>EMPATICA_BLOOD_VOLUME_PULSE</code> features from the <code>DBDP</code> provider <code>[FEATURES]</code> Features to be computed from blood volume pulse intraday data, see table below <p>Features description for <code>[EMPATICA_BLOOD_VOLUME_PULSE][PROVIDERS][DBDP]</code>:</p> Feature Units Description maxbvp - The maximum blood volume pulse during a time segment. minbvp - The minimum blood volume pulse during a time segment. avgbvp - The average blood volume pulse during a time segment. medianbvp - The median of blood volume pulse during a time segment. modebvp - The mode of blood volume pulse during a time segment. stdbvp - The standard deviation of blood volume pulse during a time segment. diffmaxmodebvp - The difference between the maximum and mode blood volume pulse during a time segment. diffminmodebvp - The difference between the mode and minimum blood volume pulse during a time segment. entropybvp nats Shannon\u2019s entropy measurement based on blood volume pulse during a time segment. <p>Assumptions/Observations</p> <p>For more information about BVP read this.</p>"},{"location":"features/empatica-electrodermal-activity/","title":"Empatica Electrodermal Activity","text":"<p>Sensor parameters description for <code>[EMPATICA_ELECTRODERMAL_ACTIVITY]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Name of the CSV file containing electrodermal activity data that is compressed inside an Empatica zip file. Since these zip files are created automatically by Empatica, there is no need to change the value of this attribute."},{"location":"features/empatica-electrodermal-activity/#dbdp-provider","title":"DBDP provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/empatica_electrodermal_activity_raw.csv\n- data/raw/{pid}/empatica_electrodermal_activity_with_datetime.csv\n- data/interim/{pid}/empatica_electrodermal_activity_features/empatica_electrodermal activity_{language}_{provider_key}.csv\n- data/processed/features/{pid}/empatica_electrodermal_activity.csv\n</code></pre> <p>Parameters description for <code>[EMPATICA_ELECTRODERMAL_ACTIVITY][PROVIDERS][DBDP]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>EMPATICA_ELECTRODERMAL_ACTIVITY</code> features from the <code>DBDP</code> provider <code>[FEATURES]</code> Features to be computed from electrodermal activity intraday data, see table below <p>Features description for <code>[EMPATICA_ELECTRODERMAL ACTIVITY][PROVIDERS][DBDP]</code>:</p> Feature Units Description maxeda microsiemens The maximum electrical conductance during a time segment. mineda microsiemens The minimum electrical conductance during a time segment. avgeda microsiemens The average electrical conductance during a time segment. medianeda microsiemens The median of electrical conductance during a time segment. modeeda microsiemens The mode of electrical conductance during a time segment. stdeda microsiemens The standard deviation of electrical conductance during a time segment. diffmaxmodeeda microsiemens The difference between the maximum and mode electrical conductance during a time segment. diffminmodeeda microsiemens The difference between the mode and minimum electrical conductance during a time segment. entropyeda nats Shannon\u2019s entropy measurement based on electrical conductance during a time segment. <p>Assumptions/Observations</p> <p>None</p>"},{"location":"features/empatica-heartrate/","title":"Empatica Heart Rate","text":"<p>Sensor parameters description for <code>[EMPATICA_HEARTRATE]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Name of the CSV file containing heart rate data that is compressed inside an Empatica zip file. Since these zip files are created automatically by Empatica, there is no need to change the value of this attribute."},{"location":"features/empatica-heartrate/#dbdp-provider","title":"DBDP provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/empatica_heartrate_raw.csv\n- data/raw/{pid}/empatica_heartrate_with_datetime.csv\n- data/interim/{pid}/empatica_heartrate_features/empatica_heartrate_{language}_{provider_key}.csv\n- data/processed/features/{pid}/empatica_heartrate.csv\n</code></pre> <p>Parameters description for <code>[EMPATICA_HEARTRATE][PROVIDERS][DBDP]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>EMPATICA_HEARTRATE</code> features from the <code>DBDP</code> provider <code>[FEATURES]</code> Features to be computed from heart rate intraday data, see table below <p>Features description for <code>[EMPATICA_HEARTRATE][PROVIDERS][DBDP]</code>:</p> Feature Units Description maxhr beats The maximum heart rate during a time segment. minhr beats The minimum heart rate during a time segment. avghr beats The average heart rate during a time segment. medianhr beats The median of heart rate during a time segment. modehr beats The mode of heart rate during a time segment. stdhr beats The standard deviation of heart rate during a time segment. diffmaxmodehr beats The difference between the maximum and mode heart rate during a time segment. diffminmodehr beats The difference between the mode and minimum heart rate during a time segment. entropyhr nats Shannon\u2019s entropy measurement based on heart rate during a time segment. <p>Assumptions/Observations</p> <p>We extract the previous features based on the average heart rate values computed in 10-second windows.</p>"},{"location":"features/empatica-inter-beat-interval/","title":"Empatica Inter Beat Interval","text":"<p>Sensor parameters description for <code>[EMPATICA_INTER_BEAT_INTERVAL]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Name of the CSV file containing inter beat interval data that is compressed inside an Empatica zip file. Since these zip files are created automatically by Empatica, there is no need to change the value of this attribute."},{"location":"features/empatica-inter-beat-interval/#dbdp-provider","title":"DBDP provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/empatica_inter_beat_interval_raw.csv\n- data/raw/{pid}/empatica_inter_beat_interval_with_datetime.csv\n- data/interim/{pid}/empatica_inter_beat_interval_features/empatica_inter_beat_interval_{language}_{provider_key}.csv\n- data/processed/features/{pid}/empatica_inter_beat_interval.csv\n</code></pre> <p>Parameters description for <code>[EMPATICA_INTER_BEAT_INTERVAL][PROVIDERS][DBDP]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>EMPATICA_INTER_BEAT_INTERVAL</code> features from the <code>DBDP</code> provider <code>[FEATURES]</code> Features to be computed from inter beat interval intraday data, see table below <p>Features description for <code>[EMPATICA_INTER_BEAT_INTERVAL][PROVIDERS][DBDP]</code>:</p> Feature Units Description maxibi seconds The maximum inter beat interval during a time segment. minibi seconds The minimum inter beat interval during a time segment. avgibi seconds The average inter beat interval during a time segment. medianibi seconds The median of inter beat interval during a time segment. modeibi seconds The mode of inter beat interval during a time segment. stdibi seconds The standard deviation of inter beat interval during a time segment. diffmaxmodeibi seconds The difference between the maximum and mode inter beat interval during a time segment. diffminmodeibi seconds The difference between the mode and minimum inter beat interval during a time segment. entropyibi nats Shannon\u2019s entropy measurement based on inter beat interval during a time segment. <p>Assumptions/Observations</p> <p>For more information about IBI read this.</p>"},{"location":"features/empatica-tags/","title":"Empatica Tags","text":"<p>Sensor parameters description for <code>[EMPATICA_TAGS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Name of the CSV file containing tags data that is compressed inside an Empatica zip file. Since these zip files are created automatically by Empatica, there is no need to change the value of this attribute. <p>Note</p> <ul> <li>No feature providers have been implemented for this sensor yet, however you can implement your own features.</li> <li>To know more about tags read this.</li> </ul>"},{"location":"features/empatica-temperature/","title":"Empatica Temperature","text":"<p>Sensor parameters description for <code>[EMPATICA_TEMPERATURE]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Name of the CSV file containing temperature data that is compressed inside an Empatica zip file. Since these zip files are created automatically by Empatica, there is no need to change the value of this attribute."},{"location":"features/empatica-temperature/#dbdp-provider","title":"DBDP provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/empatica_temperature_raw.csv\n- data/raw/{pid}/empatica_temperature_with_datetime.csv\n- data/interim/{pid}/empatica_temperature_features/empatica_temperature_{language}_{provider_key}.csv\n- data/processed/features/{pid}/empatica_temperature.csv\n</code></pre> <p>Parameters description for <code>[EMPATICA_TEMPERATURE][PROVIDERS][DBDP]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>EMPATICA_TEMPERATURE</code> features from the <code>DBDP</code> provider <code>[FEATURES]</code> Features to be computed from temperature intraday data, see table below <p>Features description for <code>[EMPATICA_TEMPERATURE][PROVIDERS][DBDP]</code>:</p> Feature Units Description maxtemp degrees C The maximum temperature during a time segment. mintemp degrees C The minimum temperature during a time segment. avgtemp degrees C The average temperature during a time segment. mediantemp degrees C The median of temperature during a time segment. modetemp degrees C The mode of temperature during a time segment. stdtemp degrees C The standard deviation of temperature during a time segment. diffmaxmodetemp degrees C The difference between the maximum and mode temperature during a time segment. diffminmodetemp degrees C The difference between the mode and minimum temperature during a time segment. entropytemp nats Shannon\u2019s entropy measurement based on temperature during a time segment. <p>Assumptions/Observations</p> <p>None</p>"},{"location":"features/feature-introduction/","title":"Behavioral Features Introduction","text":"<p>A behavioral feature is a metric computed from raw sensor data quantifying the behavior of a participant. For example, the time spent at home computed based on location data. These are also known as digital biomarkers. </p> <p>RAPIDS\u2019 <code>config.yaml</code> has a section for each supported device/sensor (e.g., <code>PHONE_ACCELEROMETER</code>, <code>FITBIT_STEPS</code>, <code>EMPATICA_HEARTRATE</code>). These sections follow a similar structure, and they can have one or more feature <code>PROVIDERS</code>, that compute one or more behavioral features.  You will modify the parameters of these <code>PROVIDERS</code> to obtain features from different mobile sensors. We\u2019ll use <code>PHONE_ACCELEROMETER</code> as an example to explain this further.</p> <p>Hint</p> <ul> <li>We recommend reading this page if you are using RAPIDS for the first time</li> <li>All computed sensor features are stored under <code>/data/processed/features</code> on files per sensor, per participant and per study (all participants).</li> <li>Every time you change any sensor parameters, provider parameters or provider features, all the necessary files will be updated as soon as you execute RAPIDS.</li> <li>In short, to extract features offered by a provider, you need to set its <code>[COMPUTE]</code> flag to <code>TRUE</code>, configure any of its parameters, and execute RAPIDS.</li> </ul>"},{"location":"features/feature-introduction/#explaining-the-configyaml-sensor-sections-with-an-example","title":"Explaining the config.yaml sensor sections with an example","text":"<p>Each sensor section follows the same structure. Click on the numbered markers to know more.</p> <pre><code>PHONE_ACCELEROMETER: # (1)\n\n    CONTAINER: accelerometer # (2)\n\n    PROVIDERS: # (3)\n        RAPIDS:\n            COMPUTE: False # (4)\n            FEATURES: [\"maxmagnitude\", \"minmagnitude\", \"avgmagnitude\", \"medianmagnitude\", \"stdmagnitude\"]\n\n            SRC_SCRIPT: src/features/phone_accelerometer/rapids/main.py\n\n        PANDA:\n            COMPUTE: False\n            VALID_SENSED_MINUTES: False\n            FEATURES: # (5)\n                exertional_activity_episode: [\"sumduration\", \"maxduration\", \"minduration\", \"avgduration\", \"medianduration\", \"stdduration\"]\n                nonexertional_activity_episode: [\"sumduration\", \"maxduration\", \"minduration\", \"avgduration\", \"medianduration\", \"stdduration\"]\n\n                        # (6)\n            SRC_SCRIPT: src/features/phone_accelerometer/panda/main.py\n</code></pre> <ol> <li> <p>Sensor section</p> <p>Each sensor (accelerometer, screen, etc.) of every supported device (smartphone, Fitbit, etc.) has a section in the <code>config.yaml</code> with <code>parameters</code> and feature <code>PROVIDERS</code>.</p> </li> <li> <p>Sensor Parameters. </p> <p>Each sensor section has one or more parameters. These are parameters that affect different aspects of how the raw data is pulled, and processed.</p> <p>The <code>CONTAINER</code> parameter exists for every sensor, but some sensors will have extra parameters like <code>[PHONE_LOCATIONS]</code>.</p> <p>We explain these parameters in a table at the top of each sensor documentation page.</p> </li> <li> <p>Sensor Providers</p> <p>Each object in this list represents a feature <code>PROVIDER</code>. Each sensor can have zero, one, or more providers.</p> <p>A <code>PROVIDER</code> is a script that creates behavioral features for a specific sensor. Providers are created by the core RAPIDS team or by the community, which are named after its first author like [PHONE_LOCATIONS][DORYAB].</p> <p>In this example, there are two accelerometer feature providers <code>RAPIDS</code> and <code>PANDA</code>.</p> </li> <li> <p><code>PROVIDER</code> Parameters</p> <p>Each <code>PROVIDER</code> has parameters that affect the computation of the behavioral features it offers.</p> <p>These parameters include at least a <code>[COMPUTE]</code> flag that you switch to <code>True</code> to extract a provider\u2019s behavioral features. </p> <p>We explain every provider\u2019s parameter in a table under the <code>Parameters description</code> heading on each provider documentation page.</p> </li> <li> <p><code>PROVIDER</code> Features</p> <p>Each <code>PROVIDER</code> offers a set of behavioral features.</p> <p>These features are grouped in an array for some providers, like those for <code>RAPIDS</code> provider. For others, they are grouped in a collection of arrays, like those for <code>PANDAS</code> provider.</p> <p>In either case, you can delete the features you are not interested in, and they will not be included in the sensor\u2019s output feature file. </p> <p>We explain each behavioral feature in a table under the <code>Features description</code> heading on each provider documentation page.</p> </li> <li> <p><code>PROVIDER</code> script</p> <p>Each <code>PROVIDER</code> has a <code>SRC_SCRIPT</code> that points to the script implementing its behavioral features.</p> <p>It has to be a relative path from RAPIDS\u2019 root folder and the script\u2019s parent folder should be named after the provider, e.g. <code>panda</code>.</p> </li> </ol> <p>These are the descriptions of each marker for accessibility:</p> <ol> <li> <p>Sensor section</p> <p>Each sensor (accelerometer, screen, etc.) of every supported device (smartphone, Fitbit, etc.) has a section in the <code>config.yaml</code> with <code>parameters</code> and feature <code>PROVIDERS</code>.</p> </li> <li> <p>Sensor Parameters. </p> <p>Each sensor section has one or more parameters. These are parameters that affect different aspects of how the raw data is pulled, and processed.</p> <p>The <code>CONTAINER</code> parameter exists for every sensor, but some sensors will have extra parameters like <code>[PHONE_LOCATIONS]</code>.</p> <p>We explain these parameters in a table at the top of each sensor documentation page.</p> </li> <li> <p>Sensor Providers</p> <p>Each object in this list represents a feature <code>PROVIDER</code>. Each sensor can have zero, one, or more providers.</p> <p>A <code>PROVIDER</code> is a script that creates behavioral features for a specific sensor. Providers are created by the core RAPIDS team or by the community, which are named after its first author like [PHONE_LOCATIONS][DORYAB].</p> <p>In this example, there are two accelerometer feature providers <code>RAPIDS</code> and <code>PANDA</code>.</p> </li> <li> <p><code>PROVIDER</code> Parameters</p> <p>Each <code>PROVIDER</code> has parameters that affect the computation of the behavioral features it offers.</p> <p>These parameters include at least a <code>[COMPUTE]</code> flag that you switch to <code>True</code> to extract a provider\u2019s behavioral features. </p> <p>We explain every provider\u2019s parameter in a table under the <code>Parameters description</code> heading on each provider documentation page.</p> </li> <li> <p><code>PROVIDER</code> Features</p> <p>Each <code>PROVIDER</code> offers a set of behavioral features.</p> <p>These features are grouped in an array for some providers, like those for <code>RAPIDS</code> provider. For others, they are grouped in a collection of arrays, like those for <code>PANDAS</code> provider.</p> <p>In either case, you can delete the features you are not interested in, and they will not be included in the sensor\u2019s output feature file. </p> <p>We explain each behavioral feature in a table under the <code>Features description</code> heading on each provider documentation page.</p> </li> <li> <p><code>PROVIDER</code> script</p> <p>Each <code>PROVIDER</code> has a <code>SRC_SCRIPT</code> that points to the script implementing its behavioral features.</p> <p>It has to be a relative path from RAPIDS\u2019 root folder and the script\u2019s parent folder should be named after the provider, e.g. <code>panda</code>.</p> </li> </ol>"},{"location":"features/fitbit-calories-intraday/","title":"Fitbit Calories Intraday","text":"<p>Sensor parameters description for <code>[FITBIT_CALORIES_INTRADAY]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Container where your calories intraday data is stored, depending on the data stream you are using this can be a database table, a CSV file, etc."},{"location":"features/fitbit-calories-intraday/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments</p> <ul> <li>Available for all time segments</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/fitbit_calories_intraday_raw.csv\n- data/raw/{pid}/fitbit_calories_intraday_with_datetime.csv\n- data/interim/{pid}/fitbit_calories_intraday_features/fitbit_calories_intraday_{language}_{provider_key}.csv\n- data/processed/features/{pid}/fitbit_calories_intraday.csv\n</code></pre> <p>Parameters description for <code>[FITBIT_CALORIES_INTRADAY][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>FITBIT_CALORIES_INTRADAY</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed from calories intraday data, see table below <code>[EPISODE_TYPE]</code> RAPIDS will compute features for any episodes in this list. There are seven types of episodes defined as consecutive appearances of a label. Four are based on the activity level labels provided by Fitbit: <code>sedentary</code>, <code>lightly active</code>, <code>fairly active</code>, and <code>very active</code>. One is defined by RAPIDS as moderate to vigorous physical activity <code>MVPA</code> episodes that are based on all <code>fairly active</code>, and <code>very active</code>  labels. Two are defined by the user based on a threshold that divides low or high MET (metabolic equivalent) episodes. <code>EPISODE_TIME_THRESHOLD</code> Any consecutive rows of the same <code>[EPISODE_TYPE]</code> will be considered a single episode if the time difference between them is less or equal than this threshold in minutes <code>[EPISODE_MET_THRESHOLD]</code> Any 1-minute calorie data chunk with a MET value equal or higher than this threshold will be considered a high MET episode and low MET otherwise.  The default value is 3 <code>[EPISODE_MVPA_CATEGORIES]</code> The Fitbit level labels that are considered part of a moderate to vigorous physical activity episode. One or more of <code>sedentary</code>, <code>lightly active</code>, <code>fairly active</code>, and <code>very active</code>. The default are <code>fairly active</code> and <code>very active</code> <code>[EPISODE_REFERENCE_TIME]</code> Reference time for the start/end time features. <code>MIDNIGHT</code> sets the reference time to 00:00 of each day, <code>START_OF_THE_SEGMENT</code> sets the reference time to the start of the time segment (useful when a segment is shorter than a day or spans multiple days) <p>Features description for <code>[FITBIT_CALORIES_INTRADAY][PROVIDERS][RAPIDS]</code>:</p> Feature\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Units Description starttimefirstepisode<code>EPISODE_TYPE</code> minutes Start time of the first episode of type <code>[EPISODE_TYPE]</code> endtimefirstepisode<code>EPISODE_TYPE</code> minutes End time of the first episode of type <code>[EPISODE_TYPE]</code> starttimelastepisode<code>EPISODE_TYPE</code> minutes Start time of the last episode of type <code>[EPISODE_TYPE]</code> endtimelastepisode<code>EPISODE_TYPE</code> minutes End time of the last episode of type <code>[EPISODE_TYPE]</code> starttimelongestepisode<code>EPISODE_TYPE</code> minutes Start time of the longest episode of type <code>[EPISODE_TYPE]</code> endtimelongestepisode<code>EPISODE_TYPE</code> minutes End time of the longest episode of type <code>[EPISODE_TYPE]</code> countepisode<code>EPISODE_TYPE</code> episodes The number of episodes of type <code>[EPISODE_TYPE]</code> sumdurationepisode<code>EPISODE_TYPE</code> minutes The sum of the duration of episodes of type <code>[EPISODE_TYPE]</code> avgdurationepisode<code>EPISODE_TYPE</code> minutes The average of the duration of episodes of type <code>[EPISODE_TYPE]</code> maxdurationepisode<code>EPISODE_TYPE</code> minutes The maximum of the duration of episodes of type <code>[EPISODE_TYPE]</code> mindurationepisode<code>EPISODE_TYPE</code> minutes The minimum of the duration of episodes of type <code>[EPISODE_TYPE]</code> stddurationepisode<code>EPISODE_TYPE</code> minutes The standard deviation of the duration of episodes of type <code>[EPISODE_TYPE]</code> summet<code>EPISODE_TYPE</code> METs The sum of all METs during episodes of type <code>[EPISODE_TYPE]</code> avgmet<code>EPISODE_TYPE</code> METs The average of all METs during episodes of type <code>[EPISODE_TYPE]</code> maxmet<code>EPISODE_TYPE</code> METs The maximum of all METs during episodes of type <code>[EPISODE_TYPE]</code> minmet<code>EPISODE_TYPE</code> METs The minimum of all METs during episodes of type <code>[EPISODE_TYPE]</code> stdmet<code>EPISODE_TYPE</code> METs The standard deviation of all METs during episodes of type <code>[EPISODE_TYPE]</code> sumcalories<code>EPISODE_TYPE</code> calories The sum of all calories during episodes of type <code>[EPISODE_TYPE]</code> avgcalories<code>EPISODE_TYPE</code> calories The average of all calories during episodes of type <code>[EPISODE_TYPE]</code> maxcalories<code>EPISODE_TYPE</code> calories The maximum of all calories during episodes of type <code>[EPISODE_TYPE]</code> mincalories<code>EPISODE_TYPE</code> calories The minimum of all calories during episodes of type <code>[EPISODE_TYPE]</code> stdcalories<code>EPISODE_TYPE</code> calories The standard deviation of all calories during episodes of type <code>[EPISODE_TYPE]</code> <p>Assumptions/Observations</p> <ul> <li>These features are based on intraday calories data that is usually obtained in 1-minute chunks from Fitbit\u2019s API.</li> <li>The MET value returned by Fitbit is divided by 10</li> <li>Take into account that the intraday data returned by Fitbit can contain time series for calories burned inclusive of BMR, tracked activity, and manually logged activities.</li> </ul>"},{"location":"features/fitbit-data-yield/","title":"Fitbit Data Yield","text":"<p>We use Fitbit heart rate intraday data to extract data yield features. Fitbit data yield features can be used to remove rows (time segments) that do not contain enough Fitbit data. You should decide what is your \u201cenough\u201d threshold depending on the time a participant was supposed to be wearing their Fitbit, the length of your study, and the rates of missing data that your analysis could handle.</p> <p>Why is Fitbit data yield important?</p> <p>Imagine that you want to extract <code>FITBIT_STEPS_SUMMARY</code> features on daily segments (<code>00:00</code> to <code>23:59</code>). Let\u2019s say that on day 1 the Fitbit logged 6k as the total step count and the heart rate sensor logged 24 hours of data and on day 2 the Fitbit logged 101 as the total step count and the heart rate sensor logged 2 hours of data. It\u2019s very likely that on day 2 you walked during the other 22 hours so including this day in your analysis could bias your results.</p> <p>Sensor parameters description for <code>[FITBIT_DATA_YIELD]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[SENSORS]</code> The Fitbit sensor we considered for calculating the Fitbit data yield features. We only support <code>FITBIT_HEARTRATE_INTRADAY</code> since sleep data is commonly collected only overnight, and step counts are 0 even when not wearing the Fitbit device."},{"location":"features/fitbit-data-yield/#rapids-provider","title":"RAPIDS provider","text":"<p>Before explaining the data yield features, let\u2019s define the following relevant concepts:</p> <ul> <li>A valid minute is any 60 second window when Fitbit heart rate intraday sensor logged at least 1 row of data</li> <li>A valid hour is any 60 minute window with at least X valid minutes. The X or threshold is given by <code>[MINUTE_RATIO_THRESHOLD_FOR_VALID_YIELDED_HOURS]</code></li> </ul> <p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/fitbit_heartrate_intraday_raw.csv\n- data/raw/{pid}/fitbit_heartrate_intraday_with_datetime.csv\n- data/interim/{pid}/fitbit_data_yield_features/fitbit_data_yield_{language}_{provider_key}.csv\n- data/processed/features/{pid}/fitbit_data_yield.csv\n</code></pre> <p>Parameters description for <code>[FITBIT_DATA_YIELD][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>FITBIT_DATA_YIELD</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed, see table below <code>[MINUTE_RATIO_THRESHOLD_FOR_VALID_YIELDED_HOURS]</code> The proportion <code>[0.0 ,1.0]</code> of valid minutes in a 60-minute window necessary to flag that window as valid. <p>Features description for <code>[FITBIT_DATA_YIELD][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description ratiovalidyieldedminutes - The ratio between the number of valid minutes and the duration in minutes of a time segment. ratiovalidyieldedhours - The ratio between the number of valid hours and the duration in hours of a time segment. If the time segment is shorter than 1 hour this feature will always be 1. <p>Assumptions/Observations</p> <ol> <li> <p>We recommend using <code>ratiovalidyieldedminutes</code> on time segments that are shorter than two or three hours and <code>ratiovalidyieldedhours</code> for longer segments. This is because relying on yielded minutes only can be misleading when a big chunk of those missing minutes are clustered together. </p> <p>For example, let\u2019s assume we are working with a 24-hour time segment that is missing 12 hours of data. Two extreme cases can occur: </p> <p><ol> <li>the 12 missing hours are from the beginning of the segment or </li> <li>30 minutes could be missing from every hour (24 * 30 minutes = 12 hours).</li> </ol></p> <p><code>ratiovalidyieldedminutes</code> would be 0.5 for both <code>a</code> and <code>b</code> (hinting the missing circumstances are similar). However, <code>ratiovalidyieldedhours</code> would be 0.5 for <code>a</code> and 1.0 for <code>b</code> if <code>[MINUTE_RATIO_THRESHOLD_FOR_VALID_YIELDED_HOURS]</code> is between [0.0 and 0.49] (hinting that the missing circumstances might be more favorable for <code>b</code>. In other words, sensed data for <code>b</code> is more evenly spread compared to <code>a</code>.</p> </li> <li> <p>We assume your Fitbit intraday data was sampled (requested form the Fitbit API) at 1 minute intervals, if the interval is longer, for example 15 minutes, you need to take into account that valid minutes and valid hours ratios are going to be small (for example you would have at most 4 \u201cminutes\u201d of data per hour because you would have four 15-minute windows) and so you should adjust your thresholds to include and exclude rows accordingly. If you are in this situation, get in touch with us, we could implement this use case but we are not sure there is enough demand for it at the moment since you can control the sampling rate of the data you request from Fitbit API.</p> </li> </ol>"},{"location":"features/fitbit-heartrate-intraday/","title":"Fitbit Heart Rate Intraday","text":"<p>Sensor parameters description for <code>[FITBIT_HEARTRATE_INTRADAY]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Container where your heart rate intraday data is stored, depending on the data stream you are using this can be a database table, a CSV file, etc."},{"location":"features/fitbit-heartrate-intraday/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments</p> <ul> <li>Available for all time segments</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/fitbit_heartrate_intraday_raw.csv\n- data/raw/{pid}/fitbit_heartrate_intraday_with_datetime.csv\n- data/interim/{pid}/fitbit_heartrate_intraday_features/fitbit_heartrate_intraday_{language}_{provider_key}.csv\n- data/processed/features/{pid}/fitbit_heartrate_intraday.csv\n</code></pre> <p>Parameters description for <code>[FITBIT_HEARTRATE_INTRADAY][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>FITBIT_HEARTRATE_INTRADAY</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed from heart rate intraday data, see table below <p>Features description for <code>[FITBIT_HEARTRATE_INTRADAY][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description maxhr beats/mins The maximum heart rate during a time segment. minhr beats/mins The minimum heart rate during a time segment. avghr beats/mins The average heart rate during a time segment. medianhr beats/mins The median of heart rate during a time segment. modehr beats/mins The mode of heart rate during a time segment. stdhr beats/mins The standard deviation of heart rate during a time segment. diffmaxmodehr beats/mins The difference between the maximum and mode heart rate during a time segment. diffminmodehr beats/mins The difference between the mode and minimum heart rate during a time segment. entropyhr nats Shannon\u2019s entropy measurement based on heart rate during a time segment. minutesonZONE minutes Number of minutes the user\u2019s heart rate fell within each <code>heartrate_zone</code> during a time segment. <p>Assumptions/Observations</p> <ol> <li>There are four heart rate zones (ZONE): <code>outofrange</code>, <code>fatburn</code>, <code>cardio</code>, and <code>peak</code>. Please refer to Fitbit documentation for more information about the way they are computed.</li> </ol>"},{"location":"features/fitbit-heartrate-summary/","title":"Fitbit Heart Rate Summary","text":"<p>Sensor parameters description for <code>[FITBIT_HEARTRATE_SUMMARY]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Container where your heart rate summary data is stored, depending on the data stream you are using this can be a database table, a CSV file, etc."},{"location":"features/fitbit-heartrate-summary/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments</p> <ul> <li>Only available for segments that span 1 or more complete days (e.g. Jan 1<sup>st</sup> 00:00 to Jan 3<sup>rd</sup> 23:59)</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/fitbit_heartrate_summary_raw.csv\n- data/raw/{pid}/fitbit_heartrate_summary_with_datetime.csv\n- data/interim/{pid}/fitbit_heartrate_summary_features/fitbit_heartrate_summary_{language}_{provider_key}.csv\n- data/processed/features/{pid}/fitbit_heartrate_summary.csv\n</code></pre> <p>Parameters description for <code>[FITBIT_HEARTRATE_SUMMARY][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>FITBIT_HEARTRATE_SUMMARY</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed from heart rate summary data, see table below <p>Features description for <code>[FITBIT_HEARTRATE_SUMMARY][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description maxrestinghr beats/mins The maximum daily resting heart rate during a time segment. minrestinghr beats/mins The minimum daily resting heart rate during a time segment. avgrestinghr beats/mins The average daily resting heart rate during a time segment. medianrestinghr beats/mins The median of daily resting heart rate during a time segment. moderestinghr beats/mins The mode of daily resting heart rate during a time segment. stdrestinghr beats/mins The standard deviation of daily resting heart rate during a time segment. diffmaxmoderestinghr beats/mins The difference between the maximum and mode daily resting heart rate during a time segment. diffminmoderestinghr beats/mins The difference between the mode and minimum daily resting heart rate during a time segment. entropyrestinghr nats Shannon\u2019s entropy measurement based on daily resting heart rate during a time segment. sumcaloriesZONE cals The total daily calories burned within <code>heartrate_zone</code> during a time segment. maxcaloriesZONE cals The maximum daily calories burned within <code>heartrate_zone</code> during a time segment. mincaloriesZONE cals The minimum daily calories burned within <code>heartrate_zone</code> during a time segment. avgcaloriesZONE cals The average daily calories burned within <code>heartrate_zone</code> during a time segment. mediancaloriesZONE cals The median of daily calories burned within <code>heartrate_zone</code> during a time segment. stdcaloriesZONE cals The standard deviation of daily calories burned within <code>heartrate_zone</code> during a time segment. entropycaloriesZONE nats Shannon\u2019s entropy measurement based on daily calories burned within <code>heartrate_zone</code> during a time segment. <p>Assumptions/Observations</p> <ol> <li> <p>There are four heart rate zones (ZONE): <code>outofrange</code>, <code>fatburn</code>, <code>cardio</code>, and <code>peak</code>. Please refer to Fitbit documentation for more information about the way they are computed.</p> </li> <li> <p>Calories\u2019 accuracy depends on the users\u2019 Fitbit profile (weight, height, etc.).</p> </li> </ol>"},{"location":"features/fitbit-sleep-intraday/","title":"Fitbit Sleep Intraday","text":"<p>Sensor parameters description for <code>[FITBIT_SLEEP_INTRADAY]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Container where your sleep intraday data is stored, depending on the data stream you are using this can be a database table, a CSV file, etc."},{"location":"features/fitbit-sleep-intraday/#rapids-provider","title":"RAPIDS provider","text":"<p>Understanding RAPIDS features</p> <p>This diagram will help you understand how sleep episodes are chunked and grouped within time segments for the RAPIDS provider.</p> <p>Available time segments</p> <ul> <li>Available for all time segments</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/fitbit_sleep_intraday_raw.csv\n- data/raw/{pid}/fitbit_sleep_intraday_with_datetime.csv\n- data/interim/{pid}/fitbit_sleep_intraday_episodes.csv\n- data/interim/{pid}/fitbit_sleep_intraday_episodes_resampled.csv\n- data/interim/{pid}/fitbit_sleep_intraday_episodes_resampled_with_datetime.csv\n- data/interim/{pid}/fitbit_sleep_intraday_features/fitbit_sleep_intraday_{language}_{provider_key}.csv\n- data/processed/features/{pid}/fitbit_sleep_intraday.csv\n</code></pre> <p>Parameters description for <code>[FITBIT_SLEEP_INTRADAY][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>FITBIT_SLEEP_INTRADAY</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed from sleep intraday data, see table below <code>[SLEEP_LEVELS]</code> Fitbit\u2019s sleep API Version 1 only provides <code>CLASSIC</code> records. However, Version 1.2 provides 2 types of records: <code>CLASSIC</code> and <code>STAGES</code>. <code>STAGES</code> is only available in devices with a heart rate sensor and even those devices will fail to report it if the battery is low or the device is not tight enough. While <code>CLASSIC</code> contains 3 sleep levels (<code>awake</code>, <code>restless</code>, and <code>asleep</code>), <code>STAGES</code> contains 4 sleep levels (<code>wake</code>, <code>deep</code>, <code>light</code>, <code>rem</code>). To make it consistent, RAPIDS groups them into 2 <code>UNIFIED</code> sleep levels: <code>awake</code> (<code>CLASSIC</code>: <code>awake</code> and <code>restless</code>; <code>STAGES</code>: <code>wake</code>) and <code>asleep</code> (<code>CLASSIC</code>: <code>asleep</code>; <code>STAGES</code>: <code>deep</code>, <code>light</code>, and <code>rem</code>). In this section, there is a boolean flag named <code>INCLUDE_ALL_GROUPS</code> that if set to TRUE, computes LEVELS_AND_TYPES features grouping all levels together in a single <code>all</code> category. <code>[SLEEP_TYPES]</code> Types of sleep to be included in the feature extraction computation. There are three sleep types: <code>main</code>, <code>nap</code>, and <code>all</code>. The <code>all</code> type means both main sleep and naps are considered. <p>Features description for <code>[FITBIT_SLEEP_INTRADAY][PROVIDERS][RAPIDS][LEVELS_AND_TYPES]</code>:</p> Feature\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Units Description countepisode<code>[LEVEL][TYPE]</code> episodes Number of <code>[LEVEL][TYPE]</code>sleep episodes. <code>[LEVEL]</code>is one of <code>[SLEEP_LEVELS]</code> (e.g. awake-classic or rem-stages) and <code>[TYPE]</code> is one of <code>[SLEEP_TYPES]</code> (e.g. main). <code>[LEVEL]</code> can also be <code>all</code> when <code>INCLUDE_ALL_GROUPS</code> is True, which ignores the levels and groups by sleep types. sumduration<code>[LEVEL][TYPE]</code> minutes Total duration of all <code>[LEVEL][TYPE]</code>sleep episodes. <code>[LEVEL]</code>is one of <code>[SLEEP_LEVELS]</code> (e.g. awake-classic or rem-stages) and <code>[TYPE]</code> is one of <code>[SLEEP_TYPES]</code> (e.g. main). <code>[LEVEL]</code> can also be <code>all</code> when <code>INCLUDE_ALL_GROUPS</code> is True, which ignores the levels and groups by sleep types. maxduration<code>[LEVEL][TYPE]</code> minutes Longest duration of any <code>[LEVEL][TYPE]</code>sleep episode. <code>[LEVEL]</code>is one of <code>[SLEEP_LEVELS]</code> (e.g. awake-classic or rem-stages) and <code>[TYPE]</code> is one of <code>[SLEEP_TYPES]</code> (e.g. main). <code>[LEVEL]</code> can also be <code>all</code> when <code>INCLUDE_ALL_GROUPS</code> is True, which ignores the levels and groups by sleep types. minduration<code>[LEVEL][TYPE]</code> minutes Shortest duration of any <code>[LEVEL][TYPE]</code>sleep episode. <code>[LEVEL]</code>is one of <code>[SLEEP_LEVELS]</code> (e.g. awake-classic or rem-stages) and <code>[TYPE]</code> is one of <code>[SLEEP_TYPES]</code> (e.g. main). <code>[LEVEL]</code> can also be <code>all</code> when <code>INCLUDE_ALL_GROUPS</code> is True, which ignores the levels and groups by sleep types. avgduration<code>[LEVEL][TYPE]</code> minutes Average duration of all <code>[LEVEL][TYPE]</code>sleep episodes. <code>[LEVEL]</code>is one of <code>[SLEEP_LEVELS]</code> (e.g. awake-classic or rem-stages) and <code>[TYPE]</code> is one of <code>[SLEEP_TYPES]</code> (e.g. main). <code>[LEVEL]</code> can also be <code>all</code> when <code>INCLUDE_ALL_GROUPS</code> is True, which ignores the levels and groups by sleep types. medianduration<code>[LEVEL][TYPE]</code> minutes Median duration of all <code>[LEVEL][TYPE]</code>sleep episodes. <code>[LEVEL]</code>is one of <code>[SLEEP_LEVELS]</code> (e.g. awake-classic or rem-stages) and <code>[TYPE]</code> is one of <code>[SLEEP_TYPES]</code> (e.g. main). <code>[LEVEL]</code> can also be <code>all</code> when <code>INCLUDE_ALL_GROUPS</code> is True, which ignores the levels and groups by sleep types. stdduration<code>[LEVEL][TYPE]</code> minutes Standard deviation duration of all <code>[LEVEL][TYPE]</code>sleep episodes. <code>[LEVEL]</code>is one of <code>[SLEEP_LEVELS]</code> (e.g. awake-classic or rem-stages) and <code>[TYPE]</code> is one of <code>[SLEEP_TYPES]</code> (e.g. main). <code>[LEVEL]</code> can also be <code>all</code> when <code>INCLUDE_ALL_GROUPS</code> is True, which ignores the levels and groups by sleep types. <p>Features description for <code>[FITBIT_SLEEP_INTRADAY][PROVIDERS][RAPIDS]</code> RATIOS <code>[ACROSS_LEVELS]</code>:</p> Feature\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Units Description ratiocount<code>[LEVEL]</code> - Ratio between the count of episodes of a single sleep <code>[LEVEL]</code> and the count of all episodes of all levels during both <code>main</code> and <code>nap</code> sleep types. This answers the question: what percentage of all <code>wake</code>, <code>deep</code>, <code>light</code>, and <code>rem</code> episodes were <code>rem</code>? (e.g., \\(countepisode[remstages][all] / countepisode[all][all]\\)) ratioduration<code>[LEVEL]</code> - Ratio between the duration of episodes of a single sleep <code>[LEVEL]</code> and the duration of all episodes of all levels during both <code>main</code> and <code>nap</code> sleep types. This answers the question: what percentage of all <code>wake</code>, <code>deep</code>, <code>light</code>, and <code>rem</code> time was <code>rem</code>? (e.g., \\(sumduration[remstages][all] / sumduration[all][all]\\)) <p>Features description for <code>[FITBIT_SLEEP_INTRADAY][PROVIDERS][RAPIDS]</code> RATIOS <code>[ACROSS_TYPES]</code>:</p> Feature\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Units Description ratiocountmain - Ratio between the count of all <code>main</code> episodes (independently of the levels inside) divided by the count of all <code>main</code> and <code>nap</code> episodes. This answers the question: what percentage of all sleep episodes (<code>main</code> and <code>nap</code>) were <code>main</code>? We do not provide the ratio for <code>nap</code> because is complementary. (\\(countepisode[all][main] / countepisode[all][all]\\)) ratiodurationmain - Ratio between the duration of all <code>main</code> episodes (independently of the levels inside) divided by the duration of all <code>main</code> and <code>nap</code> episodes. This answers the question: what percentage of all sleep time (<code>main</code> and <code>nap</code>) was <code>main</code>? We do not provide the ratio for <code>nap</code> because is complementary. (\\(sumduration[all][main] / sumduration[all][all]\\)) <p>Features description for <code>[FITBIT_SLEEP_INTRADAY][PROVIDERS][RAPIDS]</code> RATIOS <code>[WITHIN_LEVELS]</code>:</p> Feature\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Units Description ratiocountmainwithin<code>[LEVEL]</code> - Ratio between the count of episodes of a single sleep <code>[LEVEL]</code> during <code>main</code> sleep divided by the count of episodes of a single sleep <code>[LEVEL]</code> during <code>main</code> and <code>nap</code>. This answers the question: are <code>rem</code> episodes more frequent during <code>main</code> than <code>nap</code> sleep? We do not provide the ratio for <code>nap</code> because is complementary. (\\(countepisode[remstages][main] / countepisode[remstages][all]\\)) ratiodurationmainwithin<code>[LEVEL]</code> - Ratio between the duration of episodes of a single sleep <code>[LEVEL]</code> during <code>main</code> sleep divided by the duration of episodes of a single sleep <code>[LEVEL]</code> during <code>main</code> and <code>nap</code>. This answers the question: is <code>rem</code> time more frequent during <code>main</code> than <code>nap</code> sleep? We do not provide the ratio for <code>nap</code> because is complementary. (\\(countepisode[remstages][main] / countepisode[remstages][all]\\)) <p>Features description for <code>[FITBIT_SLEEP_INTRADAY][PROVIDERS][RAPIDS]</code> RATIOS <code>[WITHIN_TYPES]</code>:</p> Feature\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Units Description ratiocount<code>[LEVEL]</code>within<code>[TYPE]</code> - Ratio between the count of episodes of a single sleep <code>[LEVEL]</code> and the count of all episodes of all levels during either <code>main</code> or <code>nap</code> sleep types. This answers the question: what percentage of all <code>wake</code>, <code>deep</code>, <code>light</code>, and <code>rem</code> episodes were <code>rem</code> during <code>main</code>/<code>nap</code> sleep time? (e.g., \\(countepisode[remstages][main] / countepisode[all][main]\\)) ratioduration<code>[LEVEL]</code>within<code>[TYPE]</code> - Ratio between the duration of episodes of a single sleep <code>[LEVEL]</code> and the duration of all episodes of all levels during either <code>main</code> or <code>nap</code> sleep types. This answers the question: what percentage of all <code>wake</code>, <code>deep</code>, <code>light</code>, and <code>rem</code> time was <code>rem</code> during <code>main</code>/<code>nap</code> sleep time? (e.g., \\(sumduration[remstages][main] / sumduration[all][main]\\)) <p>Assumptions/Observations</p> <ol> <li>This diagram will help you understand how sleep episodes are chunked and grouped within time segments for the RAPIDS provider.</li> <li>Features listed in <code>[LEVELS_AND_TYPES]</code> are computed for any levels and types listed in <code>[SLEEP_LEVELS]</code> or <code>[SLEEP_TYPES]</code>. For example if <code>STAGES</code> only contains <code>[rem, light]</code> you will not get <code>countepisode[wake|deep][TYPE]</code> or sum, max, min, avg, median, or std <code>duration</code>. Levels or types in these lists do not influence <code>RATIOS</code> or <code>ROUTINE</code> features.</li> <li>Any <code>[LEVEL]</code> grouping is done within the elements of each class <code>CLASSIC</code>, <code>STAGES</code>, and <code>UNIFIED</code>. That is, we never combine <code>CLASSIC</code> or <code>STAGES</code> types to compute features.</li> <li>The categories for <code>all</code> levels (when <code>INCLUDE_ALL_GROUPS</code> is <code>True</code>) and <code>all</code> <code>SLEEP_TYPES</code> are not considered for <code>RATIOS</code> features as they are always 1.</li> <li>These features can be computed in time segments of any length, but only the 1-minute sleep chunks within each segment instance will be used.</li> </ol>"},{"location":"features/fitbit-sleep-intraday/#price-provider","title":"PRICE provider","text":"<p>Understanding PRICE features</p> <p>This diagram will help you understand how sleep episodes are chunked and grouped within time segments and <code>LNE-LNE</code> intervals for the PRICE provider.</p> <p>Available time segments</p> <ul> <li>Available for any time segments larger or equal to one day</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/fitbit_sleep_intraday_raw.csv\n- data/raw/{pid}/fitbit_sleep_intraday_parsed.csv\n- data/interim/{pid}/fitbit_sleep_intraday_episodes_resampled.csv\n- data/interim/{pid}/fitbit_sleep_intraday_episodes_resampled_with_datetime.csv\n- data/interim/{pid}/fitbit_sleep_intraday_features/fitbit_sleep_intraday_{language}_{provider_key}.csv\n- data/processed/features/{pid}/fitbit_sleep_intraday.csv\n</code></pre> <p>Parameters description for <code>[FITBIT_SLEEP_INTRADAY][PROVIDERS][PRICE]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>FITBIT_SLEEP_INTRADAY</code> features from the <code>PRICE</code> provider <code>[FEATURES]</code> Features to be computed from sleep intraday data, see table below <code>[SLEEP_LEVELS]</code> Fitbit\u2019s sleep API Version 1 only provides <code>CLASSIC</code> records. However, Version 1.2 provides 2 types of records: <code>CLASSIC</code> and <code>STAGES</code>. <code>STAGES</code> is only available in devices with a heart rate sensor and even those devices will fail to report it if the battery is low or the device is not tight enough. While <code>CLASSIC</code> contains 3 sleep levels (<code>awake</code>, <code>restless</code>, and <code>asleep</code>), <code>STAGES</code> contains 4 sleep levels (<code>wake</code>, <code>deep</code>, <code>light</code>, <code>rem</code>). To make it consistent, RAPIDS groups them into 2 <code>UNIFIED</code> sleep levels: <code>awake</code> (<code>CLASSIC</code>: <code>awake</code> and <code>restless</code>; <code>STAGES</code>: <code>wake</code>) and <code>asleep</code> (<code>CLASSIC</code>: <code>asleep</code>; <code>STAGES</code>: <code>deep</code>, <code>light</code>, and <code>rem</code>). In this section, there is a boolean flag named <code>INCLUDE_ALL_GROUPS</code> that if set to TRUE, computes avgdurationallmain<code>[DAY_TYPE]</code> features grouping all levels together in a single <code>all</code> category. <code>[DAY_TYPE]</code> The features of this provider can be computed using daily averages/standard deviations that were extracted on <code>WEEKEND</code> days only, <code>WEEK</code> days only, or <code>ALL</code> days <code>[LAST_NIGHT_END]</code> Only <code>main</code> sleep episodes that start within the <code>LNE-LNE</code> interval [<code>LAST_NIGHT_END</code>, <code>LAST_NIGHT_END</code> + 23H 59M 59S] are taken into account to compute the features described below. <code>[LAST_NIGHT_END]</code> is a number ranging from 0 (midnight) to 1439 (23:59). <p>Features description for <code>[FITBIT_SLEEP_INTRADAY][PROVIDERS][PRICE]</code>:</p> Feature\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Units Description avgduration<code>[LEVEL]</code>main<code>[DAY_TYPE]</code> minutes Average duration of daily sleep chunks of a <code>LEVEL</code>. Use the <code>DAY_TYPE</code> flag to include daily durations from weekend days only, weekdays, or both. Use <code>[LEVEL]</code> to group all levels in a single <code>all</code> category. avgratioduration<code>[LEVEL]</code>withinmain<code>[DAY_TYPE]</code> - Average of the daily ratio between the duration of sleep chunks of a <code>LEVEL</code> and total duration of all <code>main</code> sleep episodes in a day. When <code>INCLUDE_ALL_GROUPS</code> is <code>True</code> the <code>all</code> <code>LEVEL</code> is ignored since this feature is always 1. Use the <code>DAY_TYPE</code> flag to include start times from weekend days only, weekdays, or both. avgstarttimeofepisodemain<code>[DAY_TYPE]</code> minutes Average of all start times of the first <code>main</code> sleep episode within each <code>LNE-LNE</code> interval in a time segment. Use the <code>DAY_TYPE</code> flag to include start times from <code>LNE-LNE</code> intervals that start on weekend days only, weekdays, or both. avgendtimeofepisodemain<code>[DAY_TYPE]</code> minutes Average of all end times of the last <code>main</code> sleep episode within each <code>LNE-LNE</code> interval in a time segment. Use the <code>DAY_TYPE</code> flag to include end times from <code>LNE-LNE</code> intervals that start on weekend days only, weekdays, or both. avgmidpointofepisodemain<code>[DAY_TYPE]</code> minutes Average of all the differences between <code>avgendtime...</code> and <code>avgstarttime..</code> in a time segment. Use the <code>DAY_TYPE</code> flag to include end times from <code>LNE-LNE</code> intervals that start on weekend days only, weekdays, or both. stdstarttimeofepisodemain<code>[DAY_TYPE]</code> minutes Standard deviation of all start times of the first <code>main</code> sleep episode within each <code>LNE-LNE</code> interval in a time segment. Use the <code>DAY_TYPE</code> flag to include start times from <code>LNE-LNE</code> intervals that start on weekend days only, weekdays, or both. stdendtimeofepisodemain<code>[DAY_TYPE]</code> minutes Standard deviation of all end times of the last <code>main</code> sleep episode within each <code>LNE-LNE</code> interval in a time segment. Use the <code>DAY_TYPE</code> flag to include end times from <code>LNE-LNE</code> intervals that start on weekend days only, weekdays, or both. stdmidpointofepisodemain<code>[DAY_TYPE]</code> minutes Standard deviation of all the differences between <code>avgendtime...</code> and <code>avgstarttime..</code> in a time segment. Use the <code>DAY_TYPE</code> flag to include end times from <code>LNE-LNE</code> intervals that start on weekend days only, weekdays, or both. socialjetlag minutes Difference in minutes between the avgmidpointofepisodemain of weekends and weekdays that belong to each time segment instance. If your time segment does not contain at least one week day and one weekend day this feature will be NA. rmssdmeanstarttimeofepisodemain minutes Square root of the mean squared successive difference (RMSSD) between today\u2019s and yesterday\u2019s <code>starttimeofepisodemain</code> values across the entire participant\u2019s sleep data grouped per time segment instance. It represents the mean of how someone\u2019s <code>starttimeofepisodemain</code> (bedtime) changed from night to night. rmssdmeanendtimeofepisodemain minutes Square root of the mean squared successive difference (RMSSD) between today\u2019s and yesterday\u2019s <code>endtimeofepisodemain</code> values across the entire participant\u2019s sleep data grouped per time segment instance. It represents the mean of how someone\u2019s <code>endtimeofepisodemain</code> (wake time) changed from night to night. rmssdmeanmidpointofepisodemain minutes Square root of the mean squared successive difference (RMSSD) between today\u2019s and yesterday\u2019s <code>midpointofepisodemain</code> values across the entire participant\u2019s sleep data grouped per time segment instance. It represents the mean of how someone\u2019s <code>midpointofepisodemain</code> (mid time between bedtime and wake time) changed from night to night. rmssdmedianstarttimeofepisodemain minutes Square root of the median squared successive difference (RMSSD) between today\u2019s and yesterday\u2019s <code>starttimeofepisodemain</code> values across the entire participant\u2019s sleep data grouped per time segment instance. It represents the median of how someone\u2019s <code>starttimeofepisodemain</code> (bedtime) changed from night to night. rmssdmedianendtimeofepisodemain minutes Square root of the median squared successive difference (RMSSD) between today\u2019s and yesterday\u2019s <code>endtimeofepisodemain</code> values across the entire participant\u2019s sleep data grouped per time segment instance. It represents the median of how someone\u2019s <code>endtimeofepisodemain</code> (wake time) changed from night to night. rmssdmedianmidpointofepisodemain minutes Square root of the median squared successive difference (RMSSD) between today\u2019s and yesterday\u2019s <code>midpointofepisodemain</code> values across the entire participant\u2019s sleep data grouped per time segment instance. It represents the median of how someone\u2019s <code>midpointofepisodemain</code> (average mid time between bedtime and wake time) changed from night to night. <p>Assumptions/Observations</p> <ol> <li>This diagram will help you understand how sleep episodes are chunked and grouped within time segments and <code>LNE-LNE</code> intervals for the PRICE provider.</li> <li>We recommend you use periodic segments that start in the morning so RAPIDS can chunk and group sleep episodes overnight. Shifted segments (as any other segments) are labelled based on their start and end date times.</li> <li><code>avgstarttime...</code> and <code>avgendtime...</code> are roughly equivalent to an average bed and awake time only if you are using shifted segments.</li> <li>The features of this provider are only available on time segments that are longer than 24 hours because they are based on descriptive statistics computed across daily values.</li> <li>Even though Fitbit provides 2 types of sleep episodes (<code>main</code> and <code>nap</code>), only <code>main</code> sleep episodes are considered.</li> <li>The reference point for all times is 00:00 of the first day in the LNE-LNE interval.</li> <li>Sleep episodes are formed by 1-minute chunks that we group overnight starting from today\u2019s LNE and ending on tomorrow\u2019s LNE or the end of that segment (whatever is first). </li> <li>The features <code>avgstarttime...</code> and <code>avgendtime...</code> are the average of the first and last sleep episode across every LNE-LNE interval within a segment (<code>avgmidtime...</code> is the mid point between start and end). Therefore, only segments longer than 24hrs will be averaged across more than one LNE-LNE interval.</li> <li><code>socialjetlag</code> is only available on segment instances equal or longer than 48hrs that contain at least one weekday day and one weekend day, for example seven-day (weekly) segments.</li> </ol>"},{"location":"features/fitbit-sleep-summary/","title":"Fitbit Sleep Summary","text":"<p>Sensor parameters description for <code>[FITBIT_SLEEP_SUMMARY]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Container where your sleep summary data is stored, depending on the data stream you are using this can be a database table, a CSV file, etc."},{"location":"features/fitbit-sleep-summary/#rapids-provider","title":"RAPIDS provider","text":"<p>Understanding RAPIDS features</p> <p>This diagram will help you understand how sleep episodes are chunked and grouped within time segments using <code>SLEEP_SUMMARY_LAST_NIGHT_END</code> for the RAPIDS provider.</p> <p>Available time segments</p> <ul> <li>Only available for segments that span 1 or more complete days (e.g. Jan 1<sup>st</sup> 00:00 to Jan 3<sup>rd</sup> 23:59)</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/fitbit_sleep_summary_raw.csv\n- data/raw/{pid}/fitbit_sleep_summary_with_datetime.csv\n- data/interim/{pid}/fitbit_sleep_summary_features/fitbit_sleep_summary_{language}_{provider_key}.csv\n- data/processed/features/{pid}/fitbit_sleep_summary.csv\n</code></pre> <p>Parameters description for <code>[FITBIT_SLEEP_SUMMARY][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>FITBIT_SLEEP_SUMMARY</code> features from the <code>RAPIDS</code> provider <code>[SLEEP_TYPES]</code> Types of sleep to be included in the feature extraction computation. There are three sleep types: <code>main</code>, <code>nap</code>, and <code>all</code>. The <code>all</code> type means both main sleep and naps are considered. <code>[FEATURES]</code> Features to be computed from sleep summary data, see table below <code>[FITBIT_DATA_STREAMS][data stream][SLEEP_SUMMARY_LAST_NIGHT_END]</code> As an exception, the <code>LAST_NIGHT_END</code> parameter for this provider is in the data stream configuration section. This parameter controls how sleep episodes are assigned to different days and affects wake and bedtimes. <p>Features description for <code>[FITBIT_SLEEP_SUMMARY][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description firstwaketimeTYPE minutes First wake time for a certain sleep type during a time segment. Wake time is number of minutes after midnight of a sleep episode\u2019s end time. lastwaketimeTYPE minutes Last wake time for a certain sleep type during a time segment. Wake time is number of minutes after midnight of a sleep episode\u2019s end time. firstbedtimeTYPE minutes First bedtime for a certain sleep type during a time segment. Bedtime is number of minutes after midnight of a sleep episode\u2019s start time. lastbedtimeTYPE minutes Last bedtime for a certain sleep type during a time segment. Bedtime is number of minutes after midnight of a sleep episode\u2019s start time. countepisodeTYPE episodes Number of sleep episodes for a certain sleep type during a time segment. avgefficiencyTYPE scores Average sleep efficiency for a certain sleep type during a time segment. sumdurationafterwakeupTYPE minutes Total duration the user stayed in bed after waking up for a certain sleep type during a time segment. sumdurationasleepTYPE minutes Total sleep duration for a certain sleep type during a time segment. sumdurationawakeTYPE minutes Total duration the user stayed awake but still in bed for a certain sleep type during a time segment. sumdurationtofallasleepTYPE minutes Total duration the user spent to fall asleep for a certain sleep type during a time segment. sumdurationinbedTYPE minutes Total duration the user stayed in bed (sumdurationtofallasleep + sumdurationawake + sumdurationasleep + sumdurationafterwakeup) for a certain sleep type during a time segment. avgdurationafterwakeupTYPE minutes Average duration the user stayed in bed after waking up for a certain sleep type during a time segment. avgdurationasleepTYPE minutes Average sleep duration for a certain sleep type during a time segment. avgdurationawakeTYPE minutes Average duration the user stayed awake but still in bed for a certain sleep type during a time segment. avgdurationtofallasleepTYPE minutes Average duration the user spent to fall asleep for a certain sleep type during a time segment. avgdurationinbedTYPE minutes Average duration the user stayed in bed (sumdurationtofallasleep + sumdurationawake + sumdurationasleep + sumdurationafterwakeup) for a certain sleep type during a time segment. <p>Assumptions/Observations</p> <ol> <li>This diagram will help you understand how sleep episodes are chunked and grouped within time segments using <code>LNE</code> for the RAPIDS provider.</li> <li>There are three sleep types (TYPE): <code>main</code>, <code>nap</code>, <code>all</code>. The <code>all</code> type groups both <code>main</code> sleep and <code>naps</code>. All types are based on Fitbit\u2019s labels.</li> <li>There are two versions of Fitbit\u2019s sleep API (version 1 and version 1.2), and each provides raw sleep data in a different format:<ul> <li>Count &amp; duration summaries. <code>v1</code> contains <code>count_awake</code>, <code>duration_awake</code>, <code>count_awakenings</code>, <code>count_restless</code>, and <code>duration_restless</code> fields for every sleep record but <code>v1.2</code> does not.</li> </ul> </li> <li>API columns. Most features are computed based on the values provided by Fitbit\u2019s API: <code>efficiency</code>, <code>minutes_after_wakeup</code>, <code>minutes_asleep</code>, <code>minutes_awake</code>, <code>minutes_to_fall_asleep</code>, <code>minutes_in_bed</code>, <code>is_main_sleep</code> and <code>type</code>.</li> <li>Bed time and sleep duration are based on episodes that started between today\u2019s LNE and tomorrow\u2019s LNE while awake time is based on the episodes that started between yesterday\u2019s LNE and today\u2019s LNE</li> <li>The reference point for bed/awake times is today\u2019s 00:00. You can have bedtimes larger than 24 and awake times smaller than 0</li> <li>These features are only available for time segments that span midnight to midnight of the same or different day.</li> <li>We include first and last wake and bedtimes because, when <code>LAST_NIGHT_END</code> is 10 am, the first bedtime could match a nap at 2 pm, and the last bedtime could match a main overnight sleep episode that starts at 10pm.</li> <li>Set the value for <code>SLEEP_SUMMARY_LAST_NIGHT_END</code> int the config parameter [FITBIT_DATA_STREAMS][data stream][SLEEP_SUMMARY_LAST_NIGHT_END].</li> </ol>"},{"location":"features/fitbit-steps-intraday/","title":"Fitbit Steps Intraday","text":"<p>Sensor parameters description for <code>[FITBIT_STEPS_INTRADAY]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Container where your steps intraday data is stored, depending on the data stream you are using this can be a database table, a CSV file, etc."},{"location":"features/fitbit-steps-intraday/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments</p> <ul> <li>Available for all time segments</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/fitbit_steps_intraday_raw.csv\n- data/raw/{pid}/fitbit_steps_intraday_with_datetime.csv\n- data/interim/{pid}/fitbit_steps_intraday_features/fitbit_steps_intraday_{language}_{provider_key}.csv\n- data/processed/features/{pid}/fitbit_steps_intraday.csv\n</code></pre> <p>Parameters description for <code>[FITBIT_STEPS_INTRADAY][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>FITBIT_STEPS_INTRADAY</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed from steps intraday data, see table below <code>[THRESHOLD_ACTIVE_BOUT]</code> Every minute with Fitbit steps data wil be labelled as <code>sedentary</code> if its step count is below this threshold, otherwise, <code>active</code>. <code>[INCLUDE_ZERO_STEP_ROWS]</code> Whether or not to include time segments with a 0 step count during the whole day. <p>Features description for <code>[FITBIT_STEPS_INTRADAY][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description sumsteps steps The total step count during a time segment. maxsteps steps The maximum step count during a time segment. minsteps steps The minimum step count during a time segment. avgsteps steps The average step count during a time segment. stdsteps steps The standard deviation of step count during a time segment. countepisodesedentarybout bouts Number of sedentary bouts during a time segment. sumdurationsedentarybout minutes Total duration of all sedentary bouts during a time segment. maxdurationsedentarybout minutes The maximum duration of any sedentary bout during a time segment. mindurationsedentarybout minutes The minimum duration of any sedentary bout during a time segment. avgdurationsedentarybout minutes The average duration of sedentary bouts during a time segment. stddurationsedentarybout minutes The standard deviation of the duration of sedentary bouts during a time segment. countepisodeactivebout bouts Number of active bouts during a time segment. sumdurationactivebout minutes Total duration of all active bouts during a time segment. maxdurationactivebout minutes The maximum duration of any active bout during a time segment. mindurationactivebout minutes The minimum duration of any active bout during a time segment. avgdurationactivebout minutes The average duration of active bouts during a time segment. stddurationactivebout minutes The standard deviation of the duration of active bouts during a time segment. <p>Assumptions/Observations</p> <ol> <li>Active and sedentary bouts. If the step count per minute is smaller than <code>THRESHOLD_ACTIVE_BOUT</code> (default value is 10), that minute is labelled as sedentary, otherwise, is labelled as active. Active and sedentary bouts are periods of consecutive minutes labelled as <code>active</code> or <code>sedentary</code>.</li> </ol>"},{"location":"features/fitbit-steps-summary/","title":"Fitbit Steps Summary","text":"<p>Sensor parameters description for <code>[FITBIT_STEPS_SUMMARY]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Container where your steps summary data is stored, depending on the data stream you are using this can be a database table, a CSV file, etc."},{"location":"features/fitbit-steps-summary/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments</p> <ul> <li>Only available for segments that span 1 or more complete days (e.g. Jan 1<sup>st</sup> 00:00 to Jan 3<sup>rd</sup> 23:59)</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/fitbit_steps_summary_raw.csv\n- data/raw/{pid}/fitbit_steps_summary_with_datetime.csv\n- data/interim/{pid}/fitbit_steps_summary_features/fitbit_steps_summary_{language}_{provider_key}.csv\n- data/processed/features/{pid}/fitbit_steps_summary.csv\n</code></pre> <p>Parameters description for <code>[FITBIT_STEPS_SUMMARY][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>FITBIT_STEPS_SUMMARY</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed from steps summary data, see table below <p>Features description for <code>[FITBIT_STEPS_SUMMARY][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description maxsumsteps steps The maximum daily step count during a time segment. minsumsteps steps The minimum daily step count during a time segment. avgsumsteps steps The average daily step count during a time segment. mediansumsteps steps The median of daily step count during a time segment. stdsumsteps steps The standard deviation of daily step count during a time segment. <p>Assumptions/Observations</p> <p>NA</p>"},{"location":"features/phone-accelerometer/","title":"Phone Accelerometer","text":"<p>Sensor parameters description for <code>[PHONE_ACCELEROMETER]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the accelerometer data is stored"},{"location":"features/phone-accelerometer/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android and iOS</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_accelerometer_raw.csv\n- data/raw/{pid}/phone_accelerometer_with_datetime.csv\n- data/interim/{pid}/phone_accelerometer_features/phone_accelerometer_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_accelerometer.csv\n</code></pre> <p>Parameters description for <code>[PHONE_ACCELEROMETER][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_ACCELEROMETER</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed, see table below <p>Features description for <code>[PHONE_ACCELEROMETER][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description maxmagnitude m/s<sup>2</sup> The maximum magnitude of acceleration (\\(\\|acceleration\\| = \\sqrt{x^2 + y^2 + z^2}\\)). minmagnitude m/s<sup>2</sup> The minimum magnitude of acceleration. avgmagnitude m/s<sup>2</sup> The average magnitude of acceleration. medianmagnitude m/s<sup>2</sup> The median magnitude of acceleration. stdmagnitude m/s<sup>2</sup> The standard deviation of acceleration. <p>Assumptions/Observations</p> <ol> <li>Analyzing accelerometer data is a memory intensive task. If RAPIDS crashes is likely because the accelerometer dataset for a participant is to big to fit in memory. We are considering different alternatives to overcome this problem.</li> </ol>"},{"location":"features/phone-accelerometer/#panda-provider","title":"PANDA provider","text":"<p>These features are based on the work by Panda et al.</p> <p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android and iOS</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_accelerometer_raw.csv\n- data/raw/{pid}/phone_accelerometer_with_datetime.csv\n- data/interim/{pid}/phone_accelerometer_features/phone_accelerometer_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_accelerometer.csv\n</code></pre> <p>Parameters description for <code>[PHONE_ACCELEROMETER][PROVIDERS][PANDA]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_ACCELEROMETER</code> features from the <code>PANDA</code> provider <code>[FEATURES]</code> Features to be computed for exertional and non-exertional activity episodes, see table below <p>Features description for <code>[PHONE_ACCELEROMETER][PROVIDERS][PANDA]</code>:</p> Feature Units Description sumduration minutes Total duration of all exertional or non-exertional activity episodes. maxduration minutes Longest duration of any exertional or non-exertional activity episode. minduration minutes Shortest duration of any exertional or non-exertional activity episode. avgduration minutes Average duration of any exertional or non-exertional activity episode. medianduration minutes Median duration of any exertional or non-exertional activity episode. stdduration minutes Standard deviation of the duration of all exertional or non-exertional activity episodes. <p>Assumptions/Observations</p> <ol> <li>Analyzing accelerometer data is a memory intensive task. If RAPIDS crashes is likely because the accelerometer dataset for a participant is to big to fit in memory. We are considering different alternatives to overcome this problem.</li> <li>See Panda et al for a definition of exertional and non-exertional activity episodes</li> </ol>"},{"location":"features/phone-activity-recognition/","title":"Phone Activity Recognition","text":"<p>Sensor parameters description for <code>[PHONE_ACTIVITY_RECOGNITION]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER][ANDROID]</code> Data stream container (database table, CSV file, etc.) where the activity data from Android devices is stored (the AWARE client saves this data on different tables for Android and iOS) <code>[CONTAINER][IOS]</code> Data stream container (database table, CSV file, etc.) where the activity data from iOS devices is stored (the AWARE client saves this data on different tables for Android and iOS) <code>[EPISODE_THRESHOLD_BETWEEN_ROWS]</code> Difference in minutes between any two rows for them to be considered part of the same activity episode"},{"location":"features/phone-activity-recognition/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android and iOS</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_activity_recognition_raw.csv\n- data/raw/{pid}/phone_activity_recognition_with_datetime.csv\n- data/interim/{pid}/phone_activity_recognition_episodes.csv\n- data/interim/{pid}/phone_activity_recognition_episodes_resampled.csv\n- data/interim/{pid}/phone_activity_recognition_episodes_resampled_with_datetime.csv\n- data/interim/{pid}/phone_activity_recognition_features/phone_activity_recognition_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_activity_recognition.csv\n</code></pre> <p>Parameters description for <code>[PHONE_ACTIVITY_RECOGNITION][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_ACTIVITY_RECOGNITION</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed, see table below <code>[ACTIVITY_CLASSES][STATIONARY]</code> An array of the activity labels to be considered in the <code>STATIONARY</code> category choose any of <code>still</code>, <code>tilting</code> <code>[ACTIVITY_CLASSES][MOBILE]</code> An array of the activity labels to be considered in the <code>MOBILE</code> category choose any of <code>on_foot</code>, <code>walking</code>, <code>running</code>, <code>on_bicycle</code> <code>[ACTIVITY_CLASSES][VEHICLE]</code> An array of the activity labels to be considered in the <code>VEHICLE</code> category choose any of <code>in_vehicule</code> <p>Features description for <code>[PHONE_ACTIVITY_RECOGNITION][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description count rows Number of episodes. mostcommonactivity activity type The most common activity type (e.g. <code>still</code>, <code>on_foot</code>, etc.). If there is a tie, the first one is chosen. countuniqueactivities activity type Number of unique activities. durationstationary minutes The total duration of <code>[ACTIVITY_CLASSES][STATIONARY]</code> episodes durationmobile minutes The total duration of <code>[ACTIVITY_CLASSES][MOBILE]</code> episodes of on foot, running, and on bicycle activities durationvehicle minutes The total duration of <code>[ACTIVITY_CLASSES][VEHICLE]</code> episodes of on vehicle activity <p>Assumptions/Observations</p> <ol> <li> <p>iOS Activity Recognition names and types are unified with Android labels: </p> iOS Activity Name Android Activity Name Android Activity Type <code>walking</code> <code>walking</code> <code>7</code> <code>running</code> <code>running</code> <code>8</code> <code>cycling</code> <code>on_bicycle</code> <code>1</code> <code>automotive</code> <code>in_vehicle</code> <code>0</code> <code>stationary</code> <code>still</code> <code>3</code> <code>unknown</code> <code>unknown</code> <code>4</code> </li> <li> <p>In AWARE, Activity Recognition data for Android and iOS are stored in two different database tables, RAPIDS automatically infers what platform each participant belongs to based on their participant file.</p> </li> </ol>"},{"location":"features/phone-applications-crashes/","title":"Phone Applications Crashes","text":"<p>Sensor parameters description for <code>[PHONE_APPLICATIONS_CRASHES]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the applications crashes data is stored <code>[APPLICATION_CATEGORIES][CATALOGUE_SOURCE]</code> <code>FILE</code> or <code>GOOGLE</code>. If <code>FILE</code>, app categories (genres) are read from <code>[CATALOGUE_FILE]</code>. If <code>[GOOGLE]</code>, app categories (genres) are scrapped from the Play Store <code>[APPLICATION_CATEGORIES][CATALOGUE_FILE]</code> CSV file with a <code>package_name</code> and <code>genre</code> column. By default we provide the catalogue created by Stachl et al in <code>data/external/stachl_application_genre_catalogue.csv</code> <code>[APPLICATION_CATEGORIES][UPDATE_CATALOGUE_FILE]</code> if <code>[CATALOGUE_SOURCE]</code> is equal to <code>FILE</code>, this flag signals whether or not to update <code>[CATALOGUE_FILE]</code>, if <code>[CATALOGUE_SOURCE]</code> is equal to <code>GOOGLE</code> all scraped genres will be saved to <code>[CATALOGUE_FILE]</code> <code>[APPLICATION_CATEGORIES][SCRAPE_MISSING_CATEGORIES]</code> This flag signals whether or not to scrape categories (genres) missing from the <code>[CATALOGUE_FILE]</code>. If <code>[CATALOGUE_SOURCE]</code> is equal to <code>GOOGLE</code>, all genres are scraped anyway (this flag is ignored) <p>Note</p> <p>No feature providers have been implemented for this sensor yet, however you can use its key (<code>PHONE_APPLICATIONS_CRASHES</code>) to improve <code>PHONE_DATA_YIELD</code> or you can implement your own features.</p>"},{"location":"features/phone-applications-foreground/","title":"Phone Applications Foreground","text":"<p>Sensor parameters description for <code>[PHONE_APPLICATIONS_FOREGROUND]</code> (these parameters are used by the only provider available at the moment, RAPIDS):</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the applications foreground data is stored <code>[APPLICATION_CATEGORIES][CATALOGUE_SOURCE]</code> <code>FILE</code> or <code>GOOGLE</code>. If <code>FILE</code>, app categories (genres) are read from <code>[CATALOGUE_FILE]</code>. If <code>[GOOGLE]</code>, app categories (genres) are scrapped from the Play Store <code>[APPLICATION_CATEGORIES][CATALOGUE_FILE]</code> CSV file with a <code>package_name</code> and <code>genre</code> column. By default we provide the catalogue created by Stachl et al in <code>data/external/stachl_application_genre_catalogue.csv</code> <code>[APPLICATION_CATEGORIES][UPDATE_CATALOGUE_FILE]</code> if <code>[CATALOGUE_SOURCE]</code> is equal to <code>FILE</code>, this flag signals whether or not to update <code>[CATALOGUE_FILE]</code>, if <code>[CATALOGUE_SOURCE]</code> is equal to <code>GOOGLE</code> all scraped genres will be saved to <code>[CATALOGUE_FILE]</code> <code>[APPLICATION_CATEGORIES][SCRAPE_MISSING_CATEGORIES]</code> This flag signals whether or not to scrape categories (genres) missing from the <code>[CATALOGUE_FILE]</code>. If <code>[CATALOGUE_SOURCE]</code> is equal to <code>GOOGLE</code>, all genres are scraped anyway (this flag is ignored)"},{"location":"features/phone-applications-foreground/#rapids-provider","title":"RAPIDS provider","text":"<p>The app category (genre) catalogue used in these features was originally created by Stachl et al.</p> <p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android only</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_applications_foreground_raw.csv\n- data/raw/{pid}/phone_applications_foreground_with_datetime.csv\n- data/raw/{pid}/phone_applications_foreground_with_datetime_with_categories.csv\n- data/interim/{pid}/phone_applications_foreground_features/phone_applications_foreground_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_applications_foreground.csv\n</code></pre> <p>Parameters description for <code>[PHONE_APPLICATIONS_FOREGROUND][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_APPLICATIONS_FOREGROUND</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed, see table below <code>[SINGLE_CATEGORIES]</code> An array of app categories to be included in the feature extraction computation. The special keyword <code>all</code> represents a category with all the apps from each participant. By default we use the category catalogue pointed by <code>[APPLICATION_CATEGORIES][CATALOGUE_FILE]</code> (see the Sensor parameters description table above) <code>[MULTIPLE_CATEGORIES]</code> An array of collections representing meta-categories (a group of categories). They key of each element is the name of the <code>meta-category</code> and the value is an array of member app categories. By default we use the category catalogue pointed by <code>[APPLICATION_CATEGORIES][CATALOGUE_FILE]</code> (see the Sensor parameters description table above) <code>[SINGLE_APPS]</code> An array of apps to be included in the feature extraction computation. Use their package name (e.g. <code>com.google.android.youtube</code>) or the reserved keyword <code>top1global</code> (the most used app by a participant over the whole monitoring study) <code>[EXCLUDED_CATEGORIES]</code> An array of app categories to be excluded from the feature extraction computation. By default we use the category catalogue pointed by <code>[APPLICATION_CATEGORIES][CATALOGUE_FILE]</code> (see the Sensor parameters description table above) <code>[EXCLUDED_APPS]</code> An array of apps to be excluded from the feature extraction computation. Use their package name, for example: <code>com.google.android.youtube</code> <p>Features description for <code>[PHONE_APPLICATIONS_FOREGROUND][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description count apps Number of times a single app or apps within a category were used (i.e. they were brought to the foreground either by tapping their icon or switching to it from another app) timeoffirstuse minutes The time in minutes between 12:00am (midnight) and the first use of a single app or apps within a category during a <code>time_segment</code> timeoflastuse minutes The time in minutes between 12:00am (midnight) and the last use of a single app or apps within a category during a <code>time_segment</code> frequencyentropy nats The entropy of the used apps within a category during a <code>time_segment</code> (each app is seen as a unique event, the more apps were used, the higher the entropy). This is especially relevant when computed over all apps. Entropy cannot be obtained for a single app <p>Assumptions/Observations</p> <p>Features can be computed by app, by apps grouped under a single category (genre) and by multiple categories grouped together (meta-categories). For example, we can get features for <code>Facebook</code> (single app), for <code>Social Network</code> apps (a category including Facebook and other social media apps) or for <code>Social</code> (a meta-category formed by <code>Social Network</code> and <code>Social Media Tools</code> categories).</p> <p>Apps installed by default like YouTube are considered systems apps on some phones. We do an exact match to exclude apps where \u201cgenre\u201d == <code>EXCLUDED_CATEGORIES</code> or \u201cpackage_name\u201d == <code>EXCLUDED_APPS</code>.</p> <p>We provide three ways of classifying and app within a category (genre): a) by automatically scraping its official category from the Google Play Store, b) by using the catalogue created by Stachl et al. which we provide in RAPIDS (<code>data/external/stachl_application_genre_catalogue.csv</code>), or c) by manually creating a personalized catalogue. You can choose a, b or c by modifying <code>[APPLICATION_GENRES]</code> keys and values (see the Sensor parameters description table above).</p>"},{"location":"features/phone-applications-notifications/","title":"Phone Applications Notifications","text":"<p>Sensor parameters description for <code>[PHONE_APPLICATIONS_NOTIFICATIONS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the applications notifications data is stored <code>[APPLICATION_CATEGORIES][CATALOGUE_SOURCE]</code> <code>FILE</code> or <code>GOOGLE</code>. If <code>FILE</code>, app categories (genres) are read from <code>[CATALOGUE_FILE]</code>. If <code>[GOOGLE]</code>, app categories (genres) are scrapped from the Play Store <code>[APPLICATION_CATEGORIES][CATALOGUE_FILE]</code> CSV file with a <code>package_name</code> and <code>genre</code> column. By default we provide the catalogue created by Stachl et al in <code>data/external/stachl_application_genre_catalogue.csv</code> <code>[APPLICATION_CATEGORIES][UPDATE_CATALOGUE_FILE]</code> if <code>[CATALOGUE_SOURCE]</code> is equal to <code>FILE</code>, this flag signals whether or not to update <code>[CATALOGUE_FILE]</code>, if <code>[CATALOGUE_SOURCE]</code> is equal to <code>GOOGLE</code> all scraped genres will be saved to <code>[CATALOGUE_FILE]</code> <code>[APPLICATION_CATEGORIES][SCRAPE_MISSING_CATEGORIES]</code> This flag signals whether or not to scrape categories (genres) missing from the <code>[CATALOGUE_FILE]</code>. If <code>[CATALOGUE_SOURCE]</code> is equal to <code>GOOGLE</code>, all genres are scraped anyway (this flag is ignored) <p>Note</p> <p>No feature providers have been implemented for this sensor yet, however you can use its key (<code>PHONE_APPLICATIONS_NOTIFICATIONS</code>) to improve <code>PHONE_DATA_YIELD</code> or you can implement your own features.</p>"},{"location":"features/phone-battery/","title":"Phone Battery","text":"<p>Sensor parameters description for <code>[PHONE_BATTERY]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the battery data is stored <code>[EPISODE_THRESHOLD_BETWEEN_ROWS]</code> Difference in minutes between any two rows for them to be considered part of the same battery charge or discharge episode"},{"location":"features/phone-battery/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android and iOS</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_battery_raw.csv\n- data/interim/{pid}/phone_battery_episodes.csv\n- data/interim/{pid}/phone_battery_episodes_resampled.csv\n- data/interim/{pid}/phone_battery_episodes_resampled_with_datetime.csv\n- data/interim/{pid}/phone_battery_features/phone_battery_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_battery.csv\n</code></pre> <p>Parameters description for <code>[PHONE_BATTERY][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_BATTERY</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed, see table below <p>Features description for <code>[PHONE_BATTERY][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description countdischarge episodes Number of discharging episodes. sumdurationdischarge minutes The total duration of all discharging episodes. countcharge episodes Number of battery charging episodes. sumdurationcharge minutes The total duration of all charging episodes. avgconsumptionrate episodes/minutes The average of all episodes\u2019 consumption rates. An episode\u2019s consumption rate is defined as the ratio between its battery delta and duration maxconsumptionrate episodes/minutes The highest of all episodes\u2019 consumption rates. An episode\u2019s consumption rate is defined as the ratio between its battery delta and duration <p>Assumptions/Observations</p> <ol> <li>We convert battery data collected with iOS client v1 (autodetected because battery status <code>4</code> do not exist) to match Android battery format: we swap status <code>3</code> for <code>5</code> and <code>1</code> for <code>3</code></li> <li>We group battery data into discharge or charge episodes considering any contiguous rows with consecutive reductions or increases of the battery level if they are logged within <code>[EPISODE_THRESHOLD_BETWEEN_ROWS]</code> minutes from each other.</li> </ol>"},{"location":"features/phone-bluetooth/","title":"Phone Bluetooth","text":"<p>Sensor parameters description for <code>[PHONE_BLUETOOTH]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the bluetooth data is stored"},{"location":"features/phone-bluetooth/#rapids-provider","title":"RAPIDS provider","text":"<p>Warning</p> <p>The features of this provider are deprecated in favor of <code>DORYAB</code> provider (see below).</p> <p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android only</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_bluetooth_raw.csv\n- data/raw/{pid}/phone_bluetooth_with_datetime.csv\n- data/interim/{pid}/phone_bluetooth_features/phone_bluetooth_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_bluetooth.csv\"\n</code></pre> <p>Parameters description for <code>[PHONE_BLUETOOTH][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_BLUETOOTH</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed, see table below <p>Features description for <code>[PHONE_BLUETOOTH][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description countscans devices Number of scanned devices during a time segment, a device can be detected multiple times over time and these appearances are counted separately uniquedevices devices Number of unique devices during a time segment as identified by their hardware (<code>bt_address</code>) address countscansmostuniquedevice scans Number of scans of the most sensed device within each time segment instance <p>Assumptions/Observations</p> <ul> <li>From <code>v0.2.0</code> <code>countscans</code>, <code>uniquedevices</code>, <code>countscansmostuniquedevice</code> were deprecated because they overlap with the respective features for <code>ALL</code> devices of the <code>PHONE_BLUETOOTH</code> <code>DORYAB</code> provider</li> </ul>"},{"location":"features/phone-bluetooth/#doryab-provider","title":"DORYAB provider","text":"<p>This provider is adapted from the work by Doryab et al. </p> <p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android only</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_bluetooth_raw.csv\n- data/raw/{pid}/phone_bluetooth_with_datetime.csv\n- data/interim/{pid}/phone_bluetooth_features/phone_bluetooth_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_bluetooth.csv\"\n</code></pre> <p>Parameters description for <code>[PHONE_BLUETOOTH][PROVIDERS][DORYAB]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_BLUETOOTH</code> features from the <code>DORYAB</code> provider <code>[FEATURES]</code> Features to be computed, see table below. These features are computed for three device categories: <code>all</code> devices, <code>own</code> devices and <code>other</code> devices. <p>Features description for <code>[PHONE_BLUETOOTH][PROVIDERS][DORYAB]</code>:</p> Feature\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Units Description countscans scans Number of scans (rows) from the devices sensed during a time segment instance. The more scans a bluetooth device has the longer it remained within range of the participant\u2019s phone uniquedevices devices Number of unique bluetooth devices sensed during a time segment instance as identified by their hardware addresses (<code>bt_address</code>) meanscans scans Mean of the scans of every sensed device within each time segment instance stdscans scans Standard deviation of the scans of every sensed device within each time segment instance countscansmostfrequentdevicewithinsegments scans Number of scans of the most sensed device within each time segment instance countscansleastfrequentdevicewithinsegments scans Number of scans of the least sensed device within each time segment instance countscansmostfrequentdeviceacrosssegments scans Number of scans of the most sensed device across time segment instances of the same type countscansleastfrequentdeviceacrosssegments scans Number of scans of the least sensed device across time segment instances of the same type per device countscansmostfrequentdeviceacrossdataset scans Number of scans of the most sensed device across the entire dataset of every participant countscansleastfrequentdeviceacrossdataset scans Number of scans of the least sensed device across the entire dataset of every participant <p>Assumptions/Observations</p> <ul> <li>Devices are classified as belonging to the participant (<code>own</code>) or to other people (<code>others</code>) using k-means based on the number of times and the number of days each device was detected across each participant\u2019s dataset. See Doryab et al for more details.</li> <li>If ownership cannot be computed because all devices were detected on only one day, they are all considered as <code>other</code>. Thus <code>all</code> and <code>other</code> features will be equal. The likelihood of this scenario decreases the more days of data you have.</li> <li>The most and least frequent devices will be the same across time segment instances and across the entire dataset when every time segment instance covers every hour of a dataset. For example, daily segments (00:00 to 23:59) fall in this category but morning segments (06:00am to 11:59am) or periodic 30-minute segments don\u2019t.</li> </ul> Example Simplified raw bluetooth data <p>The following is a simplified example with bluetooth data from three days and two time segments: morning and afternoon. There are two <code>own</code> devices: <code>5C836F5-487E-405F-8E28-21DBD40FA4FF</code> detected seven times across two days and <code>499A1EAF-DDF1-4657-986C-EA5032104448</code> detected eight times on a single day. <pre><code>local_date  segment     bt_address                              own_device\n2016-11-29  morning     55C836F5-487E-405F-8E28-21DBD40FA4FF              1\n2016-11-29  morning     55C836F5-487E-405F-8E28-21DBD40FA4FF              1\n2016-11-29  morning     55C836F5-487E-405F-8E28-21DBD40FA4FF              1\n2016-11-29  morning     55C836F5-487E-405F-8E28-21DBD40FA4FF              1\n2016-11-29  morning     48872A52-68DE-420D-98DA-73339A1C4685              0\n2016-11-29  afternoon   55C836F5-487E-405F-8E28-21DBD40FA4FF              1\n2016-11-29  afternoon   48872A52-68DE-420D-98DA-73339A1C4685              0\n2016-11-30  morning     55C836F5-487E-405F-8E28-21DBD40FA4FF              1\n2016-11-30  morning     48872A52-68DE-420D-98DA-73339A1C4685              0\n2016-11-30  morning     25262DC7-780C-4AD5-AD3A-D9776AEF7FC1              0\n2016-11-30  morning     5B1E6981-2E50-4D9A-99D8-67AED430C5A8              0\n2016-11-30  morning     5B1E6981-2E50-4D9A-99D8-67AED430C5A8              0\n2016-11-30  afternoon   55C836F5-487E-405F-8E28-21DBD40FA4FF              1\n2017-05-07  morning     5C5A9C41-2F68-4CEB-96D0-77DE3729B729              0\n2017-05-07  morning     25262DC7-780C-4AD5-AD3A-D9776AEF7FC1              0\n2017-05-07  morning     5B1E6981-2E50-4D9A-99D8-67AED430C5A8              0\n2017-05-07  morning     6C444841-FE64-4375-BC3F-FA410CDC0AC7              0\n2017-05-07  morning     4DC7A22D-9F1F-4DEF-8576-086910AABCB5              0\n2017-05-07  afternoon   5B1E6981-2E50-4D9A-99D8-67AED430C5A8              0\n2017-05-07  afternoon   499A1EAF-DDF1-4657-986C-EA5032104448              1\n2017-05-07  afternoon   499A1EAF-DDF1-4657-986C-EA5032104448              1\n2017-05-07  afternoon   499A1EAF-DDF1-4657-986C-EA5032104448              1\n2017-05-07  afternoon   499A1EAF-DDF1-4657-986C-EA5032104448              1\n2017-05-07  afternoon   499A1EAF-DDF1-4657-986C-EA5032104448              1\n2017-05-07  afternoon   499A1EAF-DDF1-4657-986C-EA5032104448              1\n2017-05-07  afternoon   499A1EAF-DDF1-4657-986C-EA5032104448              1\n2017-05-07  afternoon   499A1EAF-DDF1-4657-986C-EA5032104448              1\n</code></pre></p> The most and least frequent <code>OTHER</code> devices (<code>own_device == 0</code>) during morning segments <p>The most and least frequent <code>ALL</code>|<code>OWN</code>|<code>OTHER</code> devices are computed within each time segment instance, across time segment instances of the same type and across the entire dataset of each person. These are the most and least frequent devices for <code>OTHER</code> devices during morning segments. <pre><code>most frequent device across 2016-11-29 morning:   '48872A52-68DE-420D-98DA-73339A1C4685'  (this device is the only one in this instance)\nleast frequent device across 2016-11-29 morning:  '48872A52-68DE-420D-98DA-73339A1C4685'  (this device is the only one in this instance)\nmost frequent device across 2016-11-30 morning:   '5B1E6981-2E50-4D9A-99D8-67AED430C5A8'\nleast frequent device across 2016-11-30 morning:  '25262DC7-780C-4AD5-AD3A-D9776AEF7FC1'  (when tied, the first occurance is chosen)\nmost frequent device across 2017-05-07 morning:   '25262DC7-780C-4AD5-AD3A-D9776AEF7FC1'  (when tied, the first occurance is chosen)\nleast frequent device across 2017-05-07 morning:  '25262DC7-780C-4AD5-AD3A-D9776AEF7FC1'  (when tied, the first occurance is chosen)\n\nmost frequent across morning segments:            '5B1E6981-2E50-4D9A-99D8-67AED430C5A8'\nleast frequent across morning segments:           '6C444841-FE64-4375-BC3F-FA410CDC0AC7' (when tied, the first occurance is chosen)\n\nmost frequent across dataset:                     '499A1EAF-DDF1-4657-986C-EA5032104448' (only taking into account \"morning\" segments)\nleast frequent across dataset:                    '4DC7A22D-9F1F-4DEF-8576-086910AABCB5' (when tied, the first occurance is chosen)\n</code></pre></p> Bluetooth features for  <code>OTHER</code> devices and morning segments <p>For brevity we only show the following features for morning segments: <pre><code>OTHER: \n    DEVICES: [\"countscans\", \"uniquedevices\", \"meanscans\", \"stdscans\"]\n    SCANS_MOST_FREQUENT_DEVICE: [\"withinsegments\", \"acrosssegments\", \"acrossdataset\"]\n</code></pre></p> <p>Note that <code>countscansmostfrequentdeviceacrossdatasetothers</code> is all <code>0</code>s because <code>499A1EAF-DDF1-4657-986C-EA5032104448</code> is excluded from the count as is labelled as an <code>own</code> device (not <code>other</code>). <pre><code>local_segment       countscansothers    uniquedevicesothers meanscansothers stdscansothers  countscansmostfrequentdevicewithinsegmentsothers    countscansmostfrequentdeviceacrosssegmentsothers    countscansmostfrequentdeviceacrossdatasetothers\n2016-11-29-morning  1                   1                   1.000000        NaN             1                                                   0.0                                                 0.0\n2016-11-30-morning  4                   3                   1.333333        0.57735         2                                                   2.0                                                 2.0\n2017-05-07-morning  5                   5                   1.000000        0.00000         1                                                   1.0                                                 1.0\n</code></pre></p>"},{"location":"features/phone-calls/","title":"Phone Calls","text":"<p>Sensor parameters description for <code>[PHONE_CALLS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the calls data is stored"},{"location":"features/phone-calls/#rapids-provider","title":"RAPIDS Provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android and iOS</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_calls_raw.csv\n- data/raw/{pid}/phone_calls_with_datetime.csv\n- data/interim/{pid}/phone_calls_features/phone_calls_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_calls.csv\n</code></pre> <p>Parameters description for <code>[PHONE_CALLS][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_CALLS</code> features from the <code>RAPIDS</code> provider <code>[CALL_TYPES]</code> The particular call_type that will be analyzed. The options for this parameter are incoming, outgoing or missed. <code>[FEATURES]</code> Features to be computed for <code>outgoing</code>, <code>incoming</code>, and <code>missed</code> calls. Note that the same features are available for both incoming and outgoing calls, while missed calls has its own set of features. See the tables below. <p>Features description for <code>[PHONE_CALLS][PROVIDERS][RAPIDS]</code> incoming and outgoing calls:</p> Feature Units Description count calls Number of calls of a particular <code>call_type</code> occurred during a particular <code>time_segment</code>. distinctcontacts contacts Number of distinct contacts that are associated with a particular <code>call_type</code> for a particular <code>time_segment</code> meanduration seconds The mean duration of all calls of a particular <code>call_type</code> during a particular <code>time_segment</code>. sumduration seconds The sum of the duration of all calls of a particular <code>call_type</code> during a particular <code>time_segment</code>. minduration seconds The duration of the shortest call of a particular <code>call_type</code> during a particular <code>time_segment</code>. maxduration seconds The duration of the longest call of a particular <code>call_type</code> during a particular <code>time_segment</code>. stdduration seconds The standard deviation of the duration of all the calls of a particular <code>call_type</code> during a particular <code>time_segment</code>. modeduration seconds The mode of the duration of all the calls of a particular <code>call_type</code> during a particular <code>time_segment</code>. entropyduration nats The estimate of the Shannon entropy for the the duration of all the calls of a particular <code>call_type</code> during a particular <code>time_segment</code>. timefirstcall minutes The time in minutes between 12:00am (midnight) and the first call of <code>call_type</code>. timelastcall minutes The time in minutes between 12:00am (midnight) and the last call of <code>call_type</code>. countmostfrequentcontact calls The number of calls of a particular <code>call_type</code> during a particular <code>time_segment</code> of the most frequent contact throughout the monitored period. <p>Features description for <code>[PHONE_CALLS][PROVIDERS][RAPIDS]</code> missed calls:</p> Feature Units Description count calls Number of <code>missed</code> calls that occurred during a particular <code>time_segment</code>. distinctcontacts contacts Number of distinct contacts that are associated with <code>missed</code> calls for a particular <code>time_segment</code> timefirstcall minutes The time in hours from 12:00am (Midnight) that the first <code>missed</code> call occurred. timelastcall minutes The time in hours from 12:00am (Midnight) that the last <code>missed</code> call occurred. countmostfrequentcontact calls The number of <code>missed</code> calls during a particular <code>time_segment</code> of the most frequent contact throughout the monitored period. <p>Assumptions/Observations</p> <ol> <li>Traces for iOS calls are unique even for the same contact calling a participant more than once which renders <code>countmostfrequentcontact</code> meaningless and <code>distinctcontacts</code> equal to the total number of traces. </li> <li><code>[CALL_TYPES]</code> and <code>[FEATURES]</code> keys in <code>config.yaml</code> need to match. For example, <code>[CALL_TYPES]</code> <code>outgoing</code> matches the <code>[FEATURES]</code> key <code>outgoing</code></li> <li>iOS calls data is transformed to match Android calls data format. See our algorithm</li> </ol>"},{"location":"features/phone-conversation/","title":"Phone Conversation","text":"<p>Sensor parameters description for <code>[PHONE_CONVERSATION]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER][ANDROID]</code> Data stream container (database table, CSV file, etc.) where the conversation data from Android devices is stored (the AWARE client saves this data on different tables for Android and iOS) <code>[CONTAINER][IOS]</code> Data stream container (database table, CSV file, etc.) where the conversation data from iOS devices is stored (the AWARE client saves this data on different tables for Android and iOS)"},{"location":"features/phone-conversation/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android only</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_conversation_raw.csv\n- data/raw/{pid}/phone_conversation_with_datetime.csv\n- data/interim/{pid}/phone_conversation_features/phone_conversation_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_conversation.csv\n</code></pre> <p>Parameters description for <code>[PHONE_CONVERSATION][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_CONVERSATION</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed, see table below <code>[RECORDING_MINUTES]</code> Minutes the plugin was recording audio (default 1 min) <code>[PAUSED_MINUTES]</code> Minutes the plugin was NOT recording audio (default 3 min) <p>Features description for <code>[PHONE_CONVERSATION][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description minutessilence minutes Minutes labeled as silence minutesnoise minutes Minutes labeled as noise minutesvoice minutes Minutes labeled as voice minutesunknown minutes Minutes labeled as unknown sumconversationduration minutes Total duration of all conversations maxconversationduration minutes Longest duration of all conversations minconversationduration minutes Shortest duration of all conversations avgconversationduration minutes Average duration of all conversations sdconversationduration minutes Standard Deviation of the duration of all conversations timefirstconversation minutes Minutes since midnight when the first conversation for a time segment was detected timelastconversation minutes Minutes since midnight when the last conversation for a time segment was detected noisesumenergy L2-norm Sum of all energy values when inference is noise noiseavgenergy L2-norm Average of all energy values when inference is noise noisesdenergy L2-norm Standard Deviation of all energy values when inference is noise noiseminenergy L2-norm Minimum of all energy values when inference is noise noisemaxenergy L2-norm Maximum of all energy values when inference is noise voicesumenergy L2-norm Sum of all energy values when inference is voice voiceavgenergy L2-norm Average of all energy values when inference is voice voicesdenergy L2-norm Standard Deviation of all energy values when inference is voice voiceminenergy L2-norm Minimum of all energy values when inference is voice voicemaxenergy L2-norm Maximum of all energy values when inference is voice silencesensedfraction - Ratio between minutessilence and the sum of (minutessilence, minutesnoise, minutesvoice, minutesunknown) noisesensedfraction - Ratio between minutesnoise and the sum of (minutessilence, minutesnoise, minutesvoice, minutesunknown) voicesensedfraction - Ratio between minutesvoice and the sum of (minutessilence, minutesnoise, minutesvoice, minutesunknown) unknownsensedfraction - Ratio between minutesunknown and the sum of (minutessilence, minutesnoise, minutesvoice, minutesunknown) silenceexpectedfraction - Ration between minutessilence and the number of minutes that in  theory should have been sensed based on the record and pause cycle of  the plugin (1440 / recordingMinutes+pausedMinutes) noiseexpectedfraction - Ration between minutesnoise and the number of minutes that in theory  should have been sensed based on the record and pause cycle of the  plugin (1440 / recordingMinutes+pausedMinutes) voiceexpectedfraction - Ration between minutesvoice and the number of minutes that in theory  should have been sensed based on the record and pause cycle of the  plugin (1440 / recordingMinutes+pausedMinutes) unknownexpectedfraction - Ration between minutesunknown and the number of minutes that in  theory should have been sensed based on the record and pause cycle of  the plugin (1440 / recordingMinutes+pausedMinutes) <p>Assumptions/Observations</p> <ol> <li>The timestamp of conversation rows in iOS is in seconds so we convert it to milliseconds to match Android\u2019s format</li> </ol>"},{"location":"features/phone-data-yield/","title":"Phone Data Yield","text":"<p>This is a combinatorial sensor which means that we use the data from multiple sensors to extract data yield features. Data yield features can be used to remove rows (time segments) that do not contain enough data. You should decide what is your \u201cenough\u201d threshold depending on the type of sensors you collected (frequency vs event based, e.g. acceleroemter vs calls), the length of your study, and the rates of missing data that your analysis could handle.</p> <p>Why is data yield important?</p> <p>Imagine that you want to extract <code>PHONE_CALL</code> features on daily segments (<code>00:00</code> to <code>23:59</code>). Let\u2019s say that on day 1 the phone logged 10 calls and 23 hours of data from other sensors and on day 2 the phone logged 10 calls and only 2 hours of data from other sensors. It\u2019s more likely that other calls were placed on the 22 hours of data that you didn\u2019t log on day 2 than on the 1 hour of data you didn\u2019t log on day 1, and so including day 2 in your analysis could bias your results.</p> <p>Sensor parameters description for <code>[PHONE_DATA_YIELD]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[SENSORS]</code> One or more phone sensor config keys (e.g. <code>PHONE_MESSAGE</code>). The more keys you include the more accurately RAPIDS can approximate the time an smartphone was sensing data. The supported phone sensors you can include in this list are outlined below (do NOT include Fitbit sensors, ONLY include phone sensors). <p>Supported phone sensors for <code>[PHONE_DATA_YIELD][SENSORS]</code></p> <pre><code>PHONE_ACCELEROMETER\nPHONE_ACTIVITY_RECOGNITION\nPHONE_APPLICATIONS_CRASHES\nPHONE_APPLICATIONS_FOREGROUND\nPHONE_APPLICATIONS_NOTIFICATIONS\nPHONE_BATTERY\nPHONE_BLUETOOTH\nPHONE_CALLS\nPHONE_CONVERSATION\nPHONE_KEYBOARD\nPHONE_LIGHT\nPHONE_LOCATIONS\nPHONE_LOG\nPHONE_MESSAGES\nPHONE_SCREEN\nPHONE_WIFI_CONNECTED\nPHONE_WIFI_VISIBLE\n</code></pre>"},{"location":"features/phone-data-yield/#rapids-provider","title":"RAPIDS provider","text":"<p>Before explaining the data yield features, let\u2019s define the following relevant concepts:</p> <ul> <li>A valid minute is any 60 second window when any phone sensor logged at least 1 row of data</li> <li>A valid hour is any 60 minute window with at least X valid minutes. The X or threshold is given by <code>[MINUTE_RATIO_THRESHOLD_FOR_VALID_YIELDED_HOURS]</code></li> </ul> <p>The timestamps of all sensors are concatenated and then grouped per time segment. Minute and hour windows are created from the beginning of each time segment instance and these windows are marked as valid based on the definitions above. The duration of each time segment is taken into account to compute the features described below.</p> <p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android and iOS</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/{sensor}_raw.csv # one for every [PHONE_DATA_YIELD][SENSORS]\n- data/interim/{pid}/phone_yielded_timestamps.csv\n- data/interim/{pid}/phone_yielded_timestamps_with_datetime.csv\n- data/interim/{pid}/phone_data_yield_features/phone_data_yield_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_data_yield.csv\n</code></pre> <p>Parameters description for <code>[PHONE_DATA_YIELD][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_DATA_YIELD</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed, see table below <code>[MINUTE_RATIO_THRESHOLD_FOR_VALID_YIELDED_HOURS]</code> The proportion <code>[0.0 ,1.0]</code> of valid minutes in a 60-minute window necessary to flag that window as valid. <p>Features description for <code>[PHONE_DATA_YIELD][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description ratiovalidyieldedminutes - The ratio between the number of valid minutes and the duration in minutes of a time segment. ratiovalidyieldedhours - The ratio between the number of valid hours and the duration in hours of a time segment. If the time segment is shorter than 1 hour this feature will always be 1. <p>Assumptions/Observations</p> <ol> <li> <p>We recommend using <code>ratiovalidyieldedminutes</code> on time segments that are shorter than two or three hours and <code>ratiovalidyieldedhours</code> for longer segments. This is because relying on yielded minutes only can be misleading when a big chunk of those missing minutes are clustered together. </p> <p>For example, let\u2019s assume we are working with a 24-hour time segment that is missing 12 hours of data. Two extreme cases can occur: </p> <p><ol> <li>the 12 missing hours are from the beginning of the segment or </li> <li>30 minutes could be missing from every hour (24 * 30 minutes = 12 hours).</li> </ol></p> <p><code>ratiovalidyieldedminutes</code> would be 0.5 for both <code>a</code> and <code>b</code> (hinting the missing circumstances are similar). However, <code>ratiovalidyieldedhours</code> would be 0.5 for <code>a</code> and 1.0 for <code>b</code> if <code>[MINUTE_RATIO_THRESHOLD_FOR_VALID_YIELDED_HOURS]</code> is between [0.0 and 0.49] (hinting that the missing circumstances might be more favorable for <code>b</code>. In other words, sensed data for <code>b</code> is more evenly spread compared to <code>a</code>.</p> </li> </ol>"},{"location":"features/phone-keyboard/","title":"Phone Keyboard","text":"<p>Sensor parameters description for <code>[PHONE_KEYBOARD]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the keyboard data is stored <p>Note</p> <p>No feature providers have been implemented for this sensor yet, however you can use its key (<code>PHONE_KEYBOARD</code>) to improve <code>PHONE_DATA_YIELD</code> or you can implement your own features.</p>"},{"location":"features/phone-light/","title":"Phone Light","text":"<p>Sensor parameters description for <code>[PHONE_LIGHT]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the light data is stored"},{"location":"features/phone-light/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android only</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_light_raw.csv\n- data/raw/{pid}/phone_light_with_datetime.csv\n- data/interim/{pid}/phone_light_features/phone_light_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_light.csv\n</code></pre> <p>Parameters description for <code>[PHONE_LIGHT][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_LIGHT</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed, see table below <p>Features description for <code>[PHONE_LIGHT][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description count rows Number light sensor rows recorded. maxlux lux The maximum ambient luminance. minlux lux The minimum ambient luminance. avglux lux The average ambient luminance. medianlux lux The median ambient luminance. stdlux lux The standard deviation of ambient luminance. <p>Assumptions/Observations</p> <p>NA</p>"},{"location":"features/phone-locations/","title":"Phone Locations","text":"<p>Sensor parameters description for <code>[PHONE_LOCATIONS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the location data is stored <code>[LOCATIONS_TO_USE]</code> Type of location data to use, one of <code>ALL</code>, <code>GPS</code>, <code>ALL_RESAMPLED</code> or <code>FUSED_RESAMPLED</code>. This filter is based on the <code>provider</code> column of the locations table, <code>ALL</code> includes every row, <code>GPS</code> only includes rows where the provider is gps, <code>ALL_RESAMPLED</code> includes all rows after being resampled, and <code>FUSED_RESAMPLED</code> only includes rows where the provider is fused after being resampled. <code>[FUSED_RESAMPLED_CONSECUTIVE_THRESHOLD]</code> if <code>ALL_RESAMPLED</code> or <code>FUSED_RESAMPLED</code> is used, the original fused data has to be resampled, a location row is resampled to the next valid timestamp (see the Assumptions/Observations below) only if the time difference between them is less or equal than this threshold (in minutes). <code>[FUSED_RESAMPLED_TIME_SINCE_VALID_LOCATION]</code> if <code>ALL_RESAMPLED</code> or <code>FUSED_RESAMPLED</code> is used, the original fused data has to be resampled, a location row is resampled at most for this long (in minutes) <p>Assumptions/Observations</p> <p>Types of location data to use Android and iOS clients can collect location coordinates through the phone\u2019s GPS, the network cellular towers around the phone, or Google\u2019s fused location API. </p> <ul> <li>If you want to use only the GPS provider, set <code>[LOCATIONS_TO_USE]</code> to <code>GPS</code></li> <li>If you want to use all providers, set <code>[LOCATIONS_TO_USE]</code> to <code>ALL</code></li> <li>If you collected location data from different providers, including the fused API, use <code>ALL_RESAMPLED</code></li> <li>If your mobile client was configured to use fused location only or want to focus only on this provider, set <code>[LOCATIONS_TO_USE]</code> to <code>RESAMPLE_FUSED</code>.</li> </ul> <p><code>ALL_RESAMPLED</code> and <code>RESAMPLE_FUSED</code> take the original location coordinates and replicate each pair forward in time as long as the phone was sensing data as indicated by the joined timestamps of <code>[PHONE_DATA_YIELD][SENSORS]</code>. This is done because Google\u2019s API only logs a new location coordinate pair when it is sufficiently different in time or space from the previous one and because GPS and network providers can log data at variable rates.</p> <p>There are two parameters associated with resampling fused location.</p> <ol> <li><code>FUSED_RESAMPLED_CONSECUTIVE_THRESHOLD</code> (in minutes, default 30) controls the maximum gap between any two coordinate pairs to replicate the last known pair. For example, participant A\u2019s phone did not collect data between 10.30 am and 10:50 am and between 11:05am and 11:40am, the last known coordinate pair is replicated during the first period but not the second. In other words, we assume that we cannot longer guarantee the participant stayed at the last known location if the phone did not sense data for more than 30 minutes. </li> <li><code>FUSED_RESAMPLED_TIME_SINCE_VALID_LOCATION</code> (in minutes, default 720 or 12 hours) stops the last known fused location from being replicated longer than this threshold even if the phone was sensing data continuously. For example, participant A went home at 9 pm, and their phone was sensing data without gaps until 11 am the next morning, the last known location is replicated until 9 am. </li> </ol> <p>If you have suggestions to modify or improve this resampling, let us know.</p>"},{"location":"features/phone-locations/#barnett-provider","title":"BARNETT provider","text":"<p>These features are based on the original open-source implementation by Barnett et al and some features created by Canzian et al.</p> <p>Available time segments and platforms</p> <ul> <li>Available only for segments that start at 00:00:00 and end at 23:59:59 of the same or a different day (daily, weekly, weekend, etc.)</li> <li>Available for Android and iOS</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_locations_raw.csv\n- data/interim/{pid}/phone_locations_processed.csv\n- data/interim/{pid}/phone_locations_processed_with_datetime.csv\n- data/interim/{pid}/phone_locations_features/phone_locations_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_locations.csv\n</code></pre> <p>Parameters description for <code>[PHONE_LOCATIONS][PROVIDERS][BARNETT]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_LOCATIONS</code> features from the <code>BARNETT</code> provider <code>[FEATURES]</code> Features to be computed, see table below <code>[ACCURACY_LIMIT]</code> An integer in meters, any location rows with an accuracy higher than this is dropped. This number means there\u2019s a 68% probability the actual location is within this radius <code>[IF_MULTIPLE_TIMEZONES]</code> Currently, <code>USE_MOST_COMMON</code> is the only value supported. If the location data for a participant belongs to multiple time zones, we select the most common because Barnett\u2019s algorithm can only handle one time zone <code>[MINUTES_DATA_USED]</code> Set to <code>True</code> to include an extra column in the final location feature file containing the number of minutes used to compute the features on each time segment. Use this for quality control purposes; the more data minutes exist for a period, the more reliable its features should be. For fused location, a single minute can contain more than one coordinate pair if the participant is moving fast enough. <p>Features description for <code>[PHONE_LOCATIONS][PROVIDERS][BARNETT]</code> adapted from Beiwe Summary Statistics:</p> Feature Units Description hometime minutes Time at home. Time spent at home in minutes. Home is the most visited significant location between 8 pm and 8 am, including any pauses within a 200-meter radius. disttravelled meters Total distance traveled over a day (flights). rog meters The Radius of Gyration (rog) is a measure in meters of the area covered by a person over a day. A centroid is calculated for all the places (pauses) visited during a day, and a weighted distance between all the places and that centroid is computed. The weights are proportional to the time spent in each place. maxdiam meters The maximum diameter is the largest distance between any two pauses. maxhomedist meters The maximum distance from home in meters. siglocsvisited locations The number of significant locations visited during the day. Significant locations are computed using k-means clustering over pauses found in the whole monitoring period. The number of clusters is found iterating k from 1 to 200 stopping until the centroids of two significant locations are within 400 meters of one another. avgflightlen meters Mean length of all flights. stdflightlen meters Standard deviation of the length of all flights. avgflightdur seconds Mean duration of all flights. stdflightdur seconds The standard deviation of the duration of all flights. probpause - The fraction of a day spent in a pause (as opposed to a flight) siglocentropy nats Shannon\u2019s entropy measurement is based on the proportion of time spent at each significant location visited during a day. circdnrtn - A continuous metric quantifying a person\u2019s circadian routine that can take any value between 0 and 1, where 0 represents a daily routine completely different from any other sensed days and 1 a routine the same as every other sensed day. wkenddayrtn - Same as circdnrtn but computed separately for weekends and weekdays. <p>Assumptions/Observations</p> <p>Multi day segment features Barnett\u2019s features are only available on time segments that span entire days (00:00:00 to 23:59:59). Such segments can be one-day long (daily) or multi-day (weekly, for example). Multi-day segment features are computed based on daily features summarized the following way:</p> <ul> <li>sum for <code>hometime</code>, <code>disttravelled</code>, <code>siglocsvisited</code>, and <code>minutes_data_used</code></li> <li>max for <code>maxdiam</code>, and <code>maxhomedist</code></li> <li>mean for <code>rog</code>, <code>avgflightlen</code>, <code>stdflightlen</code>, <code>avgflightdur</code>, <code>stdflightdur</code>, <code>probpause</code>, <code>siglocentropy</code>, <code>circdnrtn</code>, <code>wkenddayrtn</code>, and <code>minsmissing</code></li> </ul> <p>Computation speed The process to extract these features can be slow compared to other sensors and providers due to the required simulation.</p> <p>How are these features computed? These features are based on a Pause-Flight model. A pause is defined as a mobility trace (location pings) within a certain duration and distance (by default, 300 seconds and 60 meters). A flight is any mobility trace between two pauses. Data is resampled and imputed before the features are computed. See Barnett et al for more information. In RAPIDS, we only expose one parameter for these features (accuracy limit). You can change other parameters in <code>src/features/phone_locations/barnett/library/MobilityFeatures.R</code>.</p> <p>Significant Locations Significant locations are determined using K-means clustering on pauses longer than 10 minutes. The number of clusters (K) is increased until no two clusters are within 400 meters from each other. After this, pauses within a certain range of a cluster (200 meters by default) count as a visit to that significant location. This description was adapted from the Supplementary Materials of Barnett et al.</p> <p>The Circadian Calculation For a detailed description of how this is calculated, see Canzian et al.</p>"},{"location":"features/phone-locations/#doryab-provider","title":"DORYAB provider","text":"<p>These features are based on the original implementation by Doryab et al..</p> <p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android and iOS</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_locations_raw.csv\n- data/interim/{pid}/phone_locations_processed.csv\n- data/interim/{pid}/phone_locations_processed_with_datetime.csv\n- data/interim/{pid}/phone_locations_processed_with_datetime_with_home.csv\n- data/interim/{pid}/phone_locations_features/phone_locations_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_locations.csv\n</code></pre> <p>Parameters description for <code>[PHONE_LOCATIONS][PROVIDERS][DORYAB]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_LOCATIONS</code> features from the <code>BARNETT</code> provider <code>[FEATURES]</code> Features to be computed, see table below <code>[ACCURACY_LIMIT]</code> An integer in meters, any location rows with an accuracy higher than this will be dropped. This number means there\u2019s a 68% probability the true location is within this radius <code>[DBSCAN_EPS]</code> The maximum distance in meters between two samples for one to be considered as in the neighborhood of the other. This is not a maximum bound on the distances of points within a cluster. This is the most important DBSCAN parameter to choose appropriately for your data set and distance function. <code>[DBSCAN_MINSAMPLES]</code> The number of samples (or total weight) in a neighborhood for a point to be considered as a core point of a cluster. This includes the point itself. <code>[THRESHOLD_STATIC]</code> It is the threshold value in km/hr which labels a row as Static or Moving. <code>[MAXIMUM_ROW_GAP]</code> The maximum gap (in seconds) allowed between any two consecutive rows for them to be considered part of the same displacement. If this threshold is too high, it can throw speed and distance calculations off for periods when the phone was not sensing. <code>[MAXIMUM_ROW_DURATION]</code> The time difference between any two consecutive rows <code>A</code> and <code>B</code> is considered as the time a participant spent in <code>A</code>. If this difference is bigger than MAXIMUM_ROW_GAP we substitute it with <code>MAXIMUM_ROW_DURATION</code>. <code>[MINUTES_DATA_USED]</code> Set to <code>True</code> to include an extra column in the final location feature file containing the number of minutes used to compute the features on each time segment. Use this for quality control purposes; the more data minutes exist for a period, the more reliable its features should be. For fused location, a single minute can contain more than one coordinate pair if the participant is moving fast enough. <code>[SAMPLING_FREQUENCY]</code> Expected time difference between any two location rows in minutes. If set to <code>0</code>, the sampling frequency will be inferred automatically as the median of all the differences between two consecutive row timestamps (recommended if you are using <code>FUSED_RESAMPLED</code> data). This parameter impacts all the time calculations. <code>[CLUSTER_ON]</code> Set this flag to <code>PARTICIPANT_DATASET</code> to create clusters based on the entire participant\u2019s dataset or to <code>TIME_SEGMENT</code> to create clusters based on all the instances of the corresponding time segment (e.g. all mornings). <code>[CLUSTERING_ALGORITHM]</code> The original Doryab et al. implementation uses <code>DBSCAN</code>, <code>OPTICS</code> is also available with similar (but not identical) clustering results and lower memory consumption. <code>[RADIUS_FOR_HOME]</code> All location coordinates within this distance (meters) from the home location coordinates are considered a homestay (see <code>timeathome</code> feature). <p>Features description for <code>[PHONE_LOCATIONS][PROVIDERS][DORYAB]</code>:</p> Feature Units Description locationvariance \\(meters^2\\) The sum of the variances of the latitude and longitude columns. loglocationvariance - Log of the sum of the variances of the latitude and longitude columns. totaldistance meters Total distance traveled in a time segment using the haversine formula. averagespeed km/hr Average speed in a time segment considering only the instances labeled as Moving. varspeed km/hr Speed variance in a time segment considering only the instances labeled as Moving. circadianmovement - Not suggested for use now; see Observations below.  \u201cIt encodes the extent to which a person\u2019s location patterns follow a 24-hour circadian cycle.\" Doryab et al.. numberofsignificantplaces places Number of significant locations visited. It is calculated using the DBSCAN/OPTICS clustering algorithm which takes in EPS and MIN_SAMPLES as parameters to identify clusters. Each cluster is a significant place. numberlocationtransitions transitions Number of movements between any two clusters in a time segment. radiusgyration meters Quantifies the area covered by a participant timeattop1location minutes Time spent at the most significant location. timeattop2location minutes Time spent at the 2<sup>nd</sup> most significant location. timeattop3location minutes Time spent at the 3<sup>rd</sup> most significant location. movingtostaticratio - Ratio between stationary time and total location sensed time. A lat/long coordinate pair is labeled as stationary if its speed (distance/time) to the next coordinate pair is less than 1km/hr. A higher value represents a more stationary routine. These times are computed using timeInSeconds feature. outlierstimepercent - Ratio between the time spent in non-significant clusters divided by the time spent in all clusters (total location sensed time). A higher value represents more time spent in non-significant clusters. These times are computed using timeInSeconds feature. maxlengthstayatclusters minutes Maximum time spent in a cluster (significant location). minlengthstayatclusters minutes Minimum time spent in a cluster (significant location). meanlengthstayatclusters minutes Average time spent in a cluster (significant location). stdlengthstayatclusters minutes Standard deviation of time spent in a cluster (significant location). locationentropy nats Shannon Entropy computed over the row count of each cluster (significant location), it is higher the more rows belong to a cluster (i.e., the more time a participant spent at a significant location). normalizedlocationentropy nats Shannon Entropy computed over the row count of each cluster (significant location) divided by the number of clusters; it is higher the more rows belong to a cluster (i.e., the more time a participant spent at a significant location). timeathome minutes Time spent at home (see Observations below for a description on how we compute home). <p>Assumptions/Observations</p> <p>Significant Locations Identified Significant locations are determined using DBSCAN clustering on locations that a patient visit over the course of the period of data collection.</p> <p>Circadian Movement Calculation Note Feb 3 2021. It seems the implementation of this feature is not correct; we suggest not to use this feature until a fix is in place. For a detailed description of how this should be calculated, see Saeb et al.</p> <p>Fine-Tuning Clustering Parameters Based on an experiment where we collected fused location data for 7 days with a mean accuracy of 86 &amp; SD of 350.874635, we determined that <code>EPS/MAX_EPS</code>=100 produced closer clustering results to reality. Higher values (&gt;100) missed out on some significant places, like a short grocery visit, while lower values (&lt;100) picked up traffic lights and stop signs while driving as significant locations. We recommend you set <code>EPS</code> based on your location data\u2019s accuracy (the more accurate your data is, the lower you should be able to set EPS).</p> <p>Duration Calculation To calculate the time duration component for our features, we compute the difference between consecutive rows\u2019 timestamps to take into account sampling rate variability. If this time difference is larger than a threshold (300 seconds by default), we replace it with a maximum duration (60 seconds by default, i.e., we assume a participant spent at least 60 seconds in their last known location)</p> <p>Home location Home is calculated using all location data of a participant between 12 am and 6 am, then applying a clustering algorithm (<code>DB_SCAN</code> or <code>OPTICS</code>) and considering the center of the biggest cluster home for that participant.</p>"},{"location":"features/phone-log/","title":"Phone Log","text":"<p>Sensor parameters description for <code>[PHONE_LOG]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER][ANDROID]</code> Data stream container (database table, CSV file, etc.) where a data log is stored for Android devices <code>[CONTAINER][IOS]</code> Data stream container (database table, CSV file, etc.) where a data log is stored for iOS devices <p>Note</p> <p>No feature providers have been implemented for this sensor yet, however you can use its key (<code>PHONE_LOG</code>) to improve <code>PHONE_DATA_YIELD</code> or you can implement your own features.</p>"},{"location":"features/phone-messages/","title":"Phone Messages","text":"<p>Sensor parameters description for <code>[PHONE_MESSAGES]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the messages data is stored"},{"location":"features/phone-messages/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android only</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_messages_raw.csv\n- data/raw/{pid}/phone_messages_with_datetime.csv\n- data/interim/{pid}/phone_messages_features/phone_messages_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_messages.csv\n</code></pre> <p>Parameters description for <code>[PHONE_MESSAGES][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_MESSAGES</code> features from the <code>RAPIDS</code> provider <code>[MESSAGES_TYPES]</code> The <code>messages_type</code> that will be analyzed. The options for this parameter are <code>received</code> or <code>sent</code>. <code>[FEATURES]</code> Features to be computed, see table below for <code>[MESSAGES_TYPES]</code> <code>received</code> and <code>sent</code> <p>Features description for <code>[PHONE_MESSAGES][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description count messages Number of messages of type <code>messages_type</code> that occurred during a particular <code>time_segment</code>. distinctcontacts contacts Number of distinct contacts that are associated with a particular <code>messages_type</code> during a particular <code>time_segment</code>. timefirstmessages minutes Number of minutes between 12:00am (midnight) and the first <code>message</code> of a particular <code>messages_type</code> during a particular <code>time_segment</code>. timelastmessages minutes Number of minutes between 12:00am (midnight) and the last <code>message</code> of a particular <code>messages_type</code> during a particular <code>time_segment</code>. countmostfrequentcontact messages Number of messages from the contact with the most messages of <code>messages_type</code> during a <code>time_segment</code> throughout the whole dataset of each participant. <p>Assumptions/Observations</p> <ol> <li><code>[MESSAGES_TYPES]</code> and <code>[FEATURES]</code> keys in <code>config.yaml</code> need to match. For example, <code>[MESSAGES_TYPES]</code> <code>sent</code> matches the <code>[FEATURES]</code> key <code>sent</code></li> </ol>"},{"location":"features/phone-screen/","title":"Phone Screen","text":"<p>Sensor parameters description for <code>[PHONE_SCREEN]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the screen data is stored"},{"location":"features/phone-screen/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android and iOS</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_screen_raw.csv\n- data/raw/{pid}/phone_screen_with_datetime.csv\n- data/interim/{pid}/phone_screen_episodes.csv\n- data/interim/{pid}/phone_screen_episodes_resampled.csv\n- data/interim/{pid}/phone_screen_episodes_resampled_with_datetime.csv\n- data/interim/{pid}/phone_screen_features/phone_screen_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_screen.csv\n</code></pre> <p>Parameters description for <code>[PHONE_SCREEN][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_SCREEN</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed, see table below <code>[REFERENCE_HOUR_FIRST_USE]</code> The reference point from which <code>firstuseafter</code> is to be computed, default is midnight <code>[IGNORE_EPISODES_SHORTER_THAN]</code> Ignore episodes that are shorter than this threshold (minutes). Set to 0 to disable this filter. <code>[IGNORE_EPISODES_LONGER_THAN]</code> Ignore episodes that are longer than this threshold (minutes). Set to 0 to disable this filter. <code>[EPISODE_TYPES]</code> Currently we only support <code>unlock</code> episodes (from when the phone is unlocked until the screen is off) <p>Features description for <code>[PHONE_SCREEN][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description sumduration minutes Total duration of all unlock episodes. maxduration minutes Longest duration of any unlock episode. minduration minutes Shortest duration of any unlock episode. avgduration minutes Average duration of all unlock episodes. stdduration minutes Standard deviation duration of all unlock episodes. countepisode episodes Number of all unlock episodes firstuseafter minutes Minutes until the first unlock episode. <p>Assumptions/Observations</p> <ol> <li> <p>In Android, <code>lock</code> events can happen right after an <code>off</code> event, after a few seconds of an <code>off</code> event, or never happen depending on the phone's settings, therefore, an <code>unlock</code> episode is defined as the time between an <code>unlock</code> and a <code>off</code> event. In iOS, <code>on</code> and <code>off</code> events do not exist, so an <code>unlock</code> episode is defined as the time between an <code>unlock</code> and a <code>lock</code> event.</p> </li> <li> <p>Events in iOS are recorded reliably albeit some duplicated <code>lock</code> events within milliseconds from each other, so we only keep consecutive unlock/lock pairs. In Android you cand find multiple consecutive <code>unlock</code> or <code>lock</code> events, so we only keep consecutive unlock/off pairs. In our experiments these cases are less than 10% of the screen events collected and this happens because <code>ACTION_SCREEN_OFF</code> and <code>ACTION_SCREEN_ON</code> are <code>sent when the device becomes non-interactive which may have nothing to do with the screen turning off</code>. In addition to unlock/off episodes, in Android it is possible to measure the time spent on the lock screen before an <code>unlock</code> event as well as the total screen time (i.e. <code>ON</code> to <code>OFF</code>) but these are not implemented at the moment.</p> </li> <li> <p>We transform iOS screen events to match Android\u2019s format, we replace <code>lock</code> episodes with <code>off</code> episodes (2 with 0) in iOS. However, as mentioned above this is still computing <code>unlock</code> to <code>lock</code> episodes.</p> </li> </ol>"},{"location":"features/phone-wifi-connected/","title":"Phone WiFi Connected","text":"<p>Sensor parameters description for <code>[PHONE_WIFI_CONNECTED]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the wifi (connected) data is stored"},{"location":"features/phone-wifi-connected/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android and iOS</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_wifi_connected_raw.csv\n- data/raw/{pid}/phone_wifi_connected_with_datetime.csv\n- data/interim/{pid}/phone_wifi_connected_features/phone_wifi_connected_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_wifi_connected.csv\n</code></pre> <p>Parameters description for <code>[PHONE_WIFI_CONNECTED][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_WIFI_CONNECTED</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed, see table below <p>Features description for <code>[PHONE_WIFI_CONNECTED][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description countscans devices Number of scanned WiFi access points connected during a time_segment, an access point can be detected multiple times over time and these appearances are counted separately uniquedevices devices Number of unique access point during a time_segment as identified by their hardware address countscansmostuniquedevice scans Number of scans of the most scanned access point during a time_segment across the whole monitoring period <p>Assumptions/Observations</p> <ol> <li>A connected WiFI access point is one that a phone was connected to.</li> <li>By default AWARE stores this data in the <code>sensor_wifi</code> table.</li> </ol>"},{"location":"features/phone-wifi-visible/","title":"Phone WiFi Visible","text":"<p>Sensor parameters description for <code>[PHONE_WIFI_VISIBLE]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[CONTAINER]</code> Data stream container (database table, CSV file, etc.) where the wifi (visible) data is stored"},{"location":"features/phone-wifi-visible/#rapids-provider","title":"RAPIDS provider","text":"<p>Available time segments and platforms</p> <ul> <li>Available for all time segments</li> <li>Available for Android only</li> </ul> <p>File Sequence</p> <pre><code>- data/raw/{pid}/phone_wifi_visible_raw.csv\n- data/raw/{pid}/phone_wifi_visible_with_datetime.csv\n- data/interim/{pid}/phone_wifi_visible_features/phone_wifi_visible_{language}_{provider_key}.csv\n- data/processed/features/{pid}/phone_wifi_visible.csv\n</code></pre> <p>Parameters description for <code>[PHONE_WIFI_VISIBLE][PROVIDERS][RAPIDS]</code>:</p> Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[COMPUTE]</code> Set to <code>True</code> to extract <code>PHONE_WIFI_VISIBLE</code> features from the <code>RAPIDS</code> provider <code>[FEATURES]</code> Features to be computed, see table below <p>Features description for <code>[PHONE_WIFI_VISIBLE][PROVIDERS][RAPIDS]</code>:</p> Feature Units Description countscans devices Number of scanned WiFi access points visible during a time_segment, an access point can be detected multiple times over time and these appearances are counted separately uniquedevices devices Number of unique access point during a time_segment as identified by their hardware address countscansmostuniquedevice scans Number of scans of the most scanned access point during a time_segment across the whole monitoring period <p>Assumptions/Observations</p> <ol> <li>A visible WiFI access point is one that a phone sensed around itself but that it was not connected to. Due to API restrictions, this sensor is not available on iOS.</li> <li>By default AWARE stores this data in the <code>wifi</code> table.</li> </ol>"},{"location":"setup/configuration/","title":"Configuration","text":"<p>You need to follow these steps to configure your RAPIDS deployment before you can extract behavioral features.</p> <ol> <li>Verify RAPIDS can process your data streams</li> <li>Create your participants files</li> <li>Select what time segments you want to extract features on</li> <li>Select the timezone of your study</li> <li>Configure your data streams</li> <li>Select what sensors and features you want to process</li> </ol> <p>When you are done with this configuration, go to executing RAPIDS.</p> <p>Hint</p> <p>Every time you see <code>config[\"KEY\"]</code> or <code>[KEY]</code> in these docs, we are referring to the corresponding key in the <code>config.yaml</code> file.</p>"},{"location":"setup/configuration/#supported-data-streams","title":"Supported data streams","text":"<p>A data stream refers to sensor data collected using a specific device with a specific format and stored in a specific container. For example, the <code>aware_mysql</code> data stream handles smartphone data (device) collected with the AWARE Framework (format) stored in a MySQL database (container).</p> <p>Check the table in introduction to data streams to know what data streams we support. If your data stream is supported, continue to the next configuration section, you will use its label later in this guide (e.g. <code>aware_mysql</code>). If your steam is not supported, but you want to implement it, follow the tutorial to add support for new data streams and open a new discussion in Github with any questions.</p>"},{"location":"setup/configuration/#participant-files","title":"Participant files","text":"<p>Participant files link together multiple devices (smartphones and wearables) to specific participants and identify them throughout RAPIDS. You can create these files manually or automatically. Participant files are stored in <code>data/external/participant_files/pxx.yaml</code> and follow a unified structure.</p> Remember to modify the <code>config.yaml</code> file with your PIDS <p>The list <code>PIDS</code> in <code>config.yaml</code> needs to have the participant file names of the people you want to process. For example, if you created <code>p01.yaml</code>, <code>p02.yaml</code> and <code>p03.yaml</code> files in <code>/data/external/participant_files/</code>, then <code>PIDS</code> should be: <pre><code>PIDS: [p01, p02, p03] \n</code></pre></p> Optional: Migrating participants files with the old format <p>If you were using the pre-release version of RAPIDS with participant files in plain text (as opposed to yaml), you could run the following command, and your old files will be converted into yaml files stored in <code>data/external/participant_files/</code></p> <pre><code>python tools/update_format_participant_files.py\n</code></pre>"},{"location":"setup/configuration/#structure-of-participants-files","title":"Structure of participants files","text":"Example of the structure of a participant file <p>In this example, the participant used an android phone, an ios phone, a Fitbit device, and an Empatica device throughout the study between April 23<sup>rd</sup>, 2020, and October 28<sup>th</sup>, 2020</p> <p>If your participants didn\u2019t use a <code>[PHONE]</code>, <code>[FITBIT]</code> or <code>[EMPATICA]</code> device, it is not necessary to include that section in their participant file. In other words, you can analyze data from 1 or more devices per participant.</p> <pre><code>PHONE:\n  DEVICE_IDS: [a748ee1a-1d0b-4ae9-9074-279a2b6ba524, dsadas-2324-fgsf-sdwr-gdfgs4rfsdf43]\n  PLATFORMS: [android,ios]\n  LABEL: test01\n  START_DATE: 2020-04-23\n  END_DATE: 2020-10-28\nFITBIT:\n  DEVICE_IDS: [fitbit1]\n  LABEL: test01\n  START_DATE: 2020-04-23\n  END_DATE: 2020-10-28\nEMPATICA:\n  DEVICE_IDS: [empatica1]\n  LABEL: test01\n  START_DATE: 2020-04-23\n  END_DATE: 2020-10-28\n</code></pre> [PHONE] Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[DEVICE_IDS]</code> An array of the strings that uniquely identify each smartphone, you can have more than one for when participants changed phones in the middle of the study. <code>[PLATFORMS]</code> An array that specifies the OS of each smartphone in  <code>[DEVICE_IDS]</code> , use a combination of  <code>android</code>  or  <code>ios</code>  (we support participants that changed platforms in the middle of your study!). You can set <code>[PLATFORMS]: [infer]</code>, and RAPIDS will infer them automatically (each phone data stream infer this differently, e.g., <code>aware_mysql</code> uses the <code>aware_device</code> table). <code>[LABEL]</code> A string that is used in reports and visualizations. <code>[START_DATE]</code> A string with format <code>YYYY-MM-DD</code> or <code>YYYY-MM-DD HH:MM:SS</code>. Only data collected  after  this date-time will be included in the analysis. By default, <code>YYYY-MM-DD</code> is interpreted as <code>YYYY-MM-DD 00:00:00</code>. <code>[END_DATE]</code> A string with format <code>YYYY-MM-DD</code> or <code>YYYY-MM-DD HH:MM:SS</code>. Only data collected  before  this date-time will be included in the analysis. By default, <code>YYYY-MM-DD</code> is interpreted as <code>YYYY-MM-DD 00:00:00</code>. [FITBIT] Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[DEVICE_IDS]</code> An array of the strings that uniquely identify each Fitbit, you can have more than one in case the participant changed devices in the middle of the study. <code>[LABEL]</code> A string that is used in reports and visualizations. <code>[START_DATE]</code> A string with format <code>YYYY-MM-DD</code> or <code>YYYY-MM-DD HH:MM:SS</code>. Only data collected  after  this date-time will be included in the analysis. By default, <code>YYYY-MM-DD</code> is interpreted as <code>YYYY-MM-DD 00:00:00</code>. <code>[END_DATE]</code> A string with format <code>YYYY-MM-DD</code> or <code>YYYY-MM-DD HH:MM:SS</code>. Only data collected  before  this date-time will be included in the analysis. By default, <code>YYYY-MM-DD</code> is interpreted as <code>YYYY-MM-DD 00:00:00</code>. [EMPATICA] Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[DEVICE_IDS]</code> An array of the strings that uniquely identify each Empatica device used by this participant. Since the most common use case involves having multiple zip files from a single device for each person, set this device id to an arbitrary string (we usually use their <code>pid</code>) <code>[LABEL]</code> A string that is used in reports and visualizations. <code>[START_DATE]</code> A string with format <code>YYYY-MM-DD</code> or <code>YYYY-MM-DD HH:MM:SS</code>. Only data collected  after  this date-time will be included in the analysis. By default, <code>YYYY-MM-DD</code> is interpreted as <code>YYYY-MM-DD 00:00:00</code>. <code>[END_DATE]</code> A string with format <code>YYYY-MM-DD</code> or <code>YYYY-MM-DD HH:MM:SS</code>. Only data collected  before  this date-time will be included in the analysis. By default, <code>YYYY-MM-DD</code> is interpreted as <code>YYYY-MM-DD 00:00:00</code>."},{"location":"setup/configuration/#automatic-creation-of-participant-files","title":"Automatic creation of participant files","text":"<p>You can use a CSV file with a row per participant to automatically create participant files. </p> <code>AWARE_DEVICE_TABLE</code> was deprecated <p>In previous versions of RAPIDS, you could create participant files automatically using the <code>aware_device</code> table. We deprecated this option, but you can still achieve the same results if you export the output of the following SQL query as a CSV file and follow the instructions below:</p> <pre><code>SELECT device_id, device_id as fitbit_id, CONCAT(\"p\", _id) as empatica_id, CONCAT(\"p\", _id) as pid, if(brand = \"iPhone\", \"ios\", \"android\") as platform, CONCAT(\"p\", _id)  as label, DATE_FORMAT(FROM_UNIXTIME((timestamp/1000)- 86400), \"%Y-%m-%d\") as start_date, CURRENT_DATE as end_date from aware_device order by _id;\n</code></pre> <p>In your <code>config.yaml</code>:</p> <ol> <li>Set <code>CSV_FILE_PATH</code> to a CSV file path that complies with the specs described below</li> <li>Set the devices (<code>PHONE</code>, <code>FITBIT</code>, <code>EMPATICA</code>) <code>[ADD]</code> flag to <code>TRUE</code> depending on what devices you used in your study.</li> </ol> <pre><code>CREATE_PARTICIPANT_FILES:\n  CSV_FILE_PATH: \"your_path/to_your.csv\"\n  PHONE_SECTION:\n    ADD: TRUE # or FALSE\n    IGNORED_DEVICE_IDS: []\n  FITBIT_SECTION:\n    ADD: TRUE # or FALSE\n    IGNORED_DEVICE_IDS: []\n  EMPATICA_SECTION:\n    ADD: TRUE # or FALSE\n    IGNORED_DEVICE_IDS: []\n</code></pre> <p>Your CSV file (<code>[CSV_FILE_PATH]</code>) should have the following columns (headers), but the values within each column can be empty:</p> Column Description device_id Phone device id. Separate multiple ids with <code>;</code> fitbit_id Fitbit device id. Separate multiple ids with <code>;</code> empatica_id Empatica device id. Since the most common use case involves having various zip files from a single device for each person, set this device id to an arbitrary string (we usually use their <code>pid</code>) pid Unique identifiers with the format pXXX (your participant files will be named with this string) platform Use <code>android</code>, <code>ios</code> or <code>infer</code> as explained above, separate values with <code>;</code> label A human-readable string that is used in reports and visualizations. start_date A string with format <code>YYY-MM-DD</code> or <code>YYYY-MM-DD HH:MM:SS</code>. By default, <code>YYYY-MM-DD</code> is interpreted as <code>YYYY-MM-DD 00:00:00</code>. end_date A string with format <code>YYY-MM-DD</code> or <code>YYYY-MM-DD HH:MM:SS</code>. By default, <code>YYYY-MM-DD</code> is interpreted as <code>YYYY-MM-DD 00:00:00</code>. <p>Example</p> <p>We added white spaces to this example to make it easy to read, but you don\u2019t have to.</p> <pre><code>device_id                                                                ,fitbit_id, empatica_id ,pid ,label ,platform    ,start_date ,end_date\na748ee1a-1d0b-4ae9-9074-279a2b6ba524;dsadas-2324-fgsf-sdwr-gdfgs4rfsdf43 ,fitbit1  , p01         ,p01 ,julio ,android;ios ,2020-01-01 ,2021-01-01\n4c4cf7a1-0340-44bc-be0f-d5053bf7390c                                     ,fitbit2  , p02         ,p02 ,meng  ,ios         ,2021-01-01 ,2022-01-01\n</code></pre> <p>Then run </p> <pre><code>snakemake -j1 create_participants_files\n</code></pre>"},{"location":"setup/configuration/#time-segments","title":"Time Segments","text":"<p>Time segments (or epochs) are the time windows on which you want to extract behavioral features. For example, you might want to process data every day, every morning, or only during weekends. RAPIDS offers three categories of time segments that are flexible enough to cover most use cases: frequency (short time windows every day), periodic (arbitrary time windows on any day), and event (arbitrary time windows around events of interest). See also our examples.</p> Frequency Segments <p>These segments are computed every day, and all have the same duration (for example, 30 minutes). Set the following keys in your <code>config.yaml</code></p> <pre><code>TIME_SEGMENTS: &amp;time_segments\n  TYPE: FREQUENCY\n  FILE: \"data/external/your_frequency_segments.csv\"\n  INCLUDE_PAST_PERIODIC_SEGMENTS: FALSE\n</code></pre> <p>The file pointed by <code>[TIME_SEGMENTS][FILE]</code> should have the following format and only have 1 row.</p> Column Description label A string that is used as a prefix in the name of your time segments length An integer representing the duration of your time segments in minutes <p>Example</p> <pre><code>label,length\nthirtyminutes,30\n</code></pre> <p>This configuration will compute 48 time segments for every day when any data from any participant was sensed. For example:</p> <pre><code>start_time,length,label\n00:00,30,thirtyminutes0000\n00:30,30,thirtyminutes0001\n01:00,30,thirtyminutes0002\n01:30,30,thirtyminutes0003\n...\n</code></pre> Periodic Segments <p>These segments can be computed every day or on specific days of the week, month, quarter, and year. Their minimum duration is 1 minute, but they can be as long as you want. Set the following keys in your <code>config.yaml</code>.</p> <pre><code>TIME_SEGMENTS: &amp;time_segments\n  TYPE: PERIODIC\n  FILE: \"data/external/your_periodic_segments.csv\"\n  INCLUDE_PAST_PERIODIC_SEGMENTS: FALSE # or TRUE\n</code></pre> <p>If <code>[INCLUDE_PAST_PERIODIC_SEGMENTS]</code> is set to <code>TRUE</code>, RAPIDS will consider instances of your segments back enough in the past to include the first row of data of each participant. For example, if the first row of data from a participant happened on Saturday, March 7<sup>th</sup>, 2020, and the requested segment duration is 7 days starting on every Sunday, the first segment to be considered would begin on Sunday, March 1<sup>st</sup> if <code>[INCLUDE_PAST_PERIODIC_SEGMENTS]</code> is <code>TRUE</code> or on Sunday, March 8<sup>th</sup> if <code>FALSE</code>.</p> <p>The file pointed by <code>[TIME_SEGMENTS][FILE]</code> should have the following format and can have multiple rows.</p> Column Description label A string that is used as a prefix in the name of your time segments. It has to be unique between rows start_time A string with format <code>HH:MM:SS</code> representing the starting time of this segment on any day length A string representing the length of this segment. It can have one or more of the following strings <code>XXD XXH XXM XXS</code> to represent days, hours, minutes, and seconds. For example, <code>7D 23H 59M 59S</code> repeats_on One of the following options <code>every_day</code>, <code>wday</code>, <code>qday</code>, <code>mday</code>, and <code>yday</code>. The last four represent a week, quarter, month, and year day repeats_value An integer complementing <code>repeats_on</code>. If you set <code>repeats_on</code> to <code>every_day</code>, set this to <code>0</code>, otherwise <code>1-7</code> represent a <code>wday</code> starting from Mondays, <code>1-31</code> represent a <code>mday</code>, <code>1-91</code> represent a <code>qday</code>, and <code>1-366</code> represent a <code>yday</code> <p>Example</p> <pre><code>label,start_time,length,repeats_on,repeats_value\ndaily,00:00:00,23H 59M 59S,every_day,0\nmorning,06:00:00,5H 59M 59S,every_day,0\nafternoon,12:00:00,5H 59M 59S,every_day,0\nevening,18:00:00,5H 59M 59S,every_day,0\nnight,00:00:00,5H 59M 59S,every_day,0\n</code></pre> <p>This configuration will create five segment instances (<code>daily</code>, <code>morning</code>, <code>afternoon</code>, <code>evening</code>, <code>night</code>) on any given day (<code>every_day</code> set to 0). The <code>daily</code> segment will start at midnight and last <code>23:59:59</code>; the other four segments will begin at 6am, 12pm, 6pm, and 12am, respectively, and last for <code>05:59:59</code>. </p> Event segments <p>These segments can be computed before or after an event of interest (defined as any UNIX timestamp). Their minimum duration is 1 minute, but they can be as long as you want. The start of each segment can be shifted backward or forwards from the specified timestamp. Set the following keys in your <code>config.yaml</code>.</p> <pre><code>TIME_SEGMENTS: &amp;time_segments\n  TYPE: EVENT\n  FILE: \"data/external/your_event_segments.csv\"\n  INCLUDE_PAST_PERIODIC_SEGMENTS: FALSE # or TRUE\n</code></pre> <p>The file pointed by <code>[TIME_SEGMENTS][FILE]</code> should have the following format and can have multiple rows.</p> Column Description label A string that is used as a prefix in the name of your time segments. If labels are unique, every segment is independent; if two or more segments have the same label, their data will be grouped when computing auxiliary data for features like the <code>most frequent contact</code> for calls (the most frequent contact will be calculated across all these segments). There cannot be two overlapping event segments with the same label (RAPIDS will throw an error) event_timestamp A UNIX timestamp that represents the moment an event of interest happened (clinical relapse, survey, readmission, etc.). The corresponding time segment will be computed around this moment using <code>length</code>, <code>shift</code>, and <code>shift_direction</code> length A string representing the length of this segment. It can have one or more of the following keys <code>XXD XXH XXM XXS</code> to represent days, hours, minutes, and seconds. For example, <code>7D 23H 59M 59S</code> shift A string representing the time shift from <code>event_timestamp</code>. It can have one or more of the following keys <code>XXD XXH XXM XXS</code> to represent days, hours, minutes, and seconds. For example, <code>7D 23H 59M 59S</code>. Use this value to change the start of a segment with respect to its <code>event_timestamp</code>. For example, set this variable to <code>1H</code> to create a segment that starts 1 hour from an event of interest (<code>shift_direction</code> determines if it\u2019s before or after). shift_direction An integer representing whether the <code>shift</code> is before (<code>-1</code>) or after (<code>1</code>) an <code>event_timestamp</code> device_id The device id (smartphone or Fitbit) to whom this segment belongs to. You have to create a line in this event segment file for each event of a participant that you want to analyze. If you have participants with multiple device ids, you can choose any of them <p>Example</p> <pre><code>label,event_timestamp,length,shift,shift_direction,device_id\nstress1,1587661220000,1H,5M,1,a748ee1a-1d0b-4ae9-9074-279a2b6ba524\nstress2,1587747620000,4H,4H,-1,a748ee1a-1d0b-4ae9-9074-279a2b6ba524\nstress3,1587906020000,3H,5M,1,a748ee1a-1d0b-4ae9-9074-279a2b6ba524\nstress4,1584291600000,7H,4H,-1,a748ee1a-1d0b-4ae9-9074-279a2b6ba524\nstress5,1588172420000,9H,5M,-1,a748ee1a-1d0b-4ae9-9074-279a2b6ba524\nmood,1587661220000,1H,0,0,a748ee1a-1d0b-4ae9-9074-279a2b6ba524\nmood,1587747620000,1D,0,0,a748ee1a-1d0b-4ae9-9074-279a2b6ba524\nmood,1587906020000,7D,0,0,a748ee1a-1d0b-4ae9-9074-279a2b6ba524\n</code></pre> <p>This example will create eight segments for a single participant (<code>a748ee1a...</code>), five independent <code>stressX</code> segments with various lengths (1,4,3,7, and 9 hours). Segments <code>stress1</code>, <code>stress3</code>, and <code>stress5</code> are shifted forwards by 5 minutes, and <code>stress2</code> and <code>stress4</code> are shifted backward by 4 hours (that is, if the <code>stress4</code> event happened on March 15<sup>th</sup> at 1pm EST (<code>1584291600000</code>), the time segment will start on that day at 9am and end at 4pm). </p> <p>The three <code>mood</code> segments are 1 hour, 1 day, and 7 days long and have no shift. In addition, these <code>mood</code> segments are grouped together, meaning that although RAPIDS will compute features on each one of them, some information for such computation will be extracted from all three segments, for example, the phone contact that called a participant the most, or the location clusters visited by a participant.</p> Date time labels of event segments <p>In the final feature file, you will find a row per event segment. The <code>local_segment</code> column of each row has a <code>label</code>, a start date-time string, and an end date-time string.</p> <pre><code>weeklysurvey2060#2020-09-12 01:00:00,2020-09-18 23:59:59\n</code></pre> <p>All sensor data is always segmented based on timestamps, and the date-time strings are attached for informative purposes. For example, you can plot your features based on these strings. </p> <p>When you configure RAPIDS to work with a single time zone, such time zone code will be used to convert start/end timestamps (the ones you typed in the event segments file) into start/end date-time strings. However, when you configure RAPIDS to work with multiple time zones, RAPIDS will use the most common time zone across all devices of every participant to do the conversion. The most common time zone is the one in which a participant spent the most time.</p> <p>In practical terms, this means that the date-time strings of event segments that happened in uncommon time zones will have shifted start/end date-time labels. However, the data within each segment was correctly filtered based on timestamps.</p>"},{"location":"setup/configuration/#segment-examples","title":"Segment Examples","text":"5-minutes <p>Use the following <code>Frequency</code> segment file to create 288 (12 * 60 * 24) 5-minute segments starting from midnight of every day in your study <pre><code>label,length\nfiveminutes,5\n</code></pre></p> Daily <p>Use the following <code>Periodic</code> segment file to create daily segments starting from midnight of every day in your study <pre><code>label,start_time,length,repeats_on,repeats_value\ndaily,00:00:00,23H 59M 59S,every_day,0\n</code></pre></p> Morning <p>Use the following <code>Periodic</code> segment file to create morning segments starting at 06:00:00 and ending at 11:59:59 of every day in your study <pre><code>label,start_time,length,repeats_on,repeats_value\nmorning,06:00:00,5H 59M 59S,every_day,0\n</code></pre></p> Overnight <p>Use the following <code>Periodic</code> segment file to create overnight segments starting at 20:00:00 and ending at 07:59:59 (next day) of every day in your study <pre><code>label,start_time,length,repeats_on,repeats_value\nmorning,20:00:00,11H 59M 59S,every_day,0\n</code></pre></p> Weekly <p>Use the following <code>Periodic</code> segment file to create non-overlapping weekly segments starting at midnight of every Monday in your study <pre><code>label,start_time,length,repeats_on,repeats_value\nweekly,00:00:00,6D 23H 59M 59S,wday,1\n</code></pre> Use the following <code>Periodic</code> segment file to create overlapping weekly segments starting at midnight of every day in your study <pre><code>label,start_time,length,repeats_on,repeats_value\nweekly,00:00:00,6D 23H 59M 59S,every_day,0\n</code></pre></p> Week-ends <p>Use the following <code>Periodic</code> segment file to create week-end segments starting at midnight of every Saturday in your study <pre><code>label,start_time,length,repeats_on,repeats_value\nweekend,00:00:00,1D 23H 59M 59S,wday,6\n</code></pre></p> Around surveys <p>Use the following <code>Event</code> segment file to create two 2-hour segments that start 1 hour before surveys answered by 3 participants <pre><code>label,event_timestamp,length,shift,shift_direction,device_id\nsurvey1,1587661220000,2H,1H,-1,a748ee1a-1d0b-4ae9-9074-279a2b6ba524\nsurvey2,1587747620000,2H,1H,-1,a748ee1a-1d0b-4ae9-9074-279a2b6ba524\nsurvey1,1587906020000,2H,1H,-1,rqtertsd-43ff-34fr-3eeg-efe4fergregr\nsurvey2,1584291600000,2H,1H,-1,rqtertsd-43ff-34fr-3eeg-efe4fergregr\nsurvey1,1588172420000,2H,1H,-1,klj34oi2-8frk-2343-21kk-324ljklewlr3\nsurvey2,1584291600000,2H,1H,-1,klj34oi2-8frk-2343-21kk-324ljklewlr3\n</code></pre></p>"},{"location":"setup/configuration/#timezone-of-your-study","title":"Timezone of your study","text":""},{"location":"setup/configuration/#single-timezone","title":"Single timezone","text":"<p>If your study only happened in a single time zone or you want to ignore short trips of your participants to different time zones, select the appropriate code from this list and change the following config key. Double-check your timezone code pick; for example, US Eastern Time is <code>America/New_York</code>, not <code>EST</code>.</p> <pre><code>TIMEZONE: \n    TYPE: SINGLE\n    TZCODE: America/New_York\n</code></pre>"},{"location":"setup/configuration/#multiple-timezones","title":"Multiple timezones","text":"<p>If your participants lived in different time zones or they traveled across time zones, and you know when participants\u2019 devices were in a specific time zone, RAPIDS can use this data to process your data streams with the correct date-time. You need to provide RAPIDS with the time zone data in a CSV file (<code>[TZCODES_FILE]</code>) in the format described below.</p> <pre><code>TIMEZONE: \n    TYPE: MULTIPLE\n    SINGLE:\n      TZCODE: America/New_York\n    MULTIPLE:\n      TZCODES_FILE: path_to/time_zones_csv.file\n      IF_MISSING_TZCODE: STOP\n      DEFAULT_TZCODE: America/New_York\n      FITBIT: \n        ALLOW_MULTIPLE_TZ_PER_DEVICE: False\n        INFER_FROM_SMARTPHONE_TZ: False\n</code></pre> <p>Parameters for <code>[TIMEZONE]</code></p> Parameter \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description <code>[TYPE]</code> Either <code>SINGLE</code> or <code>MULTIPLE</code> as explained above <code>[SINGLE][TZCODE]</code> The time zone code from this list to be used across all devices <code>[MULTIPLE][TZCODES_FILE]</code> A CSV file containing the time zones in which participants\u2019 devices sensed data (see the required format below). Multiple devices can be linked to the same person. Read more in Participants Files <code>[MULTIPLE][IF_MISSING_TZCODE]</code> When a device is missing from <code>[TZCODES_FILE]</code> Set this flag to <code>STOP</code> to stop RAPIDS execution and show an error, or to <code>USE_DEFAULT</code> to assign the time zone specified in <code>[DEFAULT_TZCODE]</code> to any such devices <code>[MULTIPLE][FITBIT][ALLOW_MULTIPLE_TZ_PER_DEVICE]</code> You only need to care about this flag if one or more Fitbit devices sensed data in one or more time zones, and you want RAPIDS to take into account this in its feature computation. Read more in  \u201cHow does RAPIDS handle Fitbit devices?\u201d below. <code>[MULTIPLE][FITBIT][INFER_FROM_SMARTPHONE_TZ]</code> You only need to care about this flag if one or more Fitbit devices sensed data in one or more time zones, and you want RAPIDS to take into account this in its feature computation. Read more in  \u201cHow does RAPIDS handle Fitbit devices?\u201d below. Format of <code>TZCODES_FILE</code> <p><code>TZCODES_FILE</code> has three columns and a row for each time zone a device visited (a device can be a smartphone or wearable (Fitbit/Empatica)):</p> Column Description <code>device_id</code> A string that uniquely identifies a smartphone or wearable <code>tzcode</code> A string with the appropriate code from this list that represents the time zone where the <code>device</code> sensed data <code>timestamp</code> A UNIX timestamp indicating when was the first time this <code>device_id</code> sensed data in <code>tzcode</code> <pre><code>device_id,                            tzcode,              timestamp\n13dbc8a3-dae3-4834-823a-4bc96a7d459d, America/New_York,     1587500000000\n13dbc8a3-dae3-4834-823a-4bc96a7d459d, America/Mexico_City,  1587600000000\n13dbc8a3-dae3-4834-823a-4bc96a7d459d, America/Los_Angeles,  1587700000000\n65sa66a5-2d2d-4524-946v-44ascbv4sad7, Europe/Amsterdam,     1587100000000\n65sa66a5-2d2d-4524-946v-44ascbv4sad7, Europe/Berlin,        1587200000000\n65sa66a5-2d2d-4524-946v-44ascbv4sad7, Europe/Amsterdam,     1587300000000\n</code></pre> <p>Using this file, RAPDIS will create time zone intervals per device, for example for <code>13dbc8a3-dae3-4834-823a-4bc96a7d459d</code>:</p> <ul> <li>Interval 1 <code>[1587500000000, 1587599999999]</code> for <code>America/New_York</code></li> <li>Interval 2 <code>[1587600000000, 1587699999999]</code> for <code>America/Mexico_City</code></li> <li>Interval 3 <code>[1587700000000, now]</code> for <code>America/Los_Angeles</code></li> </ul> <p>Any sensor data row from a device will be assigned a timezone if it falls within that interval, for example:</p> <ul> <li>A screen row sensed at <code>1587533333333</code> will be assigned to <code>America/New_York</code> because it falls within Interval 1</li> <li>A screen row sensed at <code>1587400000000</code> will be discarded because it was logged outside any interval.</li> </ul> Can I get the <code>TZCODES_FILE</code> from the time zone table collected automatically by the AWARE app? <p>Sure. You can put your timezone table (<code>timezone.csv</code>) collected by the AWARE app under <code>data/external</code> folder and run: <pre><code>python tools/create_multi_timezones_file.py\n</code></pre> The <code>TZCODES_FILE</code> will be saved as <code>data/external/multiple_timezones.csv</code>.</p> What happens if participant X lives in Los Angeles but participant Y lives in Amsterdam and they both stayed there during my study? <p>Add a row per participant and set timestamp to <code>0</code>: <pre><code>device_id,                            tzcode,              timestamp\n13dbc8a3-dae3-4834-823a-4bc96a7d459d, America/Los_Angeles,  0\n65sa66a5-2d2d-4524-946v-44ascbv4sad7, Europe/Amsterdam,     0\n</code></pre></p> What happens if I forget to add a timezone for one or more devices? <p>It depends on <code>[IF_MISSING_TZCODE]</code>. </p> <p>If <code>[IF_MISSING_TZCODE]</code> is set to <code>STOP</code>, RAPIDS will stop its execution and show you an error message.</p> <p>If <code>[IF_MISSING_TZCODE]</code> is set to <code>USE_DEFAULT</code>, it will assign the time zone specified in <code>[DEFAULT_TZCODE]</code> to any devices with missing time zone information in <code>[TZCODES_FILE]</code>. This is helpful if only a few of your participants had multiple timezones, and you don\u2019t want to specify the same time zone for the rest.</p> How does RAPIDS handle Fitbit devices? <p>Fitbit devices are not time zone aware, and they always log data with a local date-time string. </p> <ul> <li> <p>When none of the Fitbit devices in your study changed time zones (e.g., <code>p01</code> was always in New York and <code>p02</code> was always in Amsterdam), you can set a single time zone per Fitbit device id along with a timestamp of 0 (you can still assign multiple time zones to smartphone device ids) <pre><code>device_id, tzcode,              timestamp\nfitbit123, America/New_York,     0\nfitbit999, Europe/Amsterdam,     0\n</code></pre></p> </li> <li> <p>On the other hand, when at least one of your Fitbit devices changed time zones AND you want RAPIDS to take into account these changes, you need to set <code>[ALLOW_MULTIPLE_TZ_PER_DEVICE]</code> to <code>True</code>. You have to manually allow this option because you need to be aware it can produce inaccurate features around the times when time zones changed. This is because we cannot know precisely when the Fitbit device detected and processed the time zone change.</p> <p>If you want to <code>ALLOW_MULTIPLE_TZ_PER_DEVICE</code>, you will need to add any time zone changes per device in the <code>TZCODES_FILE</code> as explained above. You could obtain this data by hand, but if your participants also used a smartphone during your study, you can use their time zone logs. Recall that in RAPIDS, every participant is represented with a participant file <code>pXX.yaml</code>, this file links together multiple devices, and we will use it to know what smartphone time zone data should be applied to Fitbit devices. Thus set <code>INFER_FROM_SMARTPHONE_TZ</code> to <code>TRUE</code>, if you have included smartphone time zone data in your <code>TZCODE_FILE</code> and want to make a participant\u2019s Fitbit data time zone aware with their respective smartphone data.</p> </li> </ul>"},{"location":"setup/configuration/#data-stream-configuration","title":"Data Stream Configuration","text":"<p>Modify the following keys in your <code>config.yaml</code> depending on the data stream you want to process.</p> Phone <p>Set <code>[PHONE_DATA_STREAMS][TYPE]</code> to the smartphone data stream you want to process (e.g. <code>aware_mysql</code>) and configure its parameters (e.g. <code>[DATABASE_GROUP]</code>). Ignore the parameters of streams you are not using (e.g. <code>[FOLDER]</code> of <code>aware_csv</code>).</p> <pre><code>PHONE_DATA_STREAMS:\n  USE: aware_mysql\n\n  # AVAILABLE:\n  aware_mysql:\n    DATABASE_GROUP: MY_GROUP\n\n  aware_csv:\n    FOLDER: data/external/aware_csv\n</code></pre> aware_mysql Key Description <code>[DATABASE_GROUP]</code> A database credentials group. Read the instructions below to set it up Setting up a DATABASE_GROUP and its connection credentials. <ol> <li> <p>If you haven\u2019t done so, create an empty file called <code>credentials.yaml</code> in your RAPIDS root directory: </p> </li> <li> <p>Add the following lines to <code>credentials.yaml</code> and replace your database-specific credentials (user, password, host, and database):</p> <pre><code>MY_GROUP:\n  database: MY_DATABASE\n  host: MY_HOST\n  password: MY_PASSWORD\n  port: 3306\n  user: MY_USER\n</code></pre> </li> <li> <p>Notes</p> <ol> <li> <p>The label <code>[MY_GROUP]</code> is arbitrary but it has to match the <code>[DATABASE_GROUP]</code> attribute of the data stream you choose to use.</p> </li> <li> <p>Indentation matters</p> </li> <li> <p>You can have more than one credentials group in <code>credentials.yaml</code></p> </li> </ol> </li> </ol> Upgrading from <code>./.env</code> from RAPIDS 0.x <p>In RAPIDS versions 0.x, database credentials were stored in a <code>./.env</code> file. If you are migrating from that type of file, you have two options:</p> <ol> <li> <p>Migrate your credentials by hand:</p> change .env format <pre><code>[MY_GROUP]\nuser=MY_USER\npassword=MY_PASSWORD\nhost=MY_HOST\nport=3306\ndatabase=MY_DATABASE\n</code></pre> to credentials.yaml format <pre><code>MY_GROUP:\n  user: MY_USER\n  password: MY_PASSWORD\n  host: MY_HOST\n  port: 3306\n  database: MY_DATABASE\n</code></pre> </li> <li> <p>Use the migration script we provide (make sure your conda environment is active):</p> <pre><code>python tools/update_format_env.py\n</code></pre> </li> </ol> Connecting to localhost (host machine) from inside our docker container. <p>If you are using RAPIDS\u2019 docker container and Docker-for-mac or Docker-for-Windows 18.03+, you can connect to a MySQL database in your host machine using <code>host.docker.internal</code> instead of <code>127.0.0.1</code> or <code>localhost</code>. In a Linux host, you need to run our docker container using <code>docker run --network=\"host\" -d moshiresearch/rapids:latest</code> and then <code>127.0.0.1</code> will point to your host machine.</p> aware_csv Key Description <code>[FOLDER]</code> Folder where you have to place a CSV file per phone sensor. Each file has to contain all the data from every participant you want to process. Fitbit <p>Set <code>[FITBIT_DATA_STREAMS][TYPE]</code> to the Fitbit data stream you want to process (e.g. <code>fitbitjson_mysql</code>) and configure its parameters (e.g. <code>[DATABASE_GROUP]</code>). Ignore the parameters of the other streams you are not using (e.g. <code>[FOLDER]</code> of <code>aware_csv</code>).</p> <p>Warning</p> <p>You will probably have to tell RAPIDS the name of the columns where you stored your Fitbit data. To do this, modify your chosen stream\u2019s <code>format.yaml</code> column mappings to match your raw data column names.</p> <pre><code>FITBIT_DATA_STREAMS:\n  USE: fitbitjson_mysql\n\n  # AVAILABLE:\n  fitbitjson_mysql:\n    DATABASE_GROUP: MY_GROUP\n    SLEEP_SUMMARY_LAST_NIGHT_END: 660\n\n  fitbitjson_csv:\n    FOLDER: data/external/fitbit_csv\n    SLEEP_SUMMARY_LAST_NIGHT_END: 660\n\n  fitbitparsed_mysql:\n    DATABASE_GROUP: MY_GROUP\n    SLEEP_SUMMARY_LAST_NIGHT_END: 660\n\n  fitbitparsed_csv:\n    FOLDER: data/external/fitbit_csv\n    SLEEP_SUMMARY_LAST_NIGHT_END: 660\n</code></pre> fitbitjson_mysql <p>This data stream processes Fitbit data inside a JSON column obtained from the Fitbit API and stored in a MySQL database. Read more about its column mappings and mutations in <code>fitbitjson_mysql</code>.</p> Key Description <code>[DATABASE_GROUP]</code> A database credentials group. Read the instructions below to set it up <code>[SLEEP_SUMMARY_LAST_NIGHT_END]</code> Segments are assigned based on this parameter. Any sleep episodes that start between today\u2019s SLEEP_SUMMARY_LAST_NIGHT_END (LNE) and tomorrow\u2019s LNE are regarded as today\u2019s sleep episodes. While today\u2019s bedtime is based on today\u2019s sleep episodes, today\u2019s wake time is based on yesterday\u2019s sleep episodes. Setting up a DATABASE_GROUP and its connection credentials. <ol> <li> <p>If you haven\u2019t done so, create an empty file called <code>credentials.yaml</code> in your RAPIDS root directory: </p> </li> <li> <p>Add the following lines to <code>credentials.yaml</code> and replace your database-specific credentials (user, password, host, and database):</p> <pre><code>MY_GROUP:\n  database: MY_DATABASE\n  host: MY_HOST\n  password: MY_PASSWORD\n  port: 3306\n  user: MY_USER\n</code></pre> </li> <li> <p>Notes</p> <ol> <li> <p>The label <code>[MY_GROUP]</code> is arbitrary but it has to match the <code>[DATABASE_GROUP]</code> attribute of the data stream you choose to use.</p> </li> <li> <p>Indentation matters</p> </li> <li> <p>You can have more than one credentials group in <code>credentials.yaml</code></p> </li> </ol> </li> </ol> Upgrading from <code>./.env</code> from RAPIDS 0.x <p>In RAPIDS versions 0.x, database credentials were stored in a <code>./.env</code> file. If you are migrating from that type of file, you have two options:</p> <ol> <li> <p>Migrate your credentials by hand:</p> change .env format <pre><code>[MY_GROUP]\nuser=MY_USER\npassword=MY_PASSWORD\nhost=MY_HOST\nport=3306\ndatabase=MY_DATABASE\n</code></pre> to credentials.yaml format <pre><code>MY_GROUP:\n  user: MY_USER\n  password: MY_PASSWORD\n  host: MY_HOST\n  port: 3306\n  database: MY_DATABASE\n</code></pre> </li> <li> <p>Use the migration script we provide (make sure your conda environment is active):</p> <pre><code>python tools/update_format_env.py\n</code></pre> </li> </ol> Connecting to localhost (host machine) from inside our docker container. <p>If you are using RAPIDS\u2019 docker container and Docker-for-mac or Docker-for-Windows 18.03+, you can connect to a MySQL database in your host machine using <code>host.docker.internal</code> instead of <code>127.0.0.1</code> or <code>localhost</code>. In a Linux host, you need to run our docker container using <code>docker run --network=\"host\" -d moshiresearch/rapids:latest</code> and then <code>127.0.0.1</code> will point to your host machine.</p> fitbitjson_csv <p>This data stream processes Fitbit data inside a JSON column obtained from the Fitbit API and stored in a CSV file. Read more about its column mappings and mutations in <code>fitbitjson_csv</code>.</p> Key Description <code>[FOLDER]</code> Folder where you have to place a CSV file per Fitbit sensor. Each file has to contain all the data from every participant you want to process. <code>[SLEEP_SUMMARY_LAST_NIGHT_END]</code> Segments are assigned based on this parameter. Any sleep episodes that start between today\u2019s SLEEP_SUMMARY_LAST_NIGHT_END (LNE) and tomorrow\u2019s LNE are regarded as today\u2019s sleep episodes. While today\u2019s bedtime is based on today\u2019s sleep episodes, today\u2019s wake time is based on yesterday\u2019s sleep episodes. fitbitparsed_mysql <p>This data stream process Fitbit data stored in multiple columns after being parsed from the JSON column returned by Fitbit API and stored in a MySQL database. Read more about its column mappings and mutations in <code>fitbitparsed_mysql</code>.</p> Key Description <code>[DATABASE_GROUP]</code> A database credentials group. Read the instructions below to set it up <code>[SLEEP_SUMMARY_LAST_NIGHT_END]</code> Segments are assigned based on this parameter. Any sleep episodes that start between today\u2019s SLEEP_SUMMARY_LAST_NIGHT_END (LNE) and tomorrow\u2019s LNE are regarded as today\u2019s sleep episodes. While today\u2019s bedtime is based on today\u2019s sleep episodes, today\u2019s wake time is based on yesterday\u2019s sleep episodes. Setting up a DATABASE_GROUP and its connection credentials. <ol> <li> <p>If you haven\u2019t done so, create an empty file called <code>credentials.yaml</code> in your RAPIDS root directory: </p> </li> <li> <p>Add the following lines to <code>credentials.yaml</code> and replace your database-specific credentials (user, password, host, and database):</p> <pre><code>MY_GROUP:\n  database: MY_DATABASE\n  host: MY_HOST\n  password: MY_PASSWORD\n  port: 3306\n  user: MY_USER\n</code></pre> </li> <li> <p>Notes</p> <ol> <li> <p>The label <code>[MY_GROUP]</code> is arbitrary but it has to match the <code>[DATABASE_GROUP]</code> attribute of the data stream you choose to use.</p> </li> <li> <p>Indentation matters</p> </li> <li> <p>You can have more than one credentials group in <code>credentials.yaml</code></p> </li> </ol> </li> </ol> Upgrading from <code>./.env</code> from RAPIDS 0.x <p>In RAPIDS versions 0.x, database credentials were stored in a <code>./.env</code> file. If you are migrating from that type of file, you have two options:</p> <ol> <li> <p>Migrate your credentials by hand:</p> change .env format <pre><code>[MY_GROUP]\nuser=MY_USER\npassword=MY_PASSWORD\nhost=MY_HOST\nport=3306\ndatabase=MY_DATABASE\n</code></pre> to credentials.yaml format <pre><code>MY_GROUP:\n  user: MY_USER\n  password: MY_PASSWORD\n  host: MY_HOST\n  port: 3306\n  database: MY_DATABASE\n</code></pre> </li> <li> <p>Use the migration script we provide (make sure your conda environment is active):</p> <pre><code>python tools/update_format_env.py\n</code></pre> </li> </ol> Connecting to localhost (host machine) from inside our docker container. <p>If you are using RAPIDS\u2019 docker container and Docker-for-mac or Docker-for-Windows 18.03+, you can connect to a MySQL database in your host machine using <code>host.docker.internal</code> instead of <code>127.0.0.1</code> or <code>localhost</code>. In a Linux host, you need to run our docker container using <code>docker run --network=\"host\" -d moshiresearch/rapids:latest</code> and then <code>127.0.0.1</code> will point to your host machine.</p> fitbitparsed_csv <p>This data stream process Fitbit data stored in multiple columns (plain text) after being parsed from the JSON column returned by Fitbit API and stored in a CSV file. Read more about its column mappings and mutations in <code>fitbitparsed_csv</code>.</p> Key Description <code>[FOLDER]</code> Folder where you have to place a CSV file per Fitbit sensor. Each file has to contain all the data from every participant you want to process. <code>[SLEEP_SUMMARY_LAST_NIGHT_END]</code> Segments are assigned based on this parameter. Any sleep episodes that start between today\u2019s SLEEP_SUMMARY_LAST_NIGHT_END (LNE) and tomorrow\u2019s LNE are regarded as today\u2019s sleep episodes. While today\u2019s bedtime is based on today\u2019s sleep episodes, today\u2019s wake time is based on yesterday\u2019s sleep episodes. Empatica <p>Set <code>[USE]</code> to the Empatica data stream you want to use; see the table in introduction to data streams. Configure any parameters as indicated below.</p> <pre><code>EMPATICA_DATA_STREAMS:\n  USE: empatica_zip\n\n  # AVAILABLE:\n  empatica_zip: \n    FOLDER: data/external/empatica\n</code></pre> empatica_zip Key Description <code>[FOLDER]</code> The relative path to a folder containing one subfolder per participant. The name of a participant folder should match their device_id assigned in their participant file. Each participant folder can have one or more zip files with any name; in other words, the sensor data in those zip files belong to a single participant. The zip files are automatically generated by Empatica and have a CSV file per sensor (<code>ACC</code>, <code>HR</code>, <code>TEMP</code>, <code>EDA</code>, <code>BVP</code>, <code>TAGS</code>). All CSV files of the same type contained in one or more zip files are uncompressed, parsed, sorted by timestamp, and joined together. Example of an EMPATICA FOLDER <p>In the file tree below, we want to process three participants\u2019 data: <code>p01</code>, <code>p02</code>, and <code>p03</code>. <code>p01</code> has two zip files, <code>p02</code> has only one zip file, and <code>p03</code> has three zip files. Each zip has a CSV file per sensor that is joined together and processed by RAPIDS.</p> <pre><code>data/ # this folder exists in the root RAPIDS folder\n  external/\n    empatica/\n      p01/\n        file1.zip\n        file2.zip\n      p02/\n        aaaa.zip\n      p03/\n        t1.zip\n        t2.zip\n        t3.zip\n</code></pre>"},{"location":"setup/configuration/#sensor-and-features-to-process","title":"Sensor and Features to Process","text":"<p>Finally, you need to modify the <code>config.yaml</code> section of the sensors you want to extract behavioral features from. All sensors follow the same naming nomenclature (<code>DEVICE_SENSOR</code>) and parameter structure which we explain in the Behavioral Features Introduction. </p> <p>Done</p> <p>Head over to Execution to learn how to execute RAPIDS.</p>"},{"location":"setup/execution/","title":"Execution","text":"<p>After you have installed and configured RAPIDS, use the following command to execute it.</p> <pre><code>./rapids -j1\n</code></pre> <p>Ready to extract behavioral features</p> <p>If you are ready to extract features head over to the Behavioral Features Introduction</p> <p>We wrap Snakemake</p> <p>The script <code>./rapids</code> is a wrapper around Snakemake so you can pass any parameters that Snakemake accepts (e.g. <code>-j1</code>). </p> <p>Updating RAPIDS output after modifying <code>config.yaml</code></p> <p>Any changes to the <code>config.yaml</code> file will be applied automatically and only the relevant files will be updated. This means that after modifying the features list for <code>PHONE_MESSAGE</code> for example, RAPIDS will execute the script that computes <code>MESSAGES</code> features and update its output file.</p> <p>Multi-core</p> <p>You can run RAPIDS over multiple cores by modifying the <code>-j</code> argument (e.g. use <code>-j8</code> to use 8 cores). However, take into account that this means multiple sensor datasets for different participants will be loaded in memory at the same time. If RAPIDS crashes because it ran out of memory, reduce the number of cores and try again.</p> <p>As reference, we have run RAPIDS over 12 cores and 32 Gb of RAM without problems for a study with 200 participants with 14 days of low-frequency smartphone data (no accelerometer, gyroscope, or magnetometer).</p> <p>Deleting RAPIDS output</p> <p>If you  want to delete all the output files RAPIDS produces, you can execute the following command:</p> <pre><code>./rapids -j1 --delete-all-output\n</code></pre> <p>Forcing a complete rerun or updating your raw data in RAPIDS</p> <p>If you want to update your raw data or rerun the whole pipeline from scratch, run the following commands:</p> <pre><code>./rapids -j1 --delete-all-output\n./rapids -j1\n</code></pre>"},{"location":"setup/installation/","title":"Installation","text":"<p>You can install RAPIDS using Docker (the fastest), or native instructions for MacOS and Linux (Ubuntu). Windows is supported through Docker or WSL.</p> Docker <ol> <li> <p>Install Docker</p> </li> <li> <p>Pull our RAPIDS container     <pre><code>docker pull moshiresearch/rapids:latest\n</code></pre></p> </li> <li> <p>Run RAPIDS' container (after this step is done you should see a     prompt in the main RAPIDS folder with its python environment active)</p> <pre><code>docker run -it moshiresearch/rapids:latest\n</code></pre> </li> <li> <p>Pull the latest version of RAPIDS</p> <pre><code>git pull\n</code></pre> </li> <li> <p>Make RAPIDS script executable     <pre><code>chmod +x rapids\n</code></pre></p> </li> <li> <p>Check that RAPIDS is working     <pre><code>./rapids -j1\n</code></pre></p> </li> <li> <p>Optional. You can edit RAPIDS files with <code>vim</code> but we recommend using <code>Visual Studio Code</code> and its <code>Remote Containers</code> extension</p> How to configure Remote Containers extension <ul> <li>Make sure RAPIDS container is running</li> <li>Install the Remote - Containers extension</li> <li>Go to the <code>Remote Explorer</code> panel on the left hand sidebar</li> <li>On the top right dropdown menu choose <code>Containers</code></li> <li>Double click on the <code>moshiresearch/rapids</code> container in the<code>CONTAINERS</code> tree</li> <li>A new VS Code session should open on RAPIDS main folder inside the container.</li> </ul> </li> </ol> <p>Warning</p> <p>If you installed RAPIDS using Docker for Windows on Windows 10, the container will have limits on the amount of RAM it can use. If you find that RAPIDS crashes due to running out of memory, increase this limit.</p> MacOS <p>We tested these instructions in Catalina and Big Sur</p> M1 Macs <p>RAPIDS can run on M1 Macs, the only changes as of Feb 21, 2021 are:</p> <ul> <li>R needs to be installed via brew under Rosetta (x86 arch) due to incompatibility issues with some R libraries. To do this, run your terminal via Rosetta, then proceed with the usual brew installation command. Use x86 brew to install R and restore RAPIDS\u2019 packages (<code>snakemake -j1 renv_install &amp; snakemake -j1 renv_restore</code>). </li> <li>There is a bug related to timezone codes. We set the correct <code>TZ_DIR</code> in <code>renv/activate.R</code> (line #19) <code>Sys.setenv(\"TZDIR\" = file.path(R.home(), \"share\", \"zoneinfo\"))</code> (RAPIDS does this automatically).</li> </ul> <ol> <li> <p>Install brew</p> </li> <li> <p>Install MySQL</p> <pre><code>brew install mysql\nbrew services start mysql\n</code></pre> </li> <li> <p>Install R 4.0, pandoc and rmarkdown. If you have other instances of R, we recommend uninstalling them</p> <pre><code>brew install r\nbrew install pandoc\nRscript --vanilla -e 'install.packages(\"rmarkdown\", repos=\"http://cran.us.r-project.org\")'\n</code></pre> </li> <li> <p>Install miniconda (restart your terminal afterwards)</p> <pre><code>brew cask install miniconda\nconda init zsh # (or conda init bash)\n</code></pre> </li> <li> <p>Clone our repo</p> <pre><code>git clone https://github.com/carissalow/rapids\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>cd rapids\nconda env create -f environment.yml -n rapids\nconda activate rapids\n</code></pre> </li> <li> <p>Install R packages and virtual environment:</p> <pre><code>snakemake -j1 renv_install\nsnakemake -j1 renv_restore\n</code></pre> <p>Note</p> <p>This step could take several minutes to complete, especially if you have less than 3Gb of RAM or packages need to be compiled from source. Please be patient and let it run until completion.</p> </li> <li> <p>Make RAPIDS script executable     <pre><code>chmod +x rapids\n</code></pre></p> </li> <li> <p>Check that RAPIDS is working     <pre><code>./rapids -j1\n</code></pre></p> </li> </ol> Ubuntu <p>We tested RAPIDS on Ubuntu 18.04 &amp; 20.04. Note that the necessary Python and R packages are available in other Linux distributions, so if you decide to give it a try, let us know and we can update these docs.</p> <ol> <li> <p>Install dependencies</p> <pre><code>sudo apt install libcurl4-openssl-dev\nsudo apt install libssl-dev\nsudo apt install libxml2-dev\nsudo apt install libglpk40\n</code></pre> </li> <li> <p>Install MySQL</p> <pre><code>sudo apt install libmysqlclient-dev\nsudo apt install mysql-server\n</code></pre> </li> <li> <p>Add key for R\u2019s repository.</p> <pre><code>sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9\n</code></pre> </li> <li> <p>Add R\u2019s repository</p> Ubuntu 18.04 Bionic <pre><code>sudo add-apt-repository 'deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/'\n</code></pre> Ubuntu 20.04 Focal <pre><code>sudo add-apt-repository 'deb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/'\n</code></pre> </li> <li> <p>Install R 4.0. If you have other instances of R, we recommend uninstalling them</p> <pre><code>sudo apt update\nsudo apt install r-base\n</code></pre> </li> <li> <p>Install Pandoc and rmarkdown</p> <pre><code>sudo apt install pandoc\nRscript --vanilla -e 'install.packages(\"rmarkdown\", repos=\"http://cran.us.r-project.org\")'\n</code></pre> </li> <li> <p>Install git</p> <pre><code>sudo apt install git\n</code></pre> </li> <li> <p>Install miniconda</p> </li> <li> <p>Restart your current shell</p> </li> <li> <p>Clone our repo:</p> <pre><code>git clone https://github.com/carissalow/rapids\n</code></pre> </li> <li> <p>Create a python virtual environment:</p> <pre><code>cd rapids\nconda env create -f environment.yml -n MY_ENV_NAME\nconda activate MY_ENV_NAME\n</code></pre> </li> <li> <p>Install the R virtual environment management package (renv)</p> <pre><code>snakemake -j1 renv_install\n</code></pre> </li> <li> <p>Restore the R virtual environment</p> Ubuntu 18.04 Bionic (fast) <p>Run the following command to restore the R virtual environment using RSPM binaries <pre><code>R -e 'renv::restore(repos = c(CRAN = \"https://packagemanager.rstudio.com/all/__linux__/bionic/latest\"))'\n</code></pre></p> Ubuntu 20.04 Focal (fast) <p>Run the following command to restore the R virtual environment using RSPM binaries <pre><code>R -e 'renv::restore(repos = c(CRAN = \"https://packagemanager.rstudio.com/all/__linux__/focal/latest\"))'\n</code></pre></p> Ubuntu (slow) <p>If the fast installation command failed for some reason, you can restore the R virtual environment from source: <pre><code>R -e 'renv::restore()'\n</code></pre></p> <p>Note</p> <p>This step could take several minutes to complete, especially if you have less than 3Gb of RAM or packages need to be compiled from source. Please be patient and let it run until completion.</p> </li> <li> <p>Make RAPIDS script executable     <pre><code>chmod +x rapids\n</code></pre></p> </li> <li> <p>Check that RAPIDS is working     <pre><code>./rapids -j1\n</code></pre></p> </li> </ol> Windows <p>There are several options varying in complexity:</p> <ul> <li>You can use our Docker instructions (tested)</li> <li>You can use our Ubuntu 20.04 instructions on WSL2 (not tested but it will likely work)</li> <li>Native installation (experimental). If you would like to contribute to RAPIDS you could try to install MySQL, miniconda, Python, and R 4.0+ in Windows and restore the Python and R virtual environments using steps 6 and 7 of the instructions for Mac. You can get in touch if you would like to discuss this with the team.</li> </ul>"},{"location":"setup/overview/","title":"Overview","text":"<p>Let\u2019s review some key concepts we use throughout these docs:</p> Definition\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description Device A mobile or wearable device, like smartphones, Fitbit wrist bands, Oura Rings, etc. Sensor A physical or digital module builtin in a device that produces a data stream. For example, a smartphone\u2019s accelerometer or screen. Data Stream Set of sensor data collected using a specific device with a particular ** format** and stored in a specific container. For example, smartphone (device) data collected with the AWARE Framework (format) and stored in a MySQL database (container). Data Stream Format Sensor data produced by a data stream have columns with specific names and types. RAPIDS can process a data stream using a <code>format.yaml</code> file that describes the raw data columns and any necessary transformations. Data Stream Container Sensor data produced by a data stream can be stored in a database, electronic files, or arbitrary electronic containers. RAPIDS can pull (download) the data from a stream using a container script implemented in R or Python. Participant A person that took part in a monitoring study Behavioral feature A metric computed from raw sensor data quantifying the behavior of a participant. For example, time spent at home calculated from location data. These are also known as digital biomarkers Time segment Time segments (or epochs) are the time windows on which RAPIDS extracts behavioral features. For example, you might want to compute participants\u2019 time at home every morning or only during weekends. You define time segments in a CSV file that RAPIDS processes. Time zone A string like <code>America/New_York</code> that represents a time zone where a device logged data. You can process data collected in single or multiple time zones for every participant. Feature Provider A script that creates behavioral features for a specific sensor. Providers are created by the core RAPIDS team or by the community, which are named after its first author like [PHONE_LOCATIONS][DORYAB]. config.yaml A YAML file where you can modify parameters to process data streams and behavioral features. This is the heart of RAPIDS and the file that you will change the most. credentials.yaml A YAML file where you can define credential groups (user, password, host, etc.) if your data stream needs to connect to a database or Web API Participant file(s) A YAML file that links one or more smartphone or wearable devices used by a single participant. RAPIDS needs one file per participant. <p>What can I do with RAPIDS?</p> <ul> <li>Extract behavioral features from smartphone, Fitbit, and Empatica\u2019s supported data streams</li> <li>Add your own behavioral features (we can include them in RAPIDS if you want to share them with the community)</li> <li>Add support for new data streams if yours cannot be processed by RAPIDS yet</li> <li>Create visualizations for data quality control  and feature inspection</li> <li>Extending RAPIDS to organize your analysis and publish a code repository along with your code</li> </ul> <p>Hint</p> <ul> <li> <p>We recommend you follow the Minimal Example tutorial to get familiar with RAPIDS</p> </li> <li> <p>In order to follow any of the previous tutorials, you will have to Install, Configure, and learn how to Execute RAPIDS.</p> </li> <li> <p>Open a new discussion in Github if you have any questions and open an issue to report any bugs.</p> </li> </ul>"},{"location":"setup/overview/#frequently-asked-questions","title":"Frequently Asked Questions","text":""},{"location":"setup/overview/#general","title":"General","text":"What exactly is RAPIDS? <p>RAPIDS is a group of configuration files and R and Python scripts executed by Snakemake. You can get a copy of RAPIDS by cloning our Github repository.</p> <p>RAPIDS is not a web application or server; all the processing is done in your laptop, server, or computer cluster.</p> How does RAPIDS work? <p>You will most of the time only have to modify configuration files in YAML format (<code>config.yaml</code>, <code>credentials.yaml</code>, and participant files <code>pxx.yaml</code>), and in CSV format (time zones and time segments).</p> <p>RAPIDS pulls data from different data containers and processes it in steps. The input/output of each stage is saved as a CSV file for inspection; you can check the files created for each sensor on its documentation page. </p> <p>All data is stored in <code>data/</code>, and all processing Python and R scripts are stored in <code>src/</code>.</p> User and File interactions in RAPIDS <p>In the figure below, we represent the interactions between users and files. After a user modifies the configuration files mentioned above, the <code>Snakefile</code> file will search for and execute the Snakemake rules that contain the Python or R scripts necessary to generate or update the required output files (behavioral features, plots, etc.).</p> <p> Interaction diagram between the user, and important files in RAPIDS </p> Data flow in RAPIDS <p>In the figure below, we represent the flow of data in RAPIDS. In broad terms, smartphone and wearable devices log data streams with a certain format to a data container (database, file, etc.). </p> <p>RAPIDS can connect to these containers if it has a <code>format.yaml</code> and a <code>container.[R|py]</code> script used to pull the correct data and mutate it to comply with RAPIDS\u2019 internal data representation. Once the data stream is in RAPIDS, it goes through some basic transformations (scripts), one that assigns a time segment and a time zone to each data row, and another one that creates \u201cepisodes\u201d of data for some sensors that need it (like screen, battery, activity recognition, and sleep intraday data).</p> <p>After this, RAPIDS executes the requested <code>PROVIDER</code> script that computes behavioral features per time segment instance. After every feature is computed, they are joined per sensor, per participant, and study. Visualizations are built based on raw data or based on calculated features. </p> <p> Data stream flow in RAPIDS </p> Is my data private? <p>Absolutely, you are processing your data with your own copy of RAPIDS in your laptop, server, or computer cluster, so neither we nor anyone else can access your datasets.</p> Do I need to have coding skills to use RAPIDS? <p>If you want to extract the behavioral features or visualizations that RAPIDS offers out of the box, the answer is no. However, you need to be comfortable running commands in your terminal and familiar with editing YAML files and CSV files.</p> <p>If you want to add support for new data streams or behavioral features, you need to be familiar with R or Python.</p> Is RAPIDS open-source or free? <p>Yes, RAPIDS is both open-source and free.</p> How do I cite RAPIDS? <p>Please refer to our Citation guide; depending on what parts of RAPIDS you used, we also ask you to cite the work of other authors that shared their work.</p> I have a lot of data, can RAPIDS handle it/ is RAPIDS fast enough? <p>Yes, we use Snakemake under the hood, so you can automatically distribute RAPIDS execution over multiple cores or clusters. RAPIDS processes data per sensor and participant, so it can take advantage of this parallel processing.</p> What are the advantages of using RAPIDS over implementing my own analysis code? <p>We believe RAPIDS can benefit your analysis in several ways:</p> <ul> <li>RAPIDS has more than 250 behavioral features available, many of them tested and used by other researchers.</li> <li>RAPIDS can extract features in dynamic time segments (for example, every x minutes, x hours, x days, x weeks, x months, etc.). This is handy because you don\u2019t have to deal with time zones, daylight saving changes, or date arithmetic.</li> <li>Your analysis is less prone to errors. Every participant sensor dataset is analyzed in the same way and isolated from each other.</li> <li>If you have lots of data, out-of-the-box parallel execution will speed up your analysis, and if your computer crashes, RAPIDS will start from where it left off. </li> <li>You can publish your analysis code along with your papers and be sure it will run exactly as it does on your computer.</li> <li>You can still add your own behavioral features and data streams if you need to, and the community will be able to reuse your work.</li> </ul>"},{"location":"setup/overview/#data-streams","title":"Data Streams","text":"Can I process smartphone data collected with Beiwe, PurpleRobot, or app X? <p>Yes, but you need to add a new data stream to RAPIDS (a new <code>format.yaml</code> and container script in R or Python). Follow this tutorial.  Open a new discussion in Github if you have any questions.</p> <p>If you do so, let us know so we can integrate your work into RAPIDS.</p> Can I process data from Oura Rings, Actigraphs, or wearable X? <p>The only wearables we support at the moment are Empatica and Fitbit. However, get in touch if you need to process data from a different wearable. We have limited resources, so we add support for additional devices on an as-needed basis, but we would be happy to collaborate. Open a new discussion in Github if you have any questions.</p> Can I process smartphone or wearable data stored in PostgreSQL, Oracle, SQLite, CSV files, or data container X? <p>Yes, but you need to add a new data stream to RAPIDS (a new <code>format.yaml</code> and container script in R or Python). Follow this tutorial. If you are processing data streams we already support like AWARE, Fitbit, or Empatica and are just connecting to a different container, you can reuse their <code>format.yaml</code> and only implement a new container script. Open a new discussion in Github if you have any questions.</p> <p>If you do so, let us know so we can integrate your work into RAPIDS.</p> I have participants that live in different time zones and some that travel; can RAPIDS handle this? <p>Yes, RAPIDS can handle single or multiple timezones per participant. You can use time zone data collected by smartphones or collected by hand.</p> Some of my participants used more than one device during my study; can RAPIDS handle this? <p>Yes, you can link more than one smartphone or wearable device to a single participant. RAPIDS will merge them and sort them automatically.</p> Some of my participants switched from Android to iOS or vice-versa during my study; can RAPIDS handle this? <p>Yes, data from multiple smartphones can be linked to a single participant. All iOS data is converted to Android data before merging it.</p>"},{"location":"setup/overview/#extending-rapids","title":"Extending RAPIDS","text":"Can I add my own behavioral features/digital biomarkers? <p>Yes, you can implement your own features in R or Python following this tutorial </p> Can I extract behavioral features based on two or more sensors? <p>Yes, we do this for <code>PHONE_DATA_YIELD</code> (combines all phone sensors), <code>PHONE_LOCATIONS</code> (combines location and data yield data), <code>PHONE_APPLICATIONS_BACKGROUND</code> (combines screen and app usage data), and <code>FITBIT_INTRADAY_STEPS</code> (combines Fitbit and sleep and step data). </p> <p>However, we haven\u2019t come up with a user-friendly way to configure this, and currently, we join sensors on a case-by-case basis. This is mainly because not enough users have needed this functionality so far. Get in touch, and we can set it up together; the more use cases we are aware of, the easier it will be to integrate this into RAPIDS.</p> I know how to program in Python or R but not both. Can I still use or extend RAPIDS? <p>Yes, you don\u2019t need to write any code to use RAPIDS out of the box. If you need to add support for new data streams  or behavioral features you can use scripts in either language.</p> I have scripts that clean raw data from X sensor, can I use them with RAPIDS? <p>Yes, you can add them as a <code>[MUTATION][SCRIPT]</code> in the <code>format.yaml</code> of the data stream you are using. You will add a <code>main</code> function that will receive a data frame with the raw data for that sensor that, in turn, will be used to compute behavioral features.</p>"},{"location":"snippets/aware_format/","title":"Aware format","text":"<p>If you collected sensor data with the vanilla (original) AWARE mobile clients, you shouldn\u2019t need to modify this format (described below). </p> <p>Remember that a format maps and transforms columns in your raw data stream to the mandatory columns RAPIDS needs.</p> <p>The yaml file that describes the format of this data stream is at: <pre><code>src/data/streams/aware_csv/format.yaml\n</code></pre></p> <p>For some sensors, we need to transform iOS data into Android format; you can refer to OS complex mapping for learn how this works.</p> <p>Hint</p> <p>The mappings in this stream (RAPIDS/Stream) are the same names because AWARE data was the first stream RAPIDS supported, meaning that it considers AWARE column names the default.</p> PHONE_ACCELEROMETER ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_VALUES_0 double_values_0 DOUBLE_VALUES_1 double_values_1 DOUBLE_VALUES_2 double_values_2 <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_ACTIVITY_RECOGNITION ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id ACTIVITY_NAME activity_name ACTIVITY_TYPE activity_type CONFIDENCE confidence <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id ACTIVITY_NAME FLAG_TO_MUTATE ACTIVITY_TYPE FLAG_TO_MUTATE CONFIDENCE FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column ACTIVITIES activities CONFIDENCE confidence <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/activity_recogniton_ios_unification.R\n</code></pre> <p>Note</p> <p>For RAPIDS columns of <code>ACTIVITY_NAME</code> and <code>ACTIVITY_TYPE</code>:</p> <ul> <li>if stream\u2019s <code>activities</code> field is automotive, set <code>ACTIVITY_NAME</code> = in_vehicle and <code>ACTIVITY_TYPE</code> = 0</li> <li>if stream\u2019s <code>activities</code> field is cycling, set <code>ACTIVITY_NAME</code> = on_bicycle and <code>ACTIVITY_TYPE</code> = 1</li> <li>if stream\u2019s <code>activities</code> field is walking, set <code>ACTIVITY_NAME</code> = walking and <code>ACTIVITY_TYPE</code> = 7</li> <li>if stream\u2019s <code>activities</code> field is running, set <code>ACTIVITY_NAME</code> = running and <code>ACTIVITY_TYPE</code> = 8</li> <li>if stream\u2019s <code>activities</code> field is stationary, set <code>ACTIVITY_NAME</code> = still and <code>ACTIVITY_TYPE</code> = 3</li> <li>if stream\u2019s <code>activities</code> field is unknown, set <code>ACTIVITY_NAME</code> = unknown and  <code>ACTIVITY_TYPE</code> = 4</li> </ul> <p>For RAPIDS <code>CONFIDENCE</code> column:</p> <ul> <li>if stream\u2019s <code>confidence</code> field is 0, set <code>CONFIDENCE</code> = 0</li> <li>if stream\u2019s <code>confidence</code> field is 1, set <code>CONFIDENCE</code> = 50</li> <li>if stream\u2019s <code>confidence</code> field is 2, set <code>CONFIDENCE</code> = 100</li> </ul> PHONE_APPLICATIONS_CRASHES ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name APPLICATION_NAME application_name APPLICATION_VERSION application_version ERROR_SHORT error_short ERROR_LONG error_long ERROR_CONDITION error_condition IS_SYSTEM_APP is_system_app <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_APPLICATIONS_FOREGROUND ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name APPLICATION_NAME application_name IS_SYSTEM_APP is_system_app <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_APPLICATIONS_NOTIFICATIONS ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name APPLICATION_NAME application_name TEXT text SOUND sound VIBRATE vibrate DEFAULTS defaults FLAGS flags <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_BATTERY ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BATTERY_STATUS battery_status BATTERY_LEVEL battery_level BATTERY_SCALE battery_scale <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS Client V1 <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BATTERY_STATUS FLAG_TO_MUTATE BATTERY_LEVEL battery_level BATTERY_SCALE battery_scale <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column BATTERY_STATUS battery_status <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/battery_ios_unification.R\n</code></pre> <p>Note</p> <p>For RAPIDS <code>BATTERY_STATUS</code> column:</p> <ul> <li>if stream\u2019s <code>battery_status</code> field is 3, set <code>BATTERY_STATUS</code> = 5 (full status)</li> <li>if stream\u2019s <code>battery_status</code> field is 1, set <code>BATTERY_STATUS</code> = 3 (discharge)</li> </ul> IOS Client V2 <p>Same as ANDROID</p> PHONE_BLUETOOTH ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id BT_ADDRESS bt_address BT_NAME bt_name BT_RSSI bt_rssi <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Only old iOS versions supported this sensor (same mapping as Android).</p> PHONE_CALLS ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id CALL_TYPE call_type CALL_DURATION call_duration TRACE trace <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id CALL_TYPE FLAG_TO_MUTATE CALL_DURATION call_duration TRACE trace <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column CALL_TYPE call_type <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/calls_ios_unification.R\n</code></pre> <p>Note</p> <p>We transform iOS call logs into Android\u2019s format. iOS stores call status: 1=incoming, 2=connected, 3=dialing, 4=disconnected, as opposed to Android\u2019s events: 1=incoming, 2=outgoing, 3=missed. </p> <p>We follow this algorithm to convert iOS call data (there are some inaccuracies in the way we handle sequences, see new rules below):</p> <ul> <li>Search for the disconnected (4) status as it is common to all calls</li> <li>Group all events that preceded every status 4</li> <li>We convert every 1,2,4 (or 2,1,4) sequence to an incoming call</li> <li>We convert every 3,2,4 (or 2,3,4) sequence to an outgoing call</li> <li>We convert every 1,4 or 3,4 sequence to a missed call (either incoming or outgoing)</li> <li>We set the duration of the call to be the sum of every status (dialing/ringing to hangup) as opposed to the duration of the last status (pick up to hang up)</li> </ul> <p>Tested with an Android (OnePlus 7T) and an iPhone XR</p> Call type Android (duration) iOS (duration) New Rule Outgoing missed ended by me 2 (0) 3,4 (0,X) 3,4 is converted to 2 with duration 0 Outgoing missed ended by them 2(0) 3,2,4 (0,X,X2) 3,2,4 is converted to 2 with duration X2* Incoming missed ended by me NA** 1,4 (0,X) 1,4 is converted to 3 with duration 0 Incoming missed ended by them 3(0) 1,4 (0,X) 1,4 is converted to 3 with duration 0 Outgoing answered 2(X excluding dialing time) 3,2,4 (0,X,X2) 3,2,4 is converted to 2 with duration X2 Incoming answered 1(X excluding dialing time) 1,2,4 (0,X,X2) 1,2,4 is converted to 1 with duration X2 <p>.* There is no way to differentiate an outgoing missed call ended by them from an outgoing answered call because the phone goes directly to voice mail and it counts as call time (essentially the voice mail answered).</p> <p>.** Android does not record incoming missed calls ended by the participant, just those ended by the person calling or ignored by the participant.</p> PHONE_CONVERSATION ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_ENERGY double_energy INFERENCE inference DOUBLE_CONVO_START double_convo_start DOUBLE_CONVO_END double_convo_end <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_ENERGY double_energy INFERENCE inference DOUBLE_CONVO_START FLAG_TO_MUTATE DOUBLE_CONVO_END FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column DOUBLE_CONVO_START double_convo_start DOUBLE_CONVO_END double_convo_end <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/conversation_ios_timestamp.R\n</code></pre> <p>Note</p> <p>For RAPIDS columns of <code>DOUBLE_CONVO_START</code> and <code>DOUBLE_CONVO_END</code>:</p> <ul> <li>if stream\u2019s <code>double_convo_start</code> field is smaller than 9999999999, it is in seconds instead of milliseconds. Set <code>DOUBLE_CONVO_START</code> = 1000 * <code>double_convo_start</code>.</li> <li>if stream\u2019s <code>double_convo_end</code> field is smaller than 9999999999, it is in seconds instead of milliseconds. Set <code>DOUBLE_CONVO_END</code> = 1000 * <code>double_convo_end</code>.</li> </ul> PHONE_KEYBOARD ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id PACKAGE_NAME package_name BEFORE_TEXT before_text CURRENT_TEXT current_text IS_PASSWORD is_password <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_LIGHT ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_LIGHT_LUX double_light_lux ACCURACY accuracy <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_LOCATIONS ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id DOUBLE_LATITUDE double_latitude DOUBLE_LONGITUDE double_longitude DOUBLE_BEARING double_bearing DOUBLE_SPEED double_speed DOUBLE_ALTITUDE double_altitude PROVIDER provider ACCURACY accuracy <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_LOG ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id LOG_MESSAGE log_message <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_MESSAGES ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id MESSAGE_TYPE message_type TRACE trace <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>This sensor is not supported by iOS devices.</p> PHONE_SCREEN ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id SCREEN_STATUS screen_status <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id SCREEN_STATUS FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS</li> </ul> Script column Stream column SCREEN_STATUS screen_status <ul> <li>SCRIPTS</li> </ul> <pre><code>src/data/streams/mutations/phone/aware/screen_ios_unification.R\n</code></pre> <p>Note</p> <p>For <code>SCREEN_STATUS</code> RAPIDS column:</p> <ul> <li>if stream\u2019s <code>screen_status</code> field is 2 (lock episode), set <code>SCREEN_STATUS</code> = 0 (off episode).</li> </ul> PHONE_WIFI_CONNECTED ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id MAC_ADDRESS mac_address SSID ssid BSSID bssid <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Same as ANDROID</p> PHONE_WIFI_VISIBLE ANDROID <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP timestamp DEVICE_ID device_id SSID ssid BSSID bssid SECURITY security FREQUENCY frequency RSSI rssi <p>MUTATION</p> <ul> <li>COLUMN_MAPPINGS (None)</li> <li>SCRIPTS (None)</li> </ul> IOS <p>Only old iOS versions supported this sensor (same mapping as Android).</p>"},{"location":"snippets/database/","title":"Database","text":"Setting up a DATABASE_GROUP and its connection credentials. <ol> <li> <p>If you haven\u2019t done so, create an empty file called <code>credentials.yaml</code> in your RAPIDS root directory: </p> </li> <li> <p>Add the following lines to <code>credentials.yaml</code> and replace your database-specific credentials (user, password, host, and database):</p> <pre><code>MY_GROUP:\n  database: MY_DATABASE\n  host: MY_HOST\n  password: MY_PASSWORD\n  port: 3306\n  user: MY_USER\n</code></pre> </li> <li> <p>Notes</p> <ol> <li> <p>The label <code>[MY_GROUP]</code> is arbitrary but it has to match the <code>[DATABASE_GROUP]</code> attribute of the data stream you choose to use.</p> </li> <li> <p>Indentation matters</p> </li> <li> <p>You can have more than one credentials group in <code>credentials.yaml</code></p> </li> </ol> </li> </ol> Upgrading from <code>./.env</code> from RAPIDS 0.x <p>In RAPIDS versions 0.x, database credentials were stored in a <code>./.env</code> file. If you are migrating from that type of file, you have two options:</p> <ol> <li> <p>Migrate your credentials by hand:</p> change .env format <pre><code>[MY_GROUP]\nuser=MY_USER\npassword=MY_PASSWORD\nhost=MY_HOST\nport=3306\ndatabase=MY_DATABASE\n</code></pre> to credentials.yaml format <pre><code>MY_GROUP:\n  user: MY_USER\n  password: MY_PASSWORD\n  host: MY_HOST\n  port: 3306\n  database: MY_DATABASE\n</code></pre> </li> <li> <p>Use the migration script we provide (make sure your conda environment is active):</p> <pre><code>python tools/update_format_env.py\n</code></pre> </li> </ol> Connecting to localhost (host machine) from inside our docker container. <p>If you are using RAPIDS\u2019 docker container and Docker-for-mac or Docker-for-Windows 18.03+, you can connect to a MySQL database in your host machine using <code>host.docker.internal</code> instead of <code>127.0.0.1</code> or <code>localhost</code>. In a Linux host, you need to run our docker container using <code>docker run --network=\"host\" -d moshiresearch/rapids:latest</code> and then <code>127.0.0.1</code> will point to your host machine.</p>"},{"location":"snippets/feature_introduction_example/","title":"Feature introduction example","text":"<ol> <li> <p>Sensor section</p> <p>Each sensor (accelerometer, screen, etc.) of every supported device (smartphone, Fitbit, etc.) has a section in the <code>config.yaml</code> with <code>parameters</code> and feature <code>PROVIDERS</code>.</p> </li> <li> <p>Sensor Parameters. </p> <p>Each sensor section has one or more parameters. These are parameters that affect different aspects of how the raw data is pulled, and processed.</p> <p>The <code>CONTAINER</code> parameter exists for every sensor, but some sensors will have extra parameters like <code>[PHONE_LOCATIONS]</code>.</p> <p>We explain these parameters in a table at the top of each sensor documentation page.</p> </li> <li> <p>Sensor Providers</p> <p>Each object in this list represents a feature <code>PROVIDER</code>. Each sensor can have zero, one, or more providers.</p> <p>A <code>PROVIDER</code> is a script that creates behavioral features for a specific sensor. Providers are created by the core RAPIDS team or by the community, which are named after its first author like [PHONE_LOCATIONS][DORYAB].</p> <p>In this example, there are two accelerometer feature providers <code>RAPIDS</code> and <code>PANDA</code>.</p> </li> <li> <p><code>PROVIDER</code> Parameters</p> <p>Each <code>PROVIDER</code> has parameters that affect the computation of the behavioral features it offers.</p> <p>These parameters include at least a <code>[COMPUTE]</code> flag that you switch to <code>True</code> to extract a provider\u2019s behavioral features. </p> <p>We explain every provider\u2019s parameter in a table under the <code>Parameters description</code> heading on each provider documentation page.</p> </li> <li> <p><code>PROVIDER</code> Features</p> <p>Each <code>PROVIDER</code> offers a set of behavioral features.</p> <p>These features are grouped in an array for some providers, like those for <code>RAPIDS</code> provider. For others, they are grouped in a collection of arrays, like those for <code>PANDAS</code> provider.</p> <p>In either case, you can delete the features you are not interested in, and they will not be included in the sensor\u2019s output feature file. </p> <p>We explain each behavioral feature in a table under the <code>Features description</code> heading on each provider documentation page.</p> </li> <li> <p><code>PROVIDER</code> script</p> <p>Each <code>PROVIDER</code> has a <code>SRC_SCRIPT</code> that points to the script implementing its behavioral features.</p> <p>It has to be a relative path from RAPIDS\u2019 root folder and the script\u2019s parent folder should be named after the provider, e.g. <code>panda</code>.</p> </li> </ol>"},{"location":"snippets/jsonfitbit_format/","title":"Jsonfitbit format","text":"<p>The <code>format.yaml</code> maps and transforms columns in your raw data stream to the mandatory columns RAPIDS needs for Fitbit sensors. This file is at:</p> <pre><code>src/data/streams/fitbitjson_csv/format.yaml\n</code></pre> <p>If you want RAPIDS to process Fitbit sensor data using this stream, you will need to map <code>DEVICE_ID</code> and <code>JSON_FITBIT_COLUMN</code> to your own raw data columns inside each sensor section in <code>format.yaml</code>.</p> FITBIT_HEARTRATE_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column LOCAL_DATE_TIME FLAG_TO_MUTATE DEVICE_ID device_id HEARTRATE_DAILY_RESTINGHR FLAG_TO_MUTATE HEARTRATE_DAILY_CALORIESOUTOFRANGE FLAG_TO_MUTATE HEARTRATE_DAILY_CALORIESFATBURN FLAG_TO_MUTATE HEARTRATE_DAILY_CALORIESCARDIO FLAG_TO_MUTATE HEARTRATE_DAILY_CALORIESPEAK FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_heartrate_summary_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p>All columns except <code>DEVICE_ID</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the raw data RAPIDS expects for this data stream device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-07\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:1200.6102,\u201dmax\u201d:88,\u201dmin\u201d:31,\u201dminutes\u201d:1058,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:760.3020,\u201dmax\u201d:120,\u201dmin\u201d:86,\u201dminutes\u201d:366,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:15.2048,\u201dmax\u201d:146,\u201dmin\u201d:120,\u201dminutes\u201d:2,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:221,\u201dmin\u201d:148,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:72}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:68},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:67},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:67},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-08\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:1100.1120,\u201dmax\u201d:89,\u201dmin\u201d:30,\u201dminutes\u201d:921,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:660.0012,\u201dmax\u201d:118,\u201dmin\u201d:82,\u201dminutes\u201d:361,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:23.7088,\u201dmax\u201d:142,\u201dmin\u201d:108,\u201dminutes\u201d:3,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:221,\u201dmin\u201d:148,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:70}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:77},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:75},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:73},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-09\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:750.3615,\u201dmax\u201d:77,\u201dmin\u201d:30,\u201dminutes\u201d:851,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:734.1516,\u201dmax\u201d:107,\u201dmin\u201d:77,\u201dminutes\u201d:550,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:131.8579,\u201dmax\u201d:130,\u201dmin\u201d:107,\u201dminutes\u201d:29,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:220,\u201dmin\u201d:130,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:69}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:90},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:89},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:88},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} </li> </ul> FITBIT_HEARTRATE_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column LOCAL_DATE_TIME FLAG_TO_MUTATE DEVICE_ID device_id HEARTRATE FLAG_TO_MUTATE HEARTRATE_ZONE FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_heartrate_intraday_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p>All columns except <code>DEVICE_ID</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the raw data RAPIDS expects for this data stream device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-07\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:1200.6102,\u201dmax\u201d:88,\u201dmin\u201d:31,\u201dminutes\u201d:1058,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:760.3020,\u201dmax\u201d:120,\u201dmin\u201d:86,\u201dminutes\u201d:366,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:15.2048,\u201dmax\u201d:146,\u201dmin\u201d:120,\u201dminutes\u201d:2,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:221,\u201dmin\u201d:148,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:72}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:68},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:67},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:67},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-08\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:1100.1120,\u201dmax\u201d:89,\u201dmin\u201d:30,\u201dminutes\u201d:921,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:660.0012,\u201dmax\u201d:118,\u201dmin\u201d:82,\u201dminutes\u201d:361,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:23.7088,\u201dmax\u201d:142,\u201dmin\u201d:108,\u201dminutes\u201d:3,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:221,\u201dmin\u201d:148,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:70}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:77},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:75},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:73},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201cactivities-heart\u201d:[{\u201cdateTime\u201d:\u201d2020-10-09\u201d,\u201dvalue\u201d:{\u201ccustomHeartRateZones\u201d:[],\u201dheartRateZones\u201d:[{\u201ccaloriesOut\u201d:750.3615,\u201dmax\u201d:77,\u201dmin\u201d:30,\u201dminutes\u201d:851,\u201dname\u201d:\u201dOut of Range\u201d},{\u201ccaloriesOut\u201d:734.1516,\u201dmax\u201d:107,\u201dmin\u201d:77,\u201dminutes\u201d:550,\u201dname\u201d:\u201dFat Burn\u201d},{\u201ccaloriesOut\u201d:131.8579,\u201dmax\u201d:130,\u201dmin\u201d:107,\u201dminutes\u201d:29,\u201dname\u201d:\u201dCardio\u201d},{\u201ccaloriesOut\u201d:0,\u201dmax\u201d:220,\u201dmin\u201d:130,\u201dminutes\u201d:0,\u201dname\u201d:\u201dPeak\u201d}],\u201drestingHeartRate\u201d:69}}],\u201dactivities-heart-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:90},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:89},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:88},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} </li> </ul> FITBIT_SLEEP_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME FLAG_TO_MUTATE LOCAL_START_DATE_TIME FLAG_TO_MUTATE LOCAL_END_DATE_TIME FLAG_TO_MUTATE DEVICE_ID device_id EFFICIENCY FLAG_TO_MUTATE MINUTES_AFTER_WAKEUP FLAG_TO_MUTATE MINUTES_ASLEEP FLAG_TO_MUTATE MINUTES_AWAKE FLAG_TO_MUTATE MINUTES_TO_FALL_ASLEEP FLAG_TO_MUTATE MINUTES_IN_BED FLAG_TO_MUTATE IS_MAIN_SLEEP FLAG_TO_MUTATE TYPE FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_sleep_summary_json.py\n- src/data/streams/mutations/fitbit/add_local_date_time.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p>Fitbit API has two versions for sleep data, v1 and v1.2. We support both but ignore v1\u2019s <code>count_awake</code>, <code>duration_awake</code>, and <code>count_awakenings</code>, <code>count_restless</code>, <code>duration_restless</code> columns.</p> <p>All columns except <code>DEVICE_ID</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the expected raw data device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-10\u201d,\u201dduration\u201d:3600000,\u201defficiency\u201d:92,\u201dendTime\u201d:\u201d2020-10-10T16:37:00.000\u201d,\u201dinfoCode\u201d:2,\u201disMainSleep\u201d:false,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-10T15:36:30.000\u201d,\u201dlevel\u201d:\u201drestless\u201d,\u201dseconds\u201d:60},{\u201cdateTime\u201d:\u201d2020-10-10T15:37:30.000\u201d,\u201dlevel\u201d:\u201dasleep\u201d,\u201dseconds\u201d:660},{\u201cdateTime\u201d:\u201d2020-10-10T15:48:30.000\u201d,\u201dlevel\u201d:\u201drestless\u201d,\u201dseconds\u201d:60},\u2026], \u201csummary\u201d:{\u201casleep\u201d:{\u201ccount\u201d:0,\u201dminutes\u201d:56},\u201dawake\u201d:{\u201ccount\u201d:0,\u201dminutes\u201d:0},\u201drestless\u201d:{\u201ccount\u201d:3,\u201dminutes\u201d:4}}},\u201dlogId\u201d:26315914306,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:55,\u201dminutesAwake\u201d:5,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-10T15:36:30.000\u201d,\u201dtimeInBed\u201d:60,\u201dtype\u201d:\u201dclassic\u201d},{\u201cdateOfSleep\u201d:\u201d2020-10-10\u201d,\u201dduration\u201d:22980000,\u201defficiency\u201d:88,\u201dendTime\u201d:\u201d2020-10-10T08:10:00.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-10T01:46:30.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:420},{\u201cdateTime\u201d:\u201d2020-10-10T01:53:30.000\u201d,\u201dlevel\u201d:\u201ddeep\u201d,\u201dseconds\u201d:1230},{\u201cdateTime\u201d:\u201d2020-10-10T02:14:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:360},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:3,\u201dminutes\u201d:92,\u201dthirtyDayAvgMinutes\u201d:0},\u201dlight\u201d:{\u201ccount\u201d:29,\u201dminutes\u201d:193,\u201dthirtyDayAvgMinutes\u201d:0},\u201drem\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:33,\u201dthirtyDayAvgMinutes\u201d:0},\u201dwake\u201d:{\u201ccount\u201d:28,\u201dminutes\u201d:65,\u201dthirtyDayAvgMinutes\u201d:0}}},\u201dlogId\u201d:26311786557,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:318,\u201dminutesAwake\u201d:65,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-10T01:46:30.000\u201d,\u201dtimeInBed\u201d:383,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:92,\u201dlight\u201d:193,\u201drem\u201d:33,\u201dwake\u201d:65},\u201dtotalMinutesAsleep\u201d:373,\u201dtotalSleepRecords\u201d:2,\u201dtotalTimeInBed\u201d:443}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-11\u201d,\u201dduration\u201d:41640000,\u201defficiency\u201d:89,\u201dendTime\u201d:\u201d2020-10-11T11:47:00.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-11T00:12:30.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:450},{\u201cdateTime\u201d:\u201d2020-10-11T00:20:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:870},{\u201cdateTime\u201d:\u201d2020-10-11T00:34:30.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:780},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:52,\u201dthirtyDayAvgMinutes\u201d:62},\u201dlight\u201d:{\u201ccount\u201d:32,\u201dminutes\u201d:442,\u201dthirtyDayAvgMinutes\u201d:364},\u201drem\u201d:{\u201ccount\u201d:6,\u201dminutes\u201d:68,\u201dthirtyDayAvgMinutes\u201d:58},\u201dwake\u201d:{\u201ccount\u201d:29,\u201dminutes\u201d:132,\u201dthirtyDayAvgMinutes\u201d:94}}},\u201dlogId\u201d:26589710670,\u201dminutesAfterWakeup\u201d:1,\u201dminutesAsleep\u201d:562,\u201dminutesAwake\u201d:132,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-11T00:12:30.000\u201d,\u201dtimeInBed\u201d:694,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:52,\u201dlight\u201d:442,\u201drem\u201d:68,\u201dwake\u201d:132},\u201dtotalMinutesAsleep\u201d:562,\u201dtotalSleepRecords\u201d:1,\u201dtotalTimeInBed\u201d:694}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-12\u201d,\u201dduration\u201d:28980000,\u201defficiency\u201d:93,\u201dendTime\u201d:\u201d2020-10-12T09:34:30.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-12T01:31:00.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:600},{\u201cdateTime\u201d:\u201d2020-10-12T01:41:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:60},{\u201cdateTime\u201d:\u201d2020-10-12T01:42:00.000\u201d,\u201dlevel\u201d:\u201ddeep\u201d,\u201dseconds\u201d:2340},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:63,\u201dthirtyDayAvgMinutes\u201d:59},\u201dlight\u201d:{\u201ccount\u201d:27,\u201dminutes\u201d:257,\u201dthirtyDayAvgMinutes\u201d:364},\u201drem\u201d:{\u201ccount\u201d:5,\u201dminutes\u201d:94,\u201dthirtyDayAvgMinutes\u201d:58},\u201dwake\u201d:{\u201ccount\u201d:24,\u201dminutes\u201d:69,\u201dthirtyDayAvgMinutes\u201d:95}}},\u201dlogId\u201d:26589710673,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:415,\u201dminutesAwake\u201d:68,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-12T01:31:00.000\u201d,\u201dtimeInBed\u201d:483,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:63,\u201dlight\u201d:257,\u201drem\u201d:94,\u201dwake\u201d:69},\u201dtotalMinutesAsleep\u201d:415,\u201dtotalSleepRecords\u201d:1,\u201dtotalTimeInBed\u201d:483}} </li> </ul> FITBIT_SLEEP_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME FLAG_TO_MUTATE DEVICE_ID device_id TYPE_EPISODE_ID FLAG_TO_MUTATE DURATION FLAG_TO_MUTATE IS_MAIN_SLEEP FLAG_TO_MUTATE TYPE FLAG_TO_MUTATE LEVEL FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_sleep_intraday_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p>Fitbit API has two versions for sleep data, v1 and v1.2, we support both.</p> <p>All columns except <code>DEVICE_ID</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the expected raw data device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-10\u201d,\u201dduration\u201d:3600000,\u201defficiency\u201d:92,\u201dendTime\u201d:\u201d2020-10-10T16:37:00.000\u201d,\u201dinfoCode\u201d:2,\u201disMainSleep\u201d:false,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-10T15:36:30.000\u201d,\u201dlevel\u201d:\u201drestless\u201d,\u201dseconds\u201d:60},{\u201cdateTime\u201d:\u201d2020-10-10T15:37:30.000\u201d,\u201dlevel\u201d:\u201dasleep\u201d,\u201dseconds\u201d:660},{\u201cdateTime\u201d:\u201d2020-10-10T15:48:30.000\u201d,\u201dlevel\u201d:\u201drestless\u201d,\u201dseconds\u201d:60},\u2026], \u201csummary\u201d:{\u201casleep\u201d:{\u201ccount\u201d:0,\u201dminutes\u201d:56},\u201dawake\u201d:{\u201ccount\u201d:0,\u201dminutes\u201d:0},\u201drestless\u201d:{\u201ccount\u201d:3,\u201dminutes\u201d:4}}},\u201dlogId\u201d:26315914306,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:55,\u201dminutesAwake\u201d:5,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-10T15:36:30.000\u201d,\u201dtimeInBed\u201d:60,\u201dtype\u201d:\u201dclassic\u201d},{\u201cdateOfSleep\u201d:\u201d2020-10-10\u201d,\u201dduration\u201d:22980000,\u201defficiency\u201d:88,\u201dendTime\u201d:\u201d2020-10-10T08:10:00.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-10T01:46:30.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:420},{\u201cdateTime\u201d:\u201d2020-10-10T01:53:30.000\u201d,\u201dlevel\u201d:\u201ddeep\u201d,\u201dseconds\u201d:1230},{\u201cdateTime\u201d:\u201d2020-10-10T02:14:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:360},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:3,\u201dminutes\u201d:92,\u201dthirtyDayAvgMinutes\u201d:0},\u201dlight\u201d:{\u201ccount\u201d:29,\u201dminutes\u201d:193,\u201dthirtyDayAvgMinutes\u201d:0},\u201drem\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:33,\u201dthirtyDayAvgMinutes\u201d:0},\u201dwake\u201d:{\u201ccount\u201d:28,\u201dminutes\u201d:65,\u201dthirtyDayAvgMinutes\u201d:0}}},\u201dlogId\u201d:26311786557,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:318,\u201dminutesAwake\u201d:65,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-10T01:46:30.000\u201d,\u201dtimeInBed\u201d:383,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:92,\u201dlight\u201d:193,\u201drem\u201d:33,\u201dwake\u201d:65},\u201dtotalMinutesAsleep\u201d:373,\u201dtotalSleepRecords\u201d:2,\u201dtotalTimeInBed\u201d:443}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-11\u201d,\u201dduration\u201d:41640000,\u201defficiency\u201d:89,\u201dendTime\u201d:\u201d2020-10-11T11:47:00.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-11T00:12:30.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:450},{\u201cdateTime\u201d:\u201d2020-10-11T00:20:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:870},{\u201cdateTime\u201d:\u201d2020-10-11T00:34:30.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:780},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:52,\u201dthirtyDayAvgMinutes\u201d:62},\u201dlight\u201d:{\u201ccount\u201d:32,\u201dminutes\u201d:442,\u201dthirtyDayAvgMinutes\u201d:364},\u201drem\u201d:{\u201ccount\u201d:6,\u201dminutes\u201d:68,\u201dthirtyDayAvgMinutes\u201d:58},\u201dwake\u201d:{\u201ccount\u201d:29,\u201dminutes\u201d:132,\u201dthirtyDayAvgMinutes\u201d:94}}},\u201dlogId\u201d:26589710670,\u201dminutesAfterWakeup\u201d:1,\u201dminutesAsleep\u201d:562,\u201dminutesAwake\u201d:132,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-11T00:12:30.000\u201d,\u201dtimeInBed\u201d:694,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:52,\u201dlight\u201d:442,\u201drem\u201d:68,\u201dwake\u201d:132},\u201dtotalMinutesAsleep\u201d:562,\u201dtotalSleepRecords\u201d:1,\u201dtotalTimeInBed\u201d:694}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 {\u201csleep\u201d:[{\u201cdateOfSleep\u201d:\u201d2020-10-12\u201d,\u201dduration\u201d:28980000,\u201defficiency\u201d:93,\u201dendTime\u201d:\u201d2020-10-12T09:34:30.000\u201d,\u201dinfoCode\u201d:0,\u201disMainSleep\u201d:true,\u201dlevels\u201d:{\u201cdata\u201d:[{\u201cdateTime\u201d:\u201d2020-10-12T01:31:00.000\u201d,\u201dlevel\u201d:\u201dwake\u201d,\u201dseconds\u201d:600},{\u201cdateTime\u201d:\u201d2020-10-12T01:41:00.000\u201d,\u201dlevel\u201d:\u201dlight\u201d,\u201dseconds\u201d:60},{\u201cdateTime\u201d:\u201d2020-10-12T01:42:00.000\u201d,\u201dlevel\u201d:\u201ddeep\u201d,\u201dseconds\u201d:2340},\u2026], \u201csummary\u201d:{\u201cdeep\u201d:{\u201ccount\u201d:4,\u201dminutes\u201d:63,\u201dthirtyDayAvgMinutes\u201d:59},\u201dlight\u201d:{\u201ccount\u201d:27,\u201dminutes\u201d:257,\u201dthirtyDayAvgMinutes\u201d:364},\u201drem\u201d:{\u201ccount\u201d:5,\u201dminutes\u201d:94,\u201dthirtyDayAvgMinutes\u201d:58},\u201dwake\u201d:{\u201ccount\u201d:24,\u201dminutes\u201d:69,\u201dthirtyDayAvgMinutes\u201d:95}}},\u201dlogId\u201d:26589710673,\u201dminutesAfterWakeup\u201d:0,\u201dminutesAsleep\u201d:415,\u201dminutesAwake\u201d:68,\u201dminutesToFallAsleep\u201d:0,\u201dstartTime\u201d:\u201d2020-10-12T01:31:00.000\u201d,\u201dtimeInBed\u201d:483,\u201dtype\u201d:\u201dstages\u201d}],\u201dsummary\u201d:{\u201cstages\u201d:{\u201cdeep\u201d:63,\u201dlight\u201d:257,\u201drem\u201d:94,\u201dwake\u201d:69},\u201dtotalMinutesAsleep\u201d:415,\u201dtotalSleepRecords\u201d:1,\u201dtotalTimeInBed\u201d:483}} </li> </ul> FITBIT_STEPS_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE DEVICE_ID device_id LOCAL_DATE_TIME FLAG_TO_MUTATE STEPS FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_steps_summary_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p><code>TIMESTAMP</code>, <code>LOCAL_DATE_TIME</code>, and <code>STEPS</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the expected raw data device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-07\u201d,\u201dvalue\u201d:\u201d1775\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:5},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:3},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:0},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-08\u201d,\u201dvalue\u201d:\u201d3201\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:14},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:11},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:10},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-09\u201d,\u201dvalue\u201d:\u201d998\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:0},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:0},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:0},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} </li> </ul> FITBIT_STEPS_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE DEVICE_ID device_id LOCAL_DATE_TIME FLAG_TO_MUTATE STEPS FLAG_TO_MUTATE <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS</p> Script column Stream column JSON_FITBIT_COLUMN fitbit_data </li> <li> <p>SCRIPTS</p> <pre><code>- src/data/streams/mutations/fitbit/parse_steps_intraday_json.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> <p>Note</p> <p><code>TIMESTAMP</code>, <code>LOCAL_DATE_TIME</code>, and <code>STEPS</code> are parsed from <code>JSON_FITBIT_COLUMN</code>. <code>JSON_FITBIT_COLUMN</code> is a string column containing the JSON objects returned by Fitbit\u2019s API. See an example of the raw data RAPIDS expects for this data stream:</p> Example of the expected raw data device_id fitbit_data a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-07\u201d,\u201dvalue\u201d:\u201d1775\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:5},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:3},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:0},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-08\u201d,\u201dvalue\u201d:\u201d3201\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:14},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:11},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:10},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u201cactivities-steps\u201d:[{\u201cdateTime\u201d:\u201d2020-10-09\u201d,\u201dvalue\u201d:\u201d998\u201d}],\u201dactivities-steps-intraday\u201d:{\u201cdataset\u201d:[{\u201ctime\u201d:\u201d00:00:00\u201d,\u201dvalue\u201d:0},{\u201ctime\u201d:\u201d00:01:00\u201d,\u201dvalue\u201d:0},{\u201ctime\u201d:\u201d00:02:00\u201d,\u201dvalue\u201d:0},\u2026],\u201ddatasetInterval\u201d:1,\u201ddatasetType\u201d:\u201dminute\u201d}} </li> </ul>"},{"location":"snippets/parsedfitbit_format/","title":"Parsedfitbit format","text":"<p>The <code>format.yaml</code> maps and transforms columns in your raw data stream to the mandatory columns RAPIDS needs for Fitbit sensors. This file is at:</p> <pre><code>src/data/streams/fitbitparsed_mysql/format.yaml\n</code></pre> <p>If you want to use this stream with your data, modify every sensor in <code>format.yaml</code> to map all columns except <code>TIMESTAMP</code> in <code>[RAPIDS_COLUMN_MAPPINGS]</code> to your raw data column names.</p> <p>All columns are mandatory; however, all except <code>device_id</code> and <code>local_date_time</code> can be empty if you don\u2019t have that data. Just have in mind that some features will be empty if some of these columns are empty.</p> FITBIT_HEARTRATE_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME local_date_time DEVICE_ID device_id HEARTRATE_DAILY_RESTINGHR heartrate_daily_restinghr HEARTRATE_DAILY_CALORIESOUTOFRANGE heartrate_daily_caloriesoutofrange HEARTRATE_DAILY_CALORIESFATBURN heartrate_daily_caloriesfatburn HEARTRATE_DAILY_CALORIESCARDIO heartrate_daily_caloriescardio HEARTRATE_DAILY_CALORIESPEAK heartrate_daily_caloriespeak <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> Example of the raw data RAPIDS expects for this data stream device_id local_date_time heartrate_daily_restinghr heartrate_daily_caloriesoutofrange heartrate_daily_caloriesfatburn heartrate_daily_caloriescardio heartrate_daily_caloriespeak a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 72 1200.6102 760.3020 15.2048 0 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-08 70 1100.1120 660.0012 23.7088 0 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-09 69 750.3615 734.1516 131.8579 0 FITBIT_HEARTRATE_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME local_date_time DEVICE_ID device_id HEARTRATE heartrate HEARTRATE_ZONE heartrate_zone <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> Example of the raw data RAPIDS expects for this data stream device_id local_date_time heartrate heartrate_zone a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:00:00 68 outofrange a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:01:00 67 outofrange a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:02:00 67 outofrange FITBIT_SLEEP_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME FLAG_TO_MUTATE LOCAL_START_DATE_TIME local_start_date_time LOCAL_END_DATE_TIME local_end_date_time DEVICE_ID device_id EFFICIENCY efficiency MINUTES_AFTER_WAKEUP minutes_after_wakeup MINUTES_ASLEEP minutes_asleep MINUTES_AWAKE minutes_awake MINUTES_TO_FALL_ASLEEP minutes_to_fall_asleep MINUTES_IN_BED minutes_in_bed IS_MAIN_SLEEP is_main_sleep TYPE type <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>- src/data/streams/mutations/fitbit/add_local_date_time.py\n- src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> <p>Fitbit API has two versions for sleep data, v1 and v1.2. We support both but ignore v1\u2019s <code>count_awake</code>, <code>duration_awake</code>, and <code>count_awakenings</code>, <code>count_restless</code>, <code>duration_restless</code> columns.</p> Example of the expected raw data device_id local_start_date_time local_end_date_time efficiency minutes_after_wakeup minutes_asleep minutes_awake minutes_to_fall_asleep minutes_in_bed is_main_sleep type a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-10 15:36:30 2020-10-10 16:37:00 92 0 55 5 0 60 0 classic a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-10 01:46:30 2020-10-10 08:10:00 88 0 318 65 0 383 1 stages a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-11 00:12:30 2020-10-11 11:47:00 89 1 562 132 0 694 1 stages a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-12 01:31:00 2020-10-12 09:34:30 93 0 415 68 0 483 1 stages FITBIT_SLEEP_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE LOCAL_DATE_TIME local_date_time DEVICE_ID device_id TYPE_EPISODE_ID type_episode_id DURATION duration IS_MAIN_SLEEP is_main_sleep TYPE type LEVEL level <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> <p>Fitbit API has two versions for sleep data, v1 and v1.2, we support both.</p> Example of the expected raw data device_id type_episode_id local_date_time duration level is_main_sleep type a748ee1a-1d0b-4ae9-9074-279a2b6ba524 0 2020-10-10 15:36:30 60 restless 0 classic a748ee1a-1d0b-4ae9-9074-279a2b6ba524 0 2020-10-10 15:37:30 660 asleep 0 classic a748ee1a-1d0b-4ae9-9074-279a2b6ba524 0 2020-10-10 15:48:30 60 restless 0 classic a748ee1a-1d0b-4ae9-9074-279a2b6ba524 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 1 2020-10-10 01:46:30 420 light 1 stages a748ee1a-1d0b-4ae9-9074-279a2b6ba524 1 2020-10-10 01:53:30 1230 deep 1 stages FITBIT_STEPS_SUMMARY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE DEVICE_ID device_id LOCAL_DATE_TIME local_date_time STEPS steps <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> Example of the expected raw data device_id local_date_time steps a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 1775 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-08 3201 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-09 998 FITBIT_STEPS_INTRADAY <p>RAPIDS_COLUMN_MAPPINGS</p> RAPIDS column Stream column TIMESTAMP FLAG_TO_MUTATE DEVICE_ID device_id LOCAL_DATE_TIME local_date_time STEPS steps <p>MUTATION</p> <ul> <li> <p>COLUMN_MAPPINGS (None)</p> </li> <li> <p>SCRIPTS </p> <pre><code>src/data/streams/mutations/fitbit/add_zero_timestamp.py\n</code></pre> </li> </ul> <p>Note</p> <p><code>add_zero_timestamp</code> adds an all-zero column called <code>timestamp</code> that will be filled in later in the pipeline by <code>readable_time.R</code> converting LOCAL_DATE_TIME to a unix timestamp taking into account single or multiple time zones.</p> Example of the expected raw data device_id local_date_time steps a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:00:00 5 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:01:00 3 a748ee1a-1d0b-4ae9-9074-279a2b6ba524 2020-10-07 00:02:00 0"},{"location":"visualizations/data-quality-visualizations/","title":"Data Quality Visualizations","text":"<p>We showcase these visualizations with a test study that collected 14 days of smartphone and Fitbit data from two participants (example01 and example02) and extracted behavioral features within five time segments (daily, morning, afternoon, evening, and night).</p> <p>Note</p> <p>Time segments (e.g. <code>daily</code>, <code>morning</code>, etc.) can have multiple instances (day 1, day 2, or morning 1, morning 2, etc.)</p>"},{"location":"visualizations/data-quality-visualizations/#1-histograms-of-phone-data-yield","title":"1. Histograms of phone data yield","text":"<p>RAPIDS provides two histograms that show the number of time segment instances that had a certain ratio of valid yielded minutes and hours, respectively. A valid yielded minute has at least 1 row of data from any smartphone sensor and a valid yielded hour contains at least M valid minutes.</p> <p>These plots can be used as a rough indication of the smartphone monitoring coverage during a study aggregated across all participants. For example, the figure below shows a valid yielded minutes histogram for daily segments and we can infer that the monitoring coverage was very good since almost all segments contain at least 90 to 100% of the expected sensed minutes.</p> <p>Example</p> <p>Click here to see an example of these interactive visualizations in HTML format</p> Histogram of the data yielded minute ratio for a single participant during five time segments (daily, morning, afternoon, evening, and night)"},{"location":"visualizations/data-quality-visualizations/#2-heatmaps-of-overall-data-yield","title":"2. Heatmaps of overall data yield","text":"<p>These heatmaps are a break down per time segment and per participant of Visualization 1. Heatmap\u2019s rows represent participants, columns represent time segment instances and the cells\u2019 color represent the valid yielded minute or hour ratio for a participant during a time segment instance.</p> <p>As different participants might join a study on different dates and time segments can be of any length and start on any day, the x-axis can be labelled with the absolute time of the start of each time segment instance or the time delta between the start of each time segment instance minus the start of the first instance. These plots provide a quick study overview of the monitoring coverage per person and per time segment. </p> <p>The figure below shows the heatmap of the valid yielded minute ratio for participants example01 and example02 on daily segments and, as we inferred from the previous histogram, the lighter (yellow) color on most time segment instances (cells) indicate both phones sensed data without interruptions for most days (except for the first and last ones).</p> [ABSOLUTE_TIME] <p>Example</p> <p>Click here to see an example of these interactive visualizations in HTML format</p> <p> Overall compliance heatmap for all participants </p> [RELATIVE_TIME] <p>Example</p> <p>Click here to see an example of these interactive visualizations in HTML format</p> <p> Overall compliance heatmap for all participants </p>"},{"location":"visualizations/data-quality-visualizations/#3-heatmap-of-recorded-phone-sensors","title":"3. Heatmap of recorded phone sensors","text":"<p>In these heatmaps rows represent time segment instances, columns represent minutes since the start of a time segment instance, and cells\u2019 color shows the number of phone sensors that logged at least one row of data during those 1-minute windows. </p> <p>RAPIDS creates a plot per participant and per time segment and can be used as a rough indication of whether time-based sensors were following their sensing schedule (e.g. if location was being sensed every 2 minutes).</p> <p>The figure below shows this heatmap for phone sensors collected by participant example01 in daily time segments from Apr 23<sup>rd</sup> 2020 to May 4<sup>th</sup> 2020. We can infer that for most of the monitoring time, the participant\u2019s phone logged data from at least 7 sensors each minute.</p> <p>Example</p> <p>Click here to see an example of these interactive visualizations in HTML format</p> Heatmap of the recorded phone sensors per minute and per time segment of a single participant"},{"location":"visualizations/data-quality-visualizations/#4-heatmap-of-sensor-row-count","title":"4. Heatmap of sensor row count","text":"<p>These heatmaps are a per-sensor breakdown of Visualization 1 and Visualization 2. Note that the second row (ratio of valid yielded minutes) of this heatmap matches the respective participant (bottom) row the screenshot in Visualization 2.</p> <p>In these heatmaps rows represent phone or Fitbit sensors, columns represent time segment instances and cell\u2019s color shows the normalized (0 to 1) row count of each sensor within a time segment instance. RAPIDS creates one heatmap per participant and they can be used to judge missing data on a per participant and per sensor basis.</p> <p>The figure below shows data for 14 phone sensors (including data yield) of example01\u2019s daily segments. From the top two rows, we can see that the phone was sensing data for most of the monitoring period (as suggested by Figure 3 and Figure 4). We can also infer how phone usage influenced the different sensor streams; there are peaks of screen events during the first day (Apr 23<sup>rd</sup>), peaks of location coordinates on Apr 26<sup>th</sup> and Apr 30<sup>th</sup>, and no sent or received SMS except for Apr 23<sup>rd</sup>, Apr 29<sup>th</sup> and Apr 30<sup>th</sup> (unlabeled row between screen and locations).</p> <p>Example</p> <p>Click here to see an example of these interactive visualizations in HTML format</p> Heatmap of the sensor row count per time segment of a single participant"},{"location":"visualizations/feature-visualizations/","title":"Feature Visualizations","text":""},{"location":"visualizations/feature-visualizations/#1-heatmap-correlation-matrix","title":"1. Heatmap Correlation Matrix","text":"<p>Columns and rows are the behavioral features computed in RAPIDS, cells\u2019 color represents the correlation coefficient between all days of data for every pair of features of all participants. </p> <p>The user can specify a minimum number of observations (time segment instances) required to compute the correlation between two features using the <code>MIN_ROWS_RATIO</code> parameter (0.5 by default) and the correlation method (Pearson, Spearman or Kendall) with the <code>CORR_METHOD</code> parameter. In addition, this plot can be configured to only display correlation coefficients above a threshold using the <code>CORR_THRESHOLD</code> parameter (0.1 by default).</p> <p>Example</p> <p>Click here to see an example of these interactive visualizations in HTML format</p> Correlation matrix heatmap for all the features of all participants"},{"location":"workflow-examples/analysis/","title":"Analysis Workflow Example","text":"<p>TL;DR</p> <ul> <li>In addition to using RAPIDS to extract behavioral features and create plots, you can structure your data analysis within RAPIDS (i.e. cleaning your features and creating ML/statistical models)</li> <li>We include an analysis example in RAPIDS that covers raw data processing, cleaning, feature extraction, machine learning modeling, and evaluation</li> <li>Use this example as a guide to structure your own analysis within RAPIDS</li> <li>RAPIDS analysis workflows are compatible with your favorite data science tools and libraries</li> <li>RAPIDS analysis workflows are reproducible and we encourage you to publish them along with your research papers</li> </ul>"},{"location":"workflow-examples/analysis/#why-should-i-integrate-my-analysis-in-rapids","title":"Why should I integrate my analysis in RAPIDS?","text":"<p>Even though the bulk of RAPIDS current functionality is related to the computation of behavioral features, we recommend RAPIDS as a complementary tool to create a mobile data analysis workflow. This is because the cookiecutter data science file organization guidelines, the use of Snakemake, the provided behavioral features, and the reproducible R and Python development environments allow researchers to divide an analysis workflow into small parts that can be audited, shared in an online repository, reproduced in other computers, and understood by other people as they follow a familiar and consistent structure. We believe these advantages outweigh the time needed to learn how to create these workflows in RAPIDS.</p> <p>We clarify that to create analysis workflows in RAPIDS, researchers can still use any data manipulation tools, editors, libraries or languages they are already familiar with. RAPIDS is meant to be the final destination of analysis code that was developed in interactive notebooks or stand-alone scripts. For example, a user can compute call and location features using RAPIDS, then, they can use Jupyter notebooks to explore feature cleaning approaches and once the cleaning code is final, it can be moved to RAPIDS as a new step in the pipeline. In turn, the output of this cleaning step can be used to explore machine learning models and once a model is finished, it can also be transferred to RAPIDS as a step of its own. The idea is that when it is time to publish a piece of research, a RAPIDS workflow can be shared in a public repository as is.</p> <p>In the following sections we share an example of how we structured an analysis workflow in RAPIDS.</p>"},{"location":"workflow-examples/analysis/#analysis-workflow-structure","title":"Analysis workflow structure","text":"<p>To accurately reflect the complexity of a real-world modeling scenario, we decided not to oversimplify this example. Importantly, every step in this example follows a basic structure: an input file and parameters are manipulated by an R or Python script that saves the results to an output file. Input files, parameters, output files and scripts are grouped into Snakemake rules that are described on <code>smk</code> files in the rules folder (we point the reader to the relevant rule(s) of each step). </p> <p>Researchers can use these rules and scripts as a guide to create their own as it is expected every modeling project will have different requirements, data and goals but ultimately most follow a similar chainned pattern.</p> <p>Hint</p> <p>The example\u2019s config file is <code>example_profile/example_config.yaml</code> and its Snakefile is in <code>example_profile/Snakefile</code>. The config file is already configured to process the sensor data as explained in Analysis workflow modules.</p>"},{"location":"workflow-examples/analysis/#description-of-the-study-modeled-in-our-analysis-workflow-example","title":"Description of the study modeled in our analysis workflow example","text":"<p>Our example is based on a hypothetical study that recruited 2 participants that underwent surgery and collected mobile data for at least one week before and one week after the procedure. Participants wore a Fitbit device and installed the AWARE client in their personal Android and iOS smartphones to collect mobile data 24/7. In addition, participants completed daily severity ratings of 12 common symptoms on a scale from 0 to 10 that we summed up into a daily symptom burden score. </p> <p>The goal of this workflow is to find out if we can predict the daily symptom burden score of a participant. Thus, we framed this question as a binary classification problem with two classes, high and low symptom burden based on the scores above and below average of each participant. We also want to compare the performance of individual (personalized) models vs a population model. </p> <p>In total, our example workflow has nine steps that are in charge of sensor data preprocessing, feature extraction, feature cleaning, machine learning model training and model evaluation (see figure below). We ship this workflow with RAPIDS and share files with test data in an Open Science Framework repository. </p> Modules of RAPIDS example workflow, from raw data to model evaluation"},{"location":"workflow-examples/analysis/#configure-and-run-the-analysis-workflow-example","title":"Configure and run the analysis workflow example","text":"<ol> <li>Install RAPIDS</li> <li>Unzip the CSV files inside rapids_example_csv.zip in <code>data/external/example_workflow/*.csv</code>.</li> <li>Create the participant files for this example by running:     <pre><code>./rapids -j1 create_example_participant_files\n</code></pre></li> <li>Run the example pipeline with:     <pre><code>./rapids -j1 --profile example_profile\n</code></pre></li> </ol> <p>Note you will see a lot of warning messages, you can ignore them since they happen because we ran ML algorithms with a small fake dataset.</p>"},{"location":"workflow-examples/analysis/#modules-of-our-analysis-workflow-example","title":"Modules of our analysis workflow example","text":"1. Feature extraction <p>We extract daily behavioral features for data yield, received and sent messages, missed, incoming and outgoing calls, resample fused location data using Doryab provider, activity recognition, battery, Bluetooth, screen, light, applications foreground, conversations, Wi-Fi connected, Wi-Fi visible, Fitbit heart rate summary and intraday data, Fitbit sleep summary data, and Fitbit step summary and intraday data without excluding sleep periods with an active bout threshold of 10 steps. In total, we obtained 237 daily sensor features over 12 days per participant. </p> 2. Extract demographic data. <p>It is common to have demographic data in addition to mobile and target (ground truth) data. In this example we include participants\u2019 age, gender and the number of days they spent in hospital after their surgery as features in our model. We extract these three columns from the <code>data/external/example_workflow/participant_info.csv</code> file. As these three features remain the same within participants, they are used only on the population model. Refer to the <code>demographic_features</code> rule in <code>rules/models.smk</code>.</p> 3. Create target labels. <p>The two classes for our machine learning binary classification problem are high and low symptom burden. Target values are already stored in the <code>data/external/example_workflow/participant_target.csv</code> file. A new rule/script can be created if further manipulation is necessary. Refer to the <code>parse_targets</code> rule in <code>rules/models.smk</code>.</p> 4. Feature merging. <p>These daily features are stored on a CSV file per sensor, a CSV file per participant, and a CSV file including all features from all participants (in every case each column represents a feature and each row represents a day). Refer to the <code>merge_sensor_features_for_individual_participants</code> and <code>merge_sensor_features_for_all_participants</code> rules in <code>rules/features.smk</code>.</p> 5. Data visualization. <p>At this point the user can use the five plots RAPIDS provides (or implement new ones) to explore and understand the quality of the raw data and extracted features and decide what sensors, days, or participants to include and exclude. Refer to <code>rules/reports.smk</code> to find the rules that generate these plots.</p> 6. Feature cleaning. <p>In this stage we perform four steps to clean our sensor feature file. First, we discard days with a data yield hour ratio less than or equal to 0.75, i.e. we include days with at least 18 hours of data. Second, we drop columns (features) with more than 30% of missing rows. Third, we drop columns with zero variance. Fourth, we drop rows (days) with more than 30% of missing columns (features). In this cleaning stage several parameters are created and exposed in <code>example_profile/example_config.yaml</code>. </p> <p>After this step, we kept 158 features over 11 days for the individual model of p01, 101 features over 12 days for the individual model of p02 and 106 features over 20 days for the population model. Note that the difference in the number of features between p01 and p02 is mostly due to iOS restrictions that stops researchers from collecting the same number of sensors than in Android phones. </p> <p>Feature cleaning for the individual models is done in the <code>clean_sensor_features_for_individual_participants</code> rule and for the population model in the <code>clean_sensor_features_for_all_participants</code> rule in <code>rules/models.smk</code>.</p> 7. Merge features and targets. <p>In this step we merge the cleaned features and target labels for our individual models in the <code>merge_features_and_targets_for_individual_model</code> rule in <code>rules/models.smk</code>. Additionally, we merge the cleaned features, target labels, and demographic features of our two participants for the population model in the <code>merge_features_and_targets_for_population_model</code> rule in <code>rules/models.smk</code>. These two merged files are the input for our individual and population models. </p> 8. Modelling. <p>This stage has three phases: model building, training and evaluation. </p> <p>In the building phase we impute, normalize and oversample our dataset.  Missing numeric values in each column are imputed with their mean and we impute missing categorical values with their mode. We normalize each numeric column with one of three strategies (min-max, z-score, and scikit-learn package\u2019s robust scaler) and we one-hot encode each categorial feature as a numerical array. We oversample our imbalanced dataset using SMOTE (Synthetic Minority Over-sampling Technique) or a Random Over sampler from scikit-learn. All these parameters are exposed in <code>example_profile/example_config.yaml</code>.</p> <p>In the training phase, we create eight models: logistic regression, k-nearest neighbors, support vector machine, decision tree, random forest, gradient boosting classifier, extreme gradient boosting classifier and a light gradient boosting machine. We cross-validate each model with an inner cycle to tune hyper-parameters based on the Macro F1 score and an outer cycle to predict the test set on a model with the best hyper-parameters. Both cross-validation cycles use a leave-one-out strategy. Parameters for each model like weights and learning rates are exposed in <code>example_profile/example_config.yaml</code>.</p> <p>Finally, in the evaluation phase we compute the accuracy, Macro F1, kappa, area under the curve and per class precision, recall and F1 score of all folds of the outer cross-validation cycle.</p> <p>Refer to the <code>modelling_for_individual_participants</code> rule for the individual modeling and to the <code>modelling_for_all_participants</code> rule for the population modeling, both in <code>rules/models.smk</code>.</p> 9. Compute model baselines. <p>We create three baselines to evaluate our classification models.</p> <p>First, a majority classifier that labels each test sample with the majority class of our training data. Second, a random weighted classifier that predicts each test observation sampling at random from a binomial distribution based on the ratio of our target labels. Third, a decision tree classifier based solely on the demographic features of each participant. As we do not have demographic features for individual model, this baseline is only available for population model. </p> <p>Our baseline metrics (e.g. accuracy, precision, etc.) are saved into a CSV file, ready to be compared to our modeling results. Refer to the <code>baselines_for_individual_model</code> rule for the individual model baselines and to the <code>baselines_for_population_model</code> rule for population model baselines, both in <code>rules/models.smk</code>.</p>"},{"location":"workflow-examples/minimal/","title":"Minimal Working Example","text":"<p>This is a quick guide for creating and running a simple pipeline to extract missing, outgoing, and incoming <code>call</code> features for <code>24 hr</code> (<code>00:00:00</code> to <code>23:59:59</code>) and <code>night</code> (<code>00:00:00</code> to <code>05:59:59</code>) time segments of every day of data of one participant that was monitored on the US East coast with an Android smartphone.</p> <ol> <li>Install RAPIDS and make sure your <code>conda</code> environment is active (see Installation)</li> <li>Download this CSV file and save it as <code>data/external/aware_csv/calls.csv</code></li> <li> <p>Make the changes listed below for the corresponding Configuration step (we provide an example of what the relevant sections in your <code>config.yml</code> will look like after you are done)</p> Required configuration changes (click to expand) <ol> <li> <p>Supported data streams. </p> <p>Based on the docs, we decided to use the <code>aware_csv</code> data stream because we are processing aware data saved in a CSV file. We will use this label in a later step; there\u2019s no need to type it or save it anywhere yet.</p> </li> <li> <p>Create your participants file.</p> <p>Since we are processing data from a single participant, you only need to create a single participant file called <code>p01.yaml</code> in <code>data/external/participant_files</code>. This participant file only has a <code>PHONE</code> section because this hypothetical participant was only monitored with a smartphone. Note that for a real analysis, you can do this automatically with a CSV file</p> <ol> <li> <p>Add <code>p01</code> to <code>[PIDS]</code> in <code>config.yaml</code></p> </li> <li> <p>Create a file in <code>data/external/participant_files/p01.yaml</code> with the following content:</p> <pre><code>PHONE:\n    DEVICE_IDS: [a748ee1a-1d0b-4ae9-9074-279a2b6ba524] # the participant's AWARE device id\n    PLATFORMS: [android] # or ios\n    LABEL: MyTestP01 # any string\n    START_DATE: 2020-01-01 # this can also be empty\n    END_DATE: 2021-01-01 # this can also be empty\n</code></pre> </li> </ol> </li> <li> <p>Select what time segments you want to extract features on. </p> <ol> <li> <p>Set <code>[TIME_SEGMENTS][FILE]</code> to <code>data/external/timesegments_periodic.csv</code> </p> </li> <li> <p>Create a file in <code>data/external/timesegments_periodic.csv</code> with the following content</p> <pre><code>label,start_time,length,repeats_on,repeats_value\ndaily,00:00:00,23H 59M 59S,every_day,0\nnight,00:00:00,5H 59M 59S,every_day,0\n</code></pre> </li> </ol> </li> <li> <p>Choose the timezone of your study. </p> <p>We will use the default time zone settings since this example is processing data collected on the US East Coast (<code>America/New_York</code>)</p> <pre><code>TIMEZONE: \n    TYPE: SINGLE\n    SINGLE:\n        TZCODE: America/New_York\n</code></pre> </li> <li> <p>Modify your device data stream configuration</p> <ol> <li> <p>Set <code>[PHONE_DATA_STREAMS][USE]</code> to <code>aware_csv</code>. </p> </li> <li> <p>We will use the default value for <code>[PHONE_DATA_STREAMS][aware_csv][FOLDER]</code> since we already stored the test calls CSV file there.</p> </li> </ol> </li> <li> <p>Select what sensors and features you want to process. </p> <ol> <li> <p>Set <code>[PHONE_CALLS][CONTAINER]</code> to <code>calls.csv</code> in the <code>config.yaml</code> file.</p> </li> <li> <p>Set <code>[PHONE_CALLS][PROVIDERS][RAPIDS][COMPUTE]</code> to <code>True</code> in the <code>config.yaml</code> file.</p> </li> </ol> </li> </ol> <p>Example of the <code>config.yaml</code> sections after the changes outlined above</p> <p>This will be your <code>config.yaml</code> after following the instructions above. Click on the numbered markers to know more.</p> <pre><code>PIDS: [p01] # (1)\n\nTIMEZONE:\n    TYPE: SINGLE # (2)\n    SINGLE:\n        TZCODE: America/New_York\n\n# ... other irrelevant sections\n\nTIME_SEGMENTS: &amp;time_segments\n    TYPE: PERIODIC # (3)\n    FILE: \"data/external/timesegments_periodic.csv\" # (4)\n    INCLUDE_PAST_PERIODIC_SEGMENTS: FALSE\n\nPHONE_DATA_STREAMS:\n    USE: aware_csv # (5)\n\n    aware_csv:\n        FOLDER: data/external/aware_csv # (6)\n\n# ... other irrelevant sections\n\n############## PHONE ###########################################################\n################################################################################\n\n# ... other irrelevant sections\n\n# Communication call features config, TYPES and FEATURES keys need to match\nPHONE_CALLS:\n    CONTAINER: calls.csv  # (7) \n    PROVIDERS:\n        RAPIDS:\n            COMPUTE: True # (8)\n            CALL_TYPES: ...\n</code></pre> <ol> <li> <p>We added <code>p01</code> to PIDS after creating the participant file:     <pre><code>data/external/participant_files/p01.yaml\n</code></pre></p> <p>With the following content: <pre><code>PHONE:\n    DEVICE_IDS: [a748ee1a-1d0b-4ae9-9074-279a2b6ba524] # the participant's AWARE device id\n    PLATFORMS: [android] # or ios\n    LABEL: MyTestP01 # any string\n    START_DATE: 2020-01-01 # this can also be empty\n    END_DATE: 2021-01-01 # this can also be empty\n</code></pre></p> </li> <li> <p>We use the default <code>SINGLE</code> time zone.</p> </li> <li> <p>We use the default <code>PERIODIC</code> time segment <code>[TYPE]</code></p> </li> <li> <p>We created this time segments file with these lines:</p> <pre><code>label,start_time,length,repeats_on,repeats_value\ndaily,00:00:00,23H 59M 59S,every_day,0\nnight,001:00:00,5H 59M 59S,every_day,0\n</code></pre> </li> <li> <p>We set <code>[USE]</code> to <code>aware_device</code> to tell RAPIDS to process sensor data collected with the AWARE Framework stored in CSV files.</p> </li> <li> <p>We used the default <code>[FOLDER]</code> for <code>awre_csv</code> since we already stored our test <code>calls.csv</code> file there</p> </li> <li> <p>We changed <code>[CONTAINER]</code> to <code>calls.csv</code> to process our test call data.</p> </li> <li> <p>We flipped <code>[COMPUTE]</code> to <code>True</code> to extract call behavioral features using the <code>RAPIDS</code> feature provider.</p> </li> </ol> </li> <li> <p>Run RAPIDS     <pre><code>./rapids -j1\n</code></pre></p> </li> <li>The call features for daily and morning time segments will be in     <pre><code>data/processed/features/all_participants/all_sensor_features.csv\n</code></pre></li> </ol>"}]}